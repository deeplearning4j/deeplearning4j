---
title: 深度学习框架比较：Deeplearning4j、Torch、Theano、Caffe和TensorFlow
layout: cn-default
redirect_from: /zh-compare-dl4j-torch7-pylearn
---
<p><h1>DL4J与Torch、Theano、Caffe、TensorFlow的比较</h1></p>
<p>Deeplearning4j不是第一个开源的深度学习项目，但与此前的其他项目相比，DL4J在编程语言和宗旨两方面都独具特色。DL4J是基于JVM、聚焦行业应用且提供商业支持的<strong>分布式深度学习框架</strong>，其宗旨是在合理的时间内解决各类涉及大量数据的问题。它与Hadoop和Spark集成，可使用任意数量的GPU或CPU运行，而且发生任何问题都可以<a href="http://www.skymind.io/contact?__hstc=3042607.a7ccacb889310ae8ee9e75399d132dd6.1464754825987.1481472359622.1481478033979.158&__hssc=3042607.7.1481478033979&__hsfp=4201184654" target="_blank">联系服务热线</a>。</p>
<br />
<p><h2>目录</h2></p>
<ol>
  <li><a href="#tensorflow">TensorFlow</a></li>
  <li><a href="#theano">Theano、Pylearn2及其生态系统</a></li>
  <li><a href="#torch">Torch</a></li>
  <li><a href="#caffe">Caffe</a></li>
  <li><a href="#cntk">CNTK</a></li>
  <li><a href="#dsstne">DSSTNE</a></li>
  <li><a href="#licensing">许可</a></li>
  <li><a href="#speed">速度</a></li>
  <li><a href="#java">DL4J：为什么用Java？</a></li>
  <li><a href="#ecosystem">DL4J：生态系统</a></li>
  <li><a href="#scala">DL4S：基于Scala语言的深度学习</a></li>
  <li><a href="#ml">机器学习框架</a></li>
  <li><a href="#tutorial">扩展阅读</a></li>
</ol>
<br />

<p><h2><a name="tensorflow">TensorFlow</a></h2></p>
<ul>
  <li>目前<strong>TensorFlow</strong>还不支持所谓的 "内联（inline）" 矩阵运算，必须要复制矩阵才能对其进行运算。复制非常大的矩阵会导致成本全面偏高。TF运行所需的时间是最新深度学习工具的四倍。谷歌表示正在解决这一问题。</li>
  <li>和大多数深度学习框架一样，TensorFlow是用一个Python API编写的，通过C/C++引擎加速。这种解决方案并不适合Java和Scala用户群。</li>
  <li>TensorFlow的用途不止于深度学习。TensorFlow其实还有支持强化学习和其他算法的工具。</li>
  <li>谷歌似乎也已承认TF的目标是招募人才。众所周知，他们最近公布了为期一年的谷歌大脑（Google Brain）人才培训项目。真是明智的举措。</li>
  <li>TensorFlow不提供商业支持，而谷歌也不太可能会从事支持开源企业软件的业务。谷歌的角色是为研究者提供一种新工具。</li>
  <li>和Theano一样，TensforFlow会生成计算图（如一系列矩阵运算，例如z = simoid(x)，其中x和z均为矩阵），自动求导。自动求导很重要，否则每尝试一种新的神经网络设计就要手动编写新的反向传播算法，没人愿意这样做。在谷歌的生态系统中，这些计算图会被谷歌大脑用于高强度计算，但谷歌还没有开放相关工具的源代码。TensorFlow可以算是谷歌内部深度学习解决方案的一半。</li>
  <li>从企业的角度看，许多公司需要思考的问题在于是否要依靠谷歌来提供这些工具。 </li>
</ul><br />
<p><h3>利与弊:</h3></p>
<span class="label label-success">利</span> Python + NumPy <br />
<span class="label label-success">利</span> 与Theano类似的计算图抽象化 <br />
<span class="label label-success">利</span> 编译时间比Theano快很多 <br />
<span class="label label-success">利</span> 用TensorBoard进行可视化 <br />
<span class="label label-success">利</span> 同时支持数据并行和模型并行 <br />
<span class="label label-danger">弊</span> 速度比其他框架慢 <br />
<span class="label label-danger">弊</span> 比Torch笨重许多；更难理解 <br />
<span class="label label-danger">弊</span> 已预定型的模型不多 <br />
<span class="label label-danger">弊</span> 计算图纯粹基于Python，所以速度较慢 <br />
<br />

<p><h2><a name="theano">Theano及其生态系统</a></h2></p>
<p>深度学习领域的学术研究者大多依赖<a href="http://deeplearning.net/software/theano/" target="_blank"><strong>Theano</strong></a>，Theano是深度学习框架中的元老，用Python编写。Theano和NumPy一样，是处理多维数组的学习库。Theano可与其他学习库配合使用，非常适合数据探索和研究活动。</p>
<p>现在已有大量基于Theano的开源深度学习库，包括<a href="https://github.com/fchollet/keras" target="_blank">Keras</a>、 <a href="https://lasagne.readthedocs.org/en/latest/">Lasagne</a>和<a href="https://github.com/mila-udem/blocks" target="_blank">Blocks</a>。这些学习库试着在Theano有时不够直观的界面之上添加一层便于使用的API。（截至2016年3月，另一个与Theano相关的学习库<a href="https://github.com/lisa-lab/pylearn2" target="_blank">Pylearn2似乎已经停止开发</a>。）</p>
<p>相比之下，Deeplearning4j的目标是成为深度学习领域的Scikit-learn，力求以可扩展、多个GPU或CPU并行的方式让尽可能多的控制点实现自动化，在需要时与Hadoop和<a href="https://deeplearning4j.org/spark" target="_blank">Spark</a>集成。 </p>
</p>
<br />
<p><h3>利与弊:</h3></p>
<span class="label label-success">利</span> Python + NumPy <br />
<span class="label label-success">利</span> 计算图是良好的抽象化方式 <br />
<span class="label label-success">利</span> RNN与计算图匹配良好 <br />
<span class="label label-success">利</span> 高级的包装界面（Keras、Lasagne）减少了使用时的麻烦 <br />
<span class="label label-danger">弊</span> 原始的Theano级别偏低 <br />
<span class="label label-danger">弊</span> 错误信息可能没有帮助 <br />
<span class="label label-danger">弊</span> 大型模型的编译时间可能较长 <br />
<span class="label label-danger">弊</span> 比Torch笨重许多；更难理解 <br />
<span class="label label-danger">弊</span> 对已预定型模型的支持不够完善 <br />
<br />

<p><h2><a name="torch">Torch</a></h2></p>
<p><a href="http://torch.ch/" target="_blank"><strong>Torch</strong></a>是用Lua编写的计算框架，支持机器学习算法。谷歌DeepMind、Facebook等大型科技公司使用Torch的某些版本，由内部团队专门负责定制自己的深度学习平台。Lua是上世纪九十年代早期在巴西开发的多范例脚本语言。</p>
<p>Torch7虽然功能强大，<a href="https://news.ycombinator.com/item?id=7929216" target="_blank">但其设计并不适合在两个群体中大范围普及</a>，即主要依赖Python的学术界，以及普遍使用Java的企业软件工程师。Deeplearning4j用Java编写，反映了我们对行业应用和使用便利的重视。我们认为可用性是阻碍深度学习实施工具广泛普及的限制因素。我们认为可扩展性应当通过Hadoop和Spark这样的开源分布式运行时系统来实现自动化。我们还认为，从确保工具正常运作和构建社区两方面来看，提供商业支持的开源框架是最恰当的解决方案。 </p>
<br />
<p><h3>利与弊:</h3></p>
<span class="label label-success">利</span> 大量模块化组件，容易组合 <br />
<span class="label label-success">利</span>  很容易编写自己的层类型并在GPU上运行 <br />
<span class="label label-success">利</span> Lua. ;) （大多数学习库的代码是Lua，比较易读） <br />
<span class="label label-success">利</span> 有很多已预定型的模型！ <br />
<span class="label label-danger">弊</span> Lua <br />
<span class="label label-danger">弊</span> 通常需要自己编写定型代码（即插即用相对较少） <br />
<span class="label label-danger">弊</span> 不适合循环神经网络 <br />
<br />

<p><h2><a name="caffe">Caffe</a></h2></p>
<p><a href="http://caffe.berkeleyvision.org/" target="_blank"><strong>Caffe</strong></a>是一个广为人知、广泛应用的机器视觉库，将Matlab实现的快速卷积网络移植到了C和C++平台上（<a href="https://sites.google.com/site/steveyegge2/google-at-delphi" target="_blank">参见Steve Yegge关于一个芯片一个芯片地移植C++代码的博客，可以帮助你思考如何在速度和这种特定的技术债务之间进行权衡</a>）。Caffe不适用于文本、声音或时间序列数据等其他类型的深度学习应用。与本文提到的其他一些框架相同，Caffe选择了Python作为其API。</p>
<p>Deeplearning4j和Caffe都可以用卷积网络进行图像分类，这是最先进的技术。与Caffe不同，Deeplearning4j<em>支持</em>任意芯片数的GPU并行运行，并且提供许多看似微不足道，却能使深度学习在多个并行GPU集群上运行得更流畅的功能。虽然在论文中被广泛引述，但Caffe主要用于为其Model Zoo网站提供已预定型的模型。Deeplearning4j正在开发将Caffe模型导入Spark的<a href="https://github.com/deeplearning4j/deeplearning4j/pull/480" target="_blank">开发解析器</a>。 </p>
<br />
<p><h3>利与弊:</h3></p>
<span class="label label-success">利</span> 适合前馈网络和图像处理 <br />
<span class="label label-success">利</span> 适合微调已有的网络 <br />
<span class="label label-success">利</span> 定型模型而无需编写任何代码 <br />
<span class="label label-success">利</span> Python界面相当有用 <br />
<span class="label label-danger">弊</span> 需要用C++ / CUDA编写新的GPU层 <br />
<span class="label label-danger">弊</span> 不适合循环网络 <br />
<span class="label label-danger">弊</span> 用于大型网络（GoogLeNet、ResNet）时过于繁琐 <br />
<br />

<p><h2><a name="cntk">CNTK</a></h2></p>
<p><a href="https://github.com/Microsoft/CNTK" target="_blank"><strong>CNTK</strong></a>是微软的开源深度学习框架。CNTK的全称是&ldquo;计算网络工具包。&rdquo;此学习库包括前馈DNN、卷积网络和循环网络。CNTK提供基于C++代码的Python API。虽然CNTK遵循一个<a href="https://github.com/Microsoft/CNTK/blob/master/LICENSE.md" target="_blank">比较宽松的许可协议</a>，却并未采用ASF 2.0、BSD或MIT等一些较为传统的许可协议。</p>
<br />

<p><h2><a name="dsstne">DSSTNE</a></h2></p>
<p>亚马逊的深度可伸缩稀疏张量网络引擎又称<a href="https://github.com/amznlabs/amazon-dsstne" target="_blank">DSSTNE</a>，是用于机器学习和深度学习建模的学习库。它是众多最新的开源深度学习库之一，在Tensorflow和CNTK之后发布。DSSTNE主要用C++写成，速度较快，不过吸引到的用户群体规模尚不及其他学习库。</p>
<br />

<p><h2><a name="licensing">许可</a></h2></p>
<p>上述开源项目的另一区别在于其许可协议：Theano、Torch和Caffe采用BSD许可协议，未能解决专利和专利争端问题。Deeplearning4j和ND4J采用<strong><a href="http://en.swpat.org/wiki/Patent_clauses_in_software_licences#Apache_License_2.0" target="_blank">Apache 2.0许可协议</a></strong>发布。该协议包含专利授权和防止报复性诉讼的条款，也就是说，任何人都可以自由使用遵循Apache 2.0协议的代码创作衍生作品并为其申请专利，但如果对他人提起针对原始代码（此处即DL4J）的专利权诉讼，就会立即丧失对代码的一切专利权。（换言之，这帮助你在诉讼中进行自我防卫，同时阻止你攻击他人。）BSD一般不能解决这个问题。</p>
<br />

<p><h2><a name="speed">速度</a></h2></p>
<p>Deeplearning4j依靠ND4J进行基础的线性代数运算，事实表明其处理大矩阵乘法的<a href="http://nd4j.org/benchmarking" target="_blank">速度至少是NumPy的两倍</a>。这正是DL4J被NASA的喷气推进实验室所采用的原因之一。此外，Deeplearning4j为多芯片运行而优化，支持采用CUDA C的x86和GPU。</p>
<p>虽然Torch7和DL4J都采用并行运行，DL4J的<strong>并行运行是自动化的</strong>。我们实现了从节点（worker nodes）和连接的自动化设置，让用户在<a href="https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-scaleout/spark" target="_blank">Spark</a>、<a href="https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-scaleout/hadoop-yarn" target="_blank">Hadoop</a>或<a href="http://deeplearning4j.org/scaleout.html" target="_blank">Akka和AWS</a>环境中建立大型并行网络时可以绕过学习库。Deeplearning4j最适合快速解决具体问题。</p>
<p>Deeplearning4j的所有功能参见<a href="features">功能介绍</a>。</p>
<br />

<p><h2><a name="java">为什么用Java</a></h2></p>
<p>经常有人问我们，既然有如此之多的深度学习用户都专注于Python，为什么还选择Java来实施开源深度学习项目。的确，Python有着优越的语法要素，可以直接将矩阵相加，而无需像Java那样先创建显式类。Python还有由Theano、NumPy等原生扩展组成的广泛的科学计算环境。</p>
<p>但Java也具备不少优点。首先，Java语言从根本上看要快于Python。如不考虑依赖用Cython加速的情况，任何用Python写成的代码在根本上速度都相对较慢。不可否认，运算量最大的运算都是用C或C++语言编写的。（此处所说的运算也包括高级机器学习流程中涉及的字符和其他任务。）大多数最初用Python编写的深度学习项目在用于生产时都必须重新编写。Deeplearning4j依靠<a href="https://github.com/bytedeco/javacpp" target="_blank">JavaCPP</a>从Java中调用预编译的本地C++代码，大幅提升定型速度。</p>
<p>其次，大型企业主要使用Java或基于JVM的系统。在企业界，Java依然是应用范围最广的语言。Java是Hadoop、Hive、Lucene和Pig的语言，而它们恰好都是解决机器学习问题的有用工具。也就是说，深度学习本可以帮助许多需要解决现实问题的程序员，但他们却被语言屏障阻碍。我们希望提高深度学习对于这一广大群体的可用性，这些新的用户可以将深度学习直接付诸实用。</p>
<p>第三，为了解决Java缺少强大的科学计算库的问题，我们编写了<a href="http://nd4j.org/" target="_blank">ND4J</a>。ND4J在分布式CPU或GPU上运行，可以通过Java或Scala的API进行对接。</p>
<p>最后，Java是一种安全的网络语言，本质上具有跨平台的特点，可在Linux服务器、Windows和OSX桌面、安卓手机上运行，还可通过嵌入式Java在物联网的低内存传感器上运行。Torch和Pylearn2通过C++进行优化，优化和维护因而存在困难，而Java则是 "<strong>一次编写，随处运行</strong>" 的语言，适合需要在多个平台上使用深度学习系统的企业。</p>
<br />

<p><h2><a name="ecosystem">生态系统</a></h2></p>
<p>生态系统也是为Java增添人气的优势之一。<a href="https://hadoop.apache.org/" target="_blank">Hadoop</a>是用 Java 实施的；<a href="https://spark.apache.org/" target="_blank">Spark</a>在 Hadoop 的 Yarn 运行时中运行；<a href="https://www.typesafe.com/community/core-projects/akka" target="_blank">Akka</a>等开发库让我们能够为 Deeplearning4j 开发分布式系统。总之，对几乎所有应用而言，Java的基础架构都经过反复测试，用Java编写的深度学习网络可以靠近数据，方便广大程序员的工作。Deeplearning4j 可以作为YARN的应用来运行和预配。</p>
<p>Scala、Clojure、Python 和 Ruby等其他通行的语言也可以原生支持 Java。我们选择Java，也是为了尽可能多地覆盖主要的程序员群体。</p>
<p>虽然Java的速度不及 C 和 C++，但它仍比许多人想象得要快，而我们建立的分布式系统可以通过增加节点来提升速度，节点可以是 GPU 或者 CPU。也就是说，如果要速度快，多加几盒处理器就好了。</p>
<p>最后，我们也在用 Java 为 DL4J 打造 NumPy 的基本应用，其中包括 ND-Array。我们相信 Java 的许多缺点都能很快克服，而其优势则大多会长期保持。</p>
<br />

<p><h2><a name="scala">Scala</a></h2></p>
<p>我们在打造 Deeplearning4j 和 ND4J 的过程中特别关注<a href="scala" target="_blank">Scala</a>，因为我们认为Scala具有成为数据科学主导语言的潜力。用<a href="http://nd4j.org/scala.html" target="_blank">Scala API</a>为JVM编写数值运算、向量化和深度学习库可以帮助整个群体向实现这一目标迈进。</p>
<p>关于DL4J与其他框架的不同之处，也许只需要<a href="quickstart">尝试一下</a>就能有深入的体会。</p>
<br />

<p><h2><a name="ml">机器学习框架</a></h2></p>
<p>上文提到的深度学习框架都是比较专业化的框架，此外还有许多通用型的机器学习框架。这里列举主要的几种：</p>
<ul>
  <li><a href="http://scikit-learn.org/stable/" target="_blank">sci-kit learn</a>－Python的默认开源机器学习框架。</li>
  <li><a href="https://mahout.apache.org/users/basics/quickstart.html" tabindex="
  ">Apache Mahout</a>－Apache的主打机器学习框架。Mahout可实现分类、聚类和推荐。</li>
  <li><a href="https://sparktc.github.io/systemml/quick-start-guide.html" target="_blank">SystemML</a>－IBM的机器学习框架，可进行描述性统计、分类、聚类、回归、矩阵参数化和生存分析，还包括支持向量机。</li>
  <li><a href="http://www.dmtk.io/" target="_blank">微软DMTK</a>－微软的分布式机器学习工具包。分布式词嵌入和LDA。</li>
</ul>
<br />

<p><h2><a name="tutorial">Deeplearning4j教程</a></h2></p>
<ul>
  <li><a href="neuralnet-overview">深度神经网络简介</a></li>
  <li><a href="convolutionalnets">卷积网络教程</a></li>
  <li><a href="lstm">LSTM和循环网络教程</a></li>
  <li><a href="usingrnns">通过DL4J使用循环网络</a></li>
  <li><a href="deepbeliefnetwork">MNIST中的深度置信网络</a></li>
  <li><a href="image-data-pipeline">用Canova定制数据加工管道</a></li>
  <li><a href="restrictedboltzmannmachine">受限玻尔兹曼机</a></li>
  <li><a href="eigenvector">本征向量、PCA和熵</a></li>
  <li><a href="glossary.html">深度学习词汇表</a></li>
  <li><a href="word2vec">Word2vec、Doc2vec和GloVe</a></li>
</ul>
