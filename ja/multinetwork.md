---
title:Creating deep-learning networks
layout: default
---

# ディープラーニングネットワークの作成

多層ネットワークとは積層した[単層ニューラルネットワーク](./singlelayernetwork.html)です。ニューラルネットワークの最初の層と[順伝播型ネットワーク](./glossary.html#feedforward)に入力層が付加されています。入力層に後続する各層はその前の層の出力を入力として使用します。

多層ネットワークは、単層ネットワークと同種類の入力を受け入れます。パラメータも一般に単層ネットワークのものと同じです。

多層ネットワークの出力層は、通常[ロジスティック回帰分類器](http://en.wikipedia.org/wiki/Multinomial_logistic_regression)であり、結果を0と1に分けます。ディープネットワークの隠れ層に基づいて入力の特徴を分類する識別層になります。 

多層ネットワークは、次のような種類の層で構成されています。

* **K**個の単層ネットワーク 

* ソフトマックス回帰による出力層

### パラメータ

以下はネットワークのトレーニングを行っているときに考慮しなければならないパラメータです。

### 学習率 

学習速度（またはステップ率）は、関数がサーチスペースをステップスルーする割合です。学習率は一般に0.001～0.1となっています。ステップが小さいければトレーニング時間も長くなりますが、より正確な結果が導かれます。 

### モメンタム 

モメンタムは最適なポイントに最適化アルゴリズムがどれだけ素早く収束するかを決定する要素の一つとして追加されたものす。 

トレーニングの速度を上げるには、モメンタムを増加させます。しかし、速度を上げるとモデルの精度が低下する可能性があることを知っておく必要があるでしょう。 

より詳しく言うと、モメンタムとは行列の変化率の導関数の一要素として適用される0～1の間の変数なのです。時間の経過とともに重みの変化率に変化をもたらします。 

### L2正規化の定数 

L2は[こちら](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm)の方程式内にあるラムダにあたります。

事前トレーニングの段階：

事前トレーニング（各層での復元を通じて特徴を学習）では、各層がトレーニングを受け、その出力が次の層に送られます。

微調整の段階：

最後に[ロジスティック回帰](http://en.wikipedia.org/wiki/Multinomial_logistic_regression)による出力層がトレーニングを受け、逆伝播が各層で行われます。

その他の種類の多層ネットワークには次のようなものがあります。

* [積層ノイズ除去オートエンコーダ](./stackeddenoisingautoencoder.html)
* [ディープ・ビリーフ・ネットワーク](./deepbeliefnetwork.html)
