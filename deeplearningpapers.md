---
title: Deep Learning Resources (Papers, Online Courses, Books)
layout: default
---

# Deep Learning Resources

## Online Courses

* [Andrew Ng's Machine-Learning Class on Coursera](https://www.coursera.org/learn/machine-learning/home/info)
* [Geoff Hinton's Neural Networks Class on Coursera](http://class.coursera.org/neuralnets-2012-001/lecture) (2012)
* [U. Toronto: Introduction to Neural Networks](http://www.cs.toronto.edu/~rgrosse/csc321/notes.html) (2015)
* [Yann LeCun's NYU Couse](http://cilvr.nyu.edu/doku.php?id=deeplearning:slides:start)
* [Ng's Lecture Notes for Stanford's CS229 Machine Learning](http://cs229.stanford.edu/materials.html)
* [Nando de Freitas's Deep Learning Class at Oxford](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu)  (2015)
* [Andrej Karpathy's Convolutional Neural Networks Class at Stanford](http://cs231n.github.io)
* [Patrick Winston's Introduction to Artificial Intelligence](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/)
* [Richard Socher's Deep Learning for NLP course](http://cs224d.stanford.edu/)
* [Machine Learning and Probabilistic Graphical Models](http://www.cedar.buffalo.edu/~srihari/CSE574/index.html)
* [Bhiksha Raj's "Deep Learning" @CMU](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2015/)
* [Sebastian Thrun's "Artificial Intelligence and Robotics"](https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373)
* [Caltech's Learning From Data ML Course](https://work.caltech.edu/telecourse.html)
* [Deep Learning Course at Udacity](https://www.udacity.com/course/deep-learning--ud730); Vincent Vanhoucke

## Deep- and Machine-Learning Fora

* [Google + Deep Learning Group](https://plus.google.com/u/0/communities/112866381580457264725?cfem=1)
* [KDNuggets: Data Science Hub](http://www.kdnuggets.com/)
* [Datatau: Hacker News for Data Science](http://www.datatau.com/)
* [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)
* [Deeplearning.net: A Portal for Theano/PyLearn](http://deeplearning.net/)

## Reinforcement Learning

* [Sutton & Barto's RL book](https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html)

## Academic Papers and Other Writings

**[Deep Learning Boook](http://www.deeplearningbook.org/)**; Yoshua Bengio, Ian Goodfellow, Aaron Courville; MIT Press

**[Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)**; Christopher Olah

**[Semantic Compositionality through Recursive Matrix-Vector Spaces](http://ttic.uchicago.edu/~haotang/speech/SocherHuvalManningNg_EMNLP2012.pdf)**; Richard Socher, Brody Huval, Christopher D. Manning and Andrew Y. Ng; Computer Science Department, Stanford University

**[Deep learning of the tissue-regulated splicing code](http://www.psi.toronto.edu/publications/2014/DeepSplicingCode.pdf)**; Michael K. K. Leung, Hui Yuan Xiong, Leo J. Lee and Brendan J. Frey

**[The human splicing code reveals new insights into the genetic determinants of disease](http://www.sciencemag.org/content/347/6218/1254806.abstract)**; Hui Y. Xiong et al

**[Notes on AdaGrad](http://www.ark.cs.cmu.edu/cdyer/adagrad.pdf)**; Chris Dyer; School of Computer Science, Carnegie Mellon University

**[Adaptive Step-Size for Online Temporal Difference Learning](http://people.cs.umass.edu/~wdabney/papers/alphaBounds.pdf)**; William Dabney and Andrew G. Barto; University of Massachusetts Amherst

**[Practical Recommendations for Gradient-Based Training of Deep Architectures](http://arxiv.org/abs/1206.5533)**; Yoshua Bengio; 2012

**[Greedy Layer-Wise Training of Deep Networks](http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006All.pdf)**; Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle; Université de Montreal 

**[Notes on Convolutional Neural Networks](http://cogprints.org/5869/1/cnn_tutorial.pdf)**; Jake Bouvrie; Center for Biological and Computational Learning, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology

**[Natural Language Processing (Almost) from Scratch](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35671.pdf)**; Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa; NEC Laboratories America

**[Unsupervised Feature Learning Via Sparse Hierarchical Representations](http://web.eecs.umich.edu/~honglak/thesis_final.pdf)**; Honglak Lee; Stanford University; August 2010

**[Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations](http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf)**; Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng; Computer Science Department, Stanford University, Stanford

**[Deep Belief Networks for phone recognition](http://www.cs.utoronto.ca/~gdahl/papers/dbnPhoneRec.pdf)**; Abdel-rahman Mohamed, George Dahl, and Geoffrey Hinton; Department of Computer Science, University of Toronto

**[Reducing the Dimensionality of Data with Neural Networks](http://www.cs.toronto.edu/~hinton/science.pdf)**; G. E. Hinton and R. R. Salakhutdinov; 28 July 2006 vol. 313 [Science](www.sciencemag.org)

**[Using Very Deep Autoencoders for Content-Based Image Retrieval](http://www.cs.toronto.edu/~fritz/absps/esann-deep-final.pdf)**; Alex Krizhevsky and Geoffrey E. Hinton; University of Toronto, Dept of Computer Science

**[Learning Deep Architectures for AI](http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf)**; Yoshua Bengio; Dept. IRO, Université de Montreal

**[Analysis of Recurrent Neural Networks with Application to Speaker Independent Phoneme Recognition](http://www.eskodijk.nl/doc/Dijk99_Recurrent_Neural_Networks.pdf)**; Esko O. Dijk; University of Twente, Department of Electrical Engineering

**[A fast learning algorithm for deep belief nets](http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)**; Geoffrey E. Hinton and Simon Osindero, Department of Computer Science University of Toronto; Yee-Whye Teh, Department of Computer Science, National University of Singapore

**[Learning Deep Architectures for AI](http://www.iro.umontreal.ca/~bengioy/papers/ftml.pdf)**; Yoshua Bengio; Foundations and Trends in Machine Learning, Vol. 2, No. 1 (2009)

**[An Analysis of Gaussian-Binary Restricted Boltzmann Machines for Natural Images](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2012-95.pdf)**; Nan Wang, Jan Melchior and Laurenz Wiskott; Institut fuer Neuroinformatik and International Graduate School of Neuroscience

**[IPAM Summer School 2012 Tutorial on: Deep Learning](http://www.ipam.ucla.edu/schedule.aspx?pc=gss2012)**; Geoffrey Hinton; Canadian Institute for Advanced Research & Department of Computer Science, University of Toronto

**[A Practical Guide to Training Restricted Boltzmann Machines](http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)**; Geoﬀrey Hinton; Department of Computer Science, University of Toronto

**[Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](http://www.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf)**; Feng Niu, Benjamin Recht, Christopher Re and Stephen J. Wright; Computer Sciences Department, University of Wisconsin-Madison

**[Improved Learning of Gaussian-Bernoulli Restricted Boltzmann Machines](http://users.ics.aalto.fi/praiko/papers/icann11.pdf)**; KyungHyun Cho, Alexander Ilin, and Tapani Raiko; Department of Information and Computer Science, Aalto University School of Science, Finland

**[Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations](http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf)**; Honglak Lee, Roger Grosse, Rajesh Ranganath and Andrew Y. Ng; Computer Science Department, Stanford University

**[Rectiﬁed Linear Units Improve Restricted Boltzmann Machines](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf)**; Vinod Nair and Geoﬀrey E. Hinton; Department of Computer Science, University of Toronto

**[Iris Data Analysis Using Back Propagation Neural Networks](http://www.ivanescobar.com/IRISPaper.pdf)**; Sean Van Osselaer; Murdoch University, Western Australia 

**[Distributed Training Strategies for the Structured Perceptron](http://aclweb.org/anthology//N/N10/N10-1069.pdf)**; Ryan McDonald, Keith Hall and Gideon Mann; Google

**[Large Scale Distributed Deep Networks](http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf)**; Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai Chen,
Matthieu Devin, Quoc V. Le, Mark Z. Mao, Marc’Aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang and Andrew Y. Ng; Google

**[Learning meanings for sentences](http://cseweb.ucsd.edu/~elkan/250B/learningmeaning.pdf)**; Charles Elkan; University of California San Diego; 2013

**[Lecture 17: Linear Gaussian Models](http://www.cs.ubc.ca/~murphyk/Teaching/CS532c_Fall04/Lectures/lec17x4.pdf)**; Kevin Murphy; University of British Columbia; 17 November 2004

**[Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)**; Yann LeCun, Leon Bottou, Genevieve B. Orr and Klaus-Robert Mueller; various institutions.

**[Deep Learning for NLP (without magic)](http://nlp.stanford.edu/courses/NAACL2013/)**; Richard Socher	and	Christopher	Manning; Stanford University

**[Deep Neural Networks for Object Detection](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf)**; Christian Szegedy, Alexander Toshev and Dumitru Erhan; Google

**[Deep Learning: Methods And Applications](https://research.microsoft.com/pubs/209355/NOW-Book-Revised-Feb2014-online.pdf)**; Li Deng and Dong Yu; Microsoft Research 

**[Numerical Optimization](https://www.springer.com/mathematics/book/978-0-387-30303-1)**; Jorge Nocedal and Stephen J. Wright; Springer

**[Neural Networks for Named-Entity Recognition](http://nlp.stanford.edu/~socherr/pa4_ner.pdf)**; Richard Socher; Programming Assignment 4, CS 224N; Dec. 5th, 2012

**[Large Scale Deep Learning](http://www.slideshare.net/SessionsEvents/quoc-le-slides-m-lconf)**; Quoc V. Le; Google & Carnegie Mellon University; MLconf 2013

**[Deep Learning Made Easier by Linear Transformations in Perceptrons](http://jmlr.org/proceedings/papers/v22/raiko12/raiko12.pdf)**; Tapani Raiko, Harri Valpola and Yann LeCun; Aalto University and New York University

**[Training Restricted Boltzmann Machines on Word Observations](http://www.cs.toronto.edu/~gdahl/papers/wrrbm_icml2012.pdf)**; George E. Dahl, Ryan P. Adams and Hugo Larochelle; University of Toronto, Harvard University and Université de Sherbrooke

**[Representational Power of Restricted Boltzmann Machines and Deep Belief Networks](https://research.microsoft.com/en-us/people/nicolasl/representational_power.pdf)**; Nicolas Le Roux and Yoshua Bengio; Université de Montréal

**[Robust Boltzmann Machines for Recognition and Denoising](http://www.cs.toronto.edu/~rsalakhu/papers/robm.pdf)**; Yichuan Tang, Ruslan Salakhutdinov and Geoffrey Hinton; University of Toronto

**[Semantic hashing](http://www.utstat.toronto.edu/~rsalakhu/papers/semantic_final.pdf)**; Ruslan Salakhutdinov and Geoffrey Hinton; Department of Computer Science, University of Toronto

**[Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)**; Richard Socher, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng and Christopher Potts; Stanford University

**[Opinion Mining and Sentiment Analysis](http://www.cs.cornell.edu/home/llee/omsa/omsa.pdf)**; Bo Pang and Lillian Lee; Yahoo Research; Foundations and Trends in Information Retrieval 

**[Sparse autoencoder: CS294A Lecture notes](http://www.stanford.edu/class/cs294a/sparseAutoencoder.pdf)**; Andrew Ng; Stanford University

**[Deep Sparse Rectiﬁer Neural Networks](http://eprints.pascal-network.org/archive/00008596/01/glorot11a.pdf)**; Xavier Glorot, Antoine Bordes and Yoshua Bengio;  University of Montreal

**[Stochastic Pooling for Regularization of Deep Convolutional Neural Networks](http://www.matthewzeiler.com/pubs/iclr2013/iclr2013.pdf)**; Matthew D. Zeiler and Rob Fergus; Courant Institute, New York University

**[Symmetry breaking in non-monotonic neural nets](http://iopscience.iop.org/0305-4470/26/12/005)**; G. Boffetta, R. Monasson and R. Zecchina; Journal of Physics A: Mathematical and General

**[Phone Recognition Using Restricted Boltzmann Machines](http://www.cs.toronto.edu/~asamir/papers/icassp10.pdf)**; Abdel-rahman Mohamed and Geoffrey Hinton; University of Toronto

**[Why Does Unsupervised Pre-training Help Deep Learning?](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_ErhanCBV10.pdf)**; Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent and Samy Bengio; Université de Montréeal and Google Research

**[Training Restricted Boltzmann Machines on Word Observations](http://arxiv.org/pdf/1202.5695.pdf)**; George E. Dahl, Ryan P. Adams and Hugo Larochelle; University of Toronto, Harvard University and Université de Sherbrooke

**[Visually Debugging Restricted Boltzmann Machine Training with a 3D Example](http://yosinski.com/media/papers/Yosinski2012VisuallyDebuggingRestrictedBoltzmannMachine.pdf)**; Jason Yosinski and Hod Lipson; Cornell University

**[Efficient Estimation of Word Representations in Vector Space](http://arxiv.org/pdf/1301.3781.pdf)**; Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean; Google

**[Exploiting Similarities among Languages for Machine Translation](http://arxiv.org/pdf/1309.4168.pdf)**; Tomas Mikolov, Quoc V. Le, Ilya Sutskever; Google

**[word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](http://arxiv.org/pdf/1402.3722v1.pdf)**; Yoav Goldberg and Omer Levy

**[A Few Useful Things to Know about Machine Learning](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)**; Pedro Domingos, University of Washington

**[A Neural Conversational Model](http://arxiv.org/pdf/1506.05869v1.pdf)**; Oriol Vinyals and Quoc Le, Google

**[On Chomsky and the Two Cultures of Statistical Learning](http://norvig.com/chomsky.html)**; Peter Norvig

**[Geometry of the restricted Boltzmann machine](http://arxiv.org/abs/0908.4425)**; Maria Angelica Cueto, Jason Morton, Bernd Sturmfels

**[Untersuchungen zu dynamischen neuronalen Netzen](http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf)**; Josef "Sepp" Hochreiter und Juergen Schmidhuber

**[Notes on Contrastive Divergence](http://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf)**

**[Transition-Based Dependency Parsing with Stack Long Short-Term Memory](http://arxiv.org/pdf/1505.08075v1.pdf)**; Chris Dyer, Miguel Ballesteros, Wang Ling, Austin Matthews, Noah A. Smith

**[How transferable are features in deep neural
networks?](http://arxiv.org/pdf/1411.1792v1.pdf)**; Jason Yosinski, Jeff Clune, Yoshua Bengio and Hod Lipson

**[Learning Internal Representations by Error Propagation](http://psych.stanford.edu/~jlm/papers/PDP/Volume%201/Chap8_PDP86.pdf)**; Rumelhart, Hinton and Williams

**[Backpropagation Through Time: What It Does and How to Do It](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2015/pdfs/Werbos.backprop.pdf)**; Paul Werbos

**[Learning Phrase Representations using RNN Encoder–Decoder
for Statistical Machine Translation](http://arxiv.org/pdf/1406.1078v3.pdf)**; Cho et al

**[Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises](https://web.stanford.edu/group/pdplab/pdphandbook/handbookli1.html)**; James L. McClelland

**[Memory Networks & QA Systems](http://arxiv.org/abs/1410.3916)**; Jason Weston, Sumit Chopra & Antoine Bordes (2014)

**[Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)**

**[Reinforcement Learning: An Introduction](https://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html)**; Richard Sutton and Andrew Barto

**[Algorithms for Reinforcement Learning](http://www.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf);** Csaba Szepesvári

**[Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)**; Volodymyr Mnih et al

**[The Markov Chain Monte Carlo Revolution](http://www.ams.org/journals/bull/2009-46-02/S0273-0979-08-01238-X/S0273-0979-08-01238-X.pdf)**; Diaconis

**[An Introduction to MCMC for Machine Learning](http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/AndrieuFreitasDoucetJordan2003.pdf)**

**[Continuous control with deep reinforcement learning](http://arxiv.org/pdf/1509.02971v1.pdf)**; DeepMind

**[Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2006_GravesFGS06.pdf)**

**[Using Neural Networks for Modeling and Representing Natural Languages](http://www.coling-2014.org/COLING%202014%20Tutorial-fix%20-%20Tomas%20Mikolov.pdf)**

## Thought Vectors

**[Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf)**;  
Socher et al. 2013. Introduces Recursive Neural Tensor Network. Uses a parse tree.

**[Distributed Representations of Sentences and Documents](http://cs.stanford.edu/~quocle/paragraph_vector.pdf)  
[Le](https://scholar.google.com/citations?user=vfT6-XIAAAAJ)**; Mikolov. 2014.  Introduces Paragraph Vector. Concatenates and averages pretrained, fixed word vectors to create vectors for sentences, paragraphs and documents. Also known as paragraph2vec. Doesn't use a parse tree.

**[Deep Recursive Neural Networks for Compositionality in Language](https://aclweb.org/anthology/P/P15/P15-1150.pdf)**;   
Irsoy & Cardie. 2014. Uses Deep Recursive Neural Networks. Uses a parse tree.

**[Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](https://aclweb.org/anthology/P/P15/P15-1150.pdf)**; Tai et al. 2015  Introduces Tree LSTM. Uses a parse tree.

## Dialog

**[A Neural Network Approach to Context-Sensitive Generation of Conversational Responses](http://arxiv.org/pdf/1506.06714v1.pdf)**; Sordoni 2015.  Generates responses to tweets. Uses [Recurrent Neural Network Language Model (RLM) architecture of (Mikolov et al., 2010).](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)    

**[Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks](http://arxiv.org/pdf/1502.05698v7.pdf)**; Weston 2015. Classifies QA tasks. Expands on Memory Networks.  

**[A Neural Conversation Model](http://arxiv.org/pdf/1506.05869v3.pdf)**; Vinyals, [Le](https://scholar.google.com/citations?user=vfT6-XIAAAAJ) 2015.  Uses LSTM RNNs to generate conversational responses. Uses [seq2seq framework](http://arxiv.org/pdf/1409.3215v3.pdf).  

**[A Tutorial on Support Vector Machines for Pattern Recognition](http://research.microsoft.com/pubs/67119/svmtutorial.pdf)

## Advanced Memory Architectures
**[Neural Turing Machines](http://arxiv.org/pdf/1410.5401v2.pdf)**; Graves et al. 2014.  

**[Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets](http://arxiv.org/pdf/1503.01007v4.pdf)**; Joulin, Mikolov 2015. [Stack RNN source code](https://github.com/facebook/Stack-RNN)  

## Researchers' Personal Websites

-  [Yoshua Bengio](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html)
-  [Geoffrey Hinton](http://www.cs.toronto.edu/~hinton/)
-  [Quoc V. Le](http://cs.stanford.edu/~quocle/)
-  [Yann LeCun](http://yann.lecun.com/)
-  [Andrew Y. Ng](http://cs.stanford.edu/people/ang/)
-  [Juergen Schmidhuber](http://people.idsia.ch/~juergen/)


## Linear Algebra Resources

* [Andrew Ng's 6-Part Review of Linear Algebra](https://www.youtube.com/playlist?list=PLnnr1O8OWc6boN4WHeuisJWmeQHH9D_Vg)
* [Linear Algebra for Machine Learning](https://www.youtube.com/watch?v=ZumgfOei0Ak); Patrick van der Smagt
* [Khan Academy's Linear Algebra Course](https://www.khanacademy.org/math/linear-algebra)
* [CMU's Linear Algebra Review](http://www.cs.cmu.edu/~zkolter/course/linalg/outline.html)
* [The Matrix Cookbook](https://ia801002.us.archive.org/13/items/K_B_Petersen_and_M_S_Peders__The_Matrix_Cookbook/matrixcookbook.pdf)
* [Old and New Matrix Algebra Useful for Statistics](http://research.microsoft.com/en-us/um/people/minka/papers/matrix/minka-matrix.pdf)
* [Math for Machine Learning](https://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf)
* [Immersive Linear Algebra](http://immersivemath.com/ila/learnmore.html)

## Other Resources

* [Open Data for Deep Learning](../opndata)
* [Machine Learning: Generative and Discriminative Models](http://www.cedar.buffalo.edu/~srihari/CSE574/Discriminative-Generative.pdf) (Power Point); Sargur N. Srihari
* [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) (A seven-video series)
* [A Neural Network in 11 Lines of Python](https://iamtrask.github.io/2015/07/12/basic-python-network/)
* [A Step-by-Step Backpropagation Example](http://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
* [Generative Learning algorithms](http://cs229.stanford.edu/notes/cs229-notes2.pdf); Notes by Andrew Ng
* [Calculus on Computational Graphs: Backpropagation](https://colah.github.io/posts/2015-08-Backprop/index.html)
* [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/index.html)
* [Probability Cheatsheet](https://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf)
