---
title: Machine Learning and Deep Learning Software Links
layout: default
---

# Machine Learning and Deep Learning Software Links

<li><a href="https://github.com/deeplearning4j/deeplearning4j">deeplearning4j</a>&#8211; Deeplearning4J is an Apache 2.0-licensed, open-source, distributed neural net library written in Java and Scala.</li>
<li><a href="http://www.tensorflow.org/get_started/index.html">Tensorflow</a> &#8211; TensorFlowâ„¢ is an open source software library for numerical computation using data flow graphs.</li>
<li><a href="https://github.com/dmlc/mxnet">MXNet</a> &#8211; MXNet is a deep learning framework designed for both efficiency and flexibility.</li>
<li><a href="http://caffe.berkeleyvision.org/">Caffe</a> -Caffe is a deep learning framework made with expression, speed, and modularity in mind.Caffe is a deep learning framework made with expression, speed, and modularity in mind.</li>
<li><a href="http://keras.io/">Keras</a>&#8211; A high-level Python API for deep learning libraries such as TensorFlow, Theano, CNTK and Deeplearning4j. The second-most popular DL library.</li>
<li><a href="https://github.com/Lasagne/Lasagne">Lasagne </a>&#8211; Lasagne is a lightweight library to build and train neural networks in Theano.</li>
<li><a href="http://deeplearning.net/software/theano">Theano</a> &#8211; CPU/GPU symbolic expression compiler in python (from MILA lab at University of Montreal)</li>
<li><a href="http://www.torch.ch/">Torch</a> &#8211; provides a Matlab-like environment for state-of-the-art machine learning algorithms in lua (from Ronan Collobert, Clement Farabet and Koray Kavukcuoglu)</li>
<li><a href="https://github.com/lisa-lab/pylearn2">Pylearn2</a> &#8211; Pylearn2 is a library designed to make machine learning research easy.</li>
<li><a href="https://github.com/mila-udem/blocks">Blocks </a>&#8211; A Theano framework for training neural networks</li>
<li><a href="http://deeplearning.net/tutorial">Deep Learning Tutorials</a> &#8211; examples of how to <em>do</em> Deep Learning with Theano (from LISA lab at University of Montreal)</li>
<li><a href="https://github.com/pfnet/chainer">Chainer</a> &#8211; A GPU based Neural Network Framework</li>
<li><a href="https://www.mathworks.com/discovery/deep-learning.html">Matlab Deep Learning</a> &#8211; Matlab Deep Learning Tools</li>
<li><a href="https://github.com/Microsoft/CNTK/wiki">CNTK &#8211; </a>Computational Network Toolkit &#8211; is a unified deep-learning toolkit by Microsoft Research.</li>
<li><a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> &#8211; A MATLAB toolbox implementing Convolutional Neural Networks (CNNs) for computer vision applications. It is simple, efficient, and can run and learn state-of-the-art CNNs.</li>
<li><a href="https://github.com/rasmusbergpalm/DeepLearnToolbox">DeepLearnToolbox</a> &#8211; A Matlab toolbox for Deep Learning (from Rasmus Berg Palm)</li>
<li>BigDL. A distributed open-source Apache Spark deep learning library designed for efficient scale-out to multiple nodes. CPU-optimized via MKL. Python support. Only works on CPUs. (Developed and supported by Intel Corp). <a href="https://software.intel.com/bigdl" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://software.intel.com/bigdl&amp;source=gmail&amp;ust=1494608750201000&amp;usg=AFQjCNEpgaZThoOgu81UdvSTEEg5hWF8fw">https://software.intel.com/bigdl</a>. <a href="https://github.com/intel-analytics/BigDL" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://github.com/intel-analytics/BigDL&amp;source=gmail&amp;ust=1494608750201000&amp;usg=AFQjCNHcfX6UXKsx23dhDrK2Wg09koWToA">https://github.com/intel-analytics/BigDL</a></li>
<li><a href="http://code.google.com/p/cuda-convnet/">Cuda-Convnet</a> &#8211; A fast C++/CUDA implementation of convolutional (or more generally, feed-forward) neural networks. It can model arbitrary layer connectivity and network depth. Any directed acyclic graph of layers will do. Training is done using the back-propagation algorithm.</li>
<li><a href="http://www.cs.toronto.edu/%7Ehinton/MatlabForSciencePaper.html">Deep Belief Networks</a>. Matlab code for learning Deep Belief Networks (from Ruslan Salakhutdinov).</li>
<li><a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/">RNNLM</a>&#8211; Tomas Mikolov&#8217;s Recurrent Neural Network based Language models Toolkit.</li>
<li><a href="http://sourceforge.net/projects/rnnl/">RNNLIB</a>-RNNLIB is a recurrent neural network library for sequence learning problems. Applicable to most types of spatiotemporal data, it has proven particularly effective for speech and handwriting recognition.</li>
<li><a href="http://code.google.com/p/matrbm/">matrbm</a>. Simplified version of Ruslan Salakhutdinov&#8217;s code, by Andrej Karpathy (Matlab).</li>
<li><a href="http://www.cs.toronto.edu/%7Ersalakhu/rbm_ais.html">Estimating Partition Functions of RBM&#8217;s</a>. Matlab code for estimating partition functions of Restricted Boltzmann Machines using Annealed Importance Sampling (from Ruslan Salakhutdinov).</li>
<li><a href="http://web.mit.edu/%7Ersalakhu/www/DBM.html">Learning Deep Boltzmann Machines </a>Matlab code for training and fine-tuning Deep Boltzmann Machines (from Ruslan Salakhutdinov).</li>
<li>The <a href="http://lush.sourceforge.net/">LUSH</a> programming language and development environment, which is used @ NYU for deep convolutional networks</li>
<li><a href="http://cs.nyu.edu/~koray/wp/?page_id=29">Eblearn.lsh</a> is a LUSH-based machine learning library for doing Energy-Based Learning. It includes code for &#8220;Predictive Sparse Decomposition&#8221; and other sparse auto-encoder methods for unsupervised learning. <a href="http://cs.nyu.edu/~koray/wp/">Koray Kavukcuoglu</a> provides Eblearn code for several deep learning papers on this <a href="http://cs.nyu.edu/~koray/wp/?page_id=17">page</a>.</li>
<li><a href="https://github.com/kyunghyuncho/deepmat">deepmat</a>&#8211; Deepmat, Matlab based deep learning algorithms.</li>
<li><a href="https://github.com/dmlc/mshadow">MShadow</a> &#8211; MShadow is a lightweight CPU/GPU Matrix/Tensor Template Library in C++/CUDA. The goal of mshadow is to support efficient, device invariant and simple tensor library for machine learning project that aims for both simplicity and performance. Supports CPU/GPU/Multi-GPU and distributed system.</li>
<li><a href="https://github.com/dmlc/cxxnet">CXXNET</a> &#8211; CXXNET is fast, concise, distributed deep learning framework based on MShadow. It is a lightweight and easy extensible C++/CUDA neural network toolkit with friendly Python/Matlab interface for training and prediction.</li>
<li><a href="http://nengo.ca/">Nengo</a>-Nengo is a graphical and scripting based software package for simulating large-scale neural systems.</li>
<li><a href="http://eblearn.sourceforge.net/index.shtml">Eblearn</a> is a C++ machine learning library with a BSD license for energy-based learning, convolutional networks, vision/recognition applications, etc. EBLearn is primarily maintained by <a href="http://cs.nyu.edu/~sermanet/">Pierre Sermanet</a> at NYU.</li>
<li><a href="http://code.google.com/p/cudamat/">cudamat</a> is a GPU-based matrix library for Python. Example code for training Neural Networks and Restricted Boltzmann Machines is included.</li>
<li><a href="http://www.cs.toronto.edu/~tijmen/gnumpy.html">Gnumpy</a> is a Python module that interfaces in a way almost identical to numpy, but does its computations on your computer&#8217;s GPU. It runs on top of cudamat.</li>
<li>The <a href="http://www.ais.uni-bonn.de/deep_learning/downloads.html">CUV Library</a> (github <a href="https://github.com/deeplearningais/CUV">link</a>) is a C++ framework with python bindings for easy use of Nvidia CUDA functions on matrices. It contains an RBM implementation, as well as annealed importance sampling code and code to calculate the partition function exactly (from <a href="http://www.ais.uni-bonn.de">AIS lab</a> at University of Bonn).</li>
<li><a href="http://www.cs.toronto.edu/~ranzato/publications/factored3wayRBM/code/factored3wayBM_04May2010.zip">3-way factored RBM</a> and <a href="http://www.cs.toronto.edu/~ranzato/publications/mcRBM/code/mcRBM_04May2010.zip">mcRBM</a> is python code calling CUDAMat to train models of natural images (from <a title="Marc'Aurelio Ranzato" href="http://www.cs.toronto.edu/~ranzato">Marc&#8217;Aurelio Ranzato</a>).</li>
<li>Matlab code for training <a href="http://www.cs.nyu.edu/~gwtaylor/publications/nips2006mhmublv/code.html">conditional RBMs/DBNs</a> and <a href="http://www.cs.nyu.edu/~gwtaylor/publications/icml2009/code/">factored conditional RBMs</a> (from <a href="http://www.cs.nyu.edu/~gwtaylor/">Graham Taylor</a>).</li>
<li><a href="http://www.cs.toronto.edu/~ranzato/publications/mPoT/mPoT.html">mPoT</a> is python code using CUDAMat and gnumpy to train models of natural images (from <a title="Marc'Aurelio Ranzato" href="http://www.cs.toronto.edu/%7Eranzato">Marc&#8217;Aurelio Ranzato</a>).</li>
<li><a href="https://github.com/ivan-vasilev/neuralnetworks">neuralnetworks</a> is a java based gpu library for deep learning algorithms.</li>
<li><a href="https://github.com/sdemyanov/ConvNet">ConvNet</a> is a matlab based convolutional neural network toolbox.</li>
<li><a href="http://elektronn.org/">Elektronn</a> is a deep learning toolkit that makes powerful neural networks accessible to scientists outside the machine learning community.</li>
<li><a href="http://www.opennn.net/">OpenNN</a> is an open source class library written in C++ programming language which implements neural networks, a main area of deep learning research.</li>
<li><a href="https://neuraldesigner.com/">NeuralDesigner</a>  is an innovative deep learning tool for predictive analytics.</li>
<li><a href="https://github.com/ironbar/Theano_Generalized_Hebbian_Learning">Theano Generalized Hebbian Learning.</a></li>
<li><a href="http://singa.apache.org/en/index.html" target="_blank">Apache Singa</a> is an open source deep learning library that provides a flexible architecture for scalable distributed training. It is extensible to run over a wide range of hardware, and has a focus on health-care applications.</li>
<li><a href="https://github.com/yechengxi/LightNet">Lightnet</a>  is a lightweight, versatile and purely Matlab-based deep learning framework. The aim of the design is to provide an easy-to-understand, easy-to-use and efficient computational platform for deep learning research.</li>
<li><a href="https://github.com/KotlinNLP/SimpleDNN">SimpleDNN</a> is a machine learning lightweight open-source library written in Kotlin whose purpose is to support the development of feed-forward and recurrent Artificial Neural Networks.</li>
</ol>
<p>If your software belongs here, <a href="mailto:ca9lar@gmail.com">email us</a> and let us know.</p>

## <a name="intro">More Machine Learning Tutorials</a>

For people just getting started with deep learning, the following tutorials and videos provide an easy entrance to the fundamental ideas of deep neural networks:

* [Recurrent Networks and LSTMs](./lstm.html)
* [Deep Reinforcement Learning](./deepreinforcementlearning.html)
* [Deep Convolutional Networks](./convolutionalnets.html)
* [Multilayer Perceptron (MLPs) for Classification](./multilayerperceptron.html)
* [Generative Adversarial Networks (GANs)](./generative-adversarial-network.html)
* [Symbolic Reasoning & Deep Learning](./symbolicreasoning.html)
* [Using Graph Data with Deep Learning](./graphdata.html)
* [AI vs. Machine Learning vs. Deep Learning](./ai-machinelearning-deeplearning.html)
* [Markov Chain Monte Carlo & Machine Learning](/markovchainmontecarlo.html)
* [MNIST for Beginners](./mnist-for-beginners.html)
* [Restricted Boltzmann Machines](./restrictedboltzmannmachine.html)
* [Eigenvectors, PCA, Covariance and Entropy](./eigenvector.html)
* [Glossary of Deep-Learning and Neural-Net Terms](./glossary.html)
* [Word2vec and Natural-Language Processing](./word2vec.html)
* [Deeplearning4j Examples via Quickstart](./quickstart.html)
* [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) (A seven-video series)
* [Inference: Machine Learning Model Server](./modelserver.html)
