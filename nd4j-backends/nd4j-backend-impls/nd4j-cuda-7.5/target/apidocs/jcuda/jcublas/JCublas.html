<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_73) on Tue Mar 08 22:45:47 PST 2016 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>JCublas (nd4j-cuda-7.5 0.4-rc3.9-SNAPSHOT API)</title>
<meta name="date" content="2016-03-08">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="JCublas (nd4j-cuda-7.5 0.4-rc3.9-SNAPSHOT API)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":9,"i1":9,"i2":9,"i3":9,"i4":9,"i5":9,"i6":9,"i7":9,"i8":9,"i9":9,"i10":9,"i11":9,"i12":9,"i13":9,"i14":9,"i15":9,"i16":9,"i17":9,"i18":9,"i19":9,"i20":9,"i21":9,"i22":9,"i23":9,"i24":9,"i25":9,"i26":9,"i27":9,"i28":9,"i29":9,"i30":9,"i31":9,"i32":9,"i33":9,"i34":9,"i35":9,"i36":9,"i37":9,"i38":9,"i39":9,"i40":9,"i41":9,"i42":9,"i43":9,"i44":9,"i45":9,"i46":9,"i47":9,"i48":9,"i49":9,"i50":9,"i51":9,"i52":9,"i53":9,"i54":9,"i55":9,"i56":9,"i57":9,"i58":9,"i59":9,"i60":9,"i61":9,"i62":9,"i63":9,"i64":9,"i65":9,"i66":9,"i67":9,"i68":9,"i69":9,"i70":9,"i71":9,"i72":9,"i73":9,"i74":9,"i75":9,"i76":9,"i77":9,"i78":9,"i79":9,"i80":9,"i81":9,"i82":9,"i83":9,"i84":9,"i85":9,"i86":9,"i87":9,"i88":9,"i89":9,"i90":9,"i91":9,"i92":9,"i93":9,"i94":9,"i95":9,"i96":9,"i97":9,"i98":9,"i99":9,"i100":9,"i101":9,"i102":9,"i103":9,"i104":9,"i105":9,"i106":9,"i107":9,"i108":9,"i109":9,"i110":9,"i111":9,"i112":9,"i113":9,"i114":9,"i115":9,"i116":9,"i117":9,"i118":9,"i119":9,"i120":9,"i121":9,"i122":9,"i123":9,"i124":9,"i125":9,"i126":9,"i127":9,"i128":9,"i129":9,"i130":9,"i131":9,"i132":9,"i133":9,"i134":9,"i135":9,"i136":9,"i137":9,"i138":9,"i139":9,"i140":9,"i141":9,"i142":9,"i143":9,"i144":9,"i145":9,"i146":9,"i147":9,"i148":9,"i149":9,"i150":9,"i151":9,"i152":9,"i153":9,"i154":9,"i155":9,"i156":9,"i157":9,"i158":9,"i159":9,"i160":9,"i161":9,"i162":9,"i163":9,"i164":9,"i165":9,"i166":9,"i167":9,"i168":9,"i169":9,"i170":9,"i171":9,"i172":9,"i173":9,"i174":9,"i175":9};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/JCublas.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../jcuda/jcublas/cublasStatus.html" title="class in jcuda.jcublas"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../jcuda/jcublas/JCublas2.html" title="class in jcuda.jcublas"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?jcuda/jcublas/JCublas.html" target="_top">Frames</a></li>
<li><a href="JCublas.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">jcuda.jcublas</div>
<h2 title="Class JCublas" class="title">Class JCublas</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li><a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">java.lang.Object</a></li>
<li>
<ul class="inheritance">
<li>jcuda.jcublas.JCublas</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="typeNameLabel">JCublas</span>
extends <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></pre>
<div class="block">Java bindings for CUBLAS, the NVIDIA CUDA BLAS library.
 <br />
 Most comments are taken from the cublas.h header file.
 <br />
 <b>Note:</b>: This class mimics the original CUBLAS API. 
 With CUDA 4.0, a new API for CUBLAS has been introduced.
 This is referred to as the "new CUBLAS API", and is 
 defined in the C header "cublas_v2.h". Consequently,
 the new CUBLAS API is offered via the <a href="../../jcuda/jcublas/JCublas2.html" title="class in jcuda.jcublas"><code>JCublas2</code></a> 
 class.<br>
 <br>
 New applications should generally use the new CUBLAS API.
 This class is only maintained for backward compatibility
 of existing applications. For more information, see
 http://docs.nvidia.com/cuda/cublas/#new-and-legacy-cublas-api</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasAlloc-int-int-jcuda.Pointer-">cublasAlloc</a></span>(int&nbsp;n,
           int&nbsp;elemSize,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;ptr)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasAlloc (int n, int elemSize, void **devicePtr)<br />
<br />
 creates an object in GPU memory space capable of holding an array of
 n elements, where each element requires elemSize bytes of storage.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCaxpy-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCaxpy</a></span>(int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasCaxpy (int n, cuComplex alpha, const cuComplex *x, int incx,
              cuComplex *y, int incy)

 multiplies single-complex vector x by single-complex scalar alpha and adds
 the result to single-complex vector y; that is, it overwrites single-complex
 y with single-complex alpha * x + y.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCcopy</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasCcopy (int n, const cuComplex *x, int incx, cuComplex *y, int incy)

 copies the single-complex vector x to the single-complex vector y.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>static <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCdotc-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCdotc</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cuComplex
 cublasCdotc (int n, const cuComplex *x, int incx, const cuComplex *y,
              int incy)

 computes the dot product of two single-complex vectors.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCdotu-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCdotu</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cuComplex
 cdotu (int n, const cuComplex *x, int incx, const cuComplex *y, int incy)

 computes the dot product of two single-complex vectors.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCgbmv-char-int-int-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCgbmv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;kl,
           int&nbsp;ku,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasCgbmv (char trans, int m, int n, int kl, int ku, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *x, int incx, cuComplex beta,
              cuComplex *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are single precision complex scalars.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCgemm-char-char-int-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCgemm</a></span>(char&nbsp;transa,
           char&nbsp;transb,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void cublasCgemm (char transa, char transb, int m, int n, int k,
                   cuComplex alpha, const cuComplex *A, int lda,
                   const cuComplex *B, int ldb, cuComplex beta,
                   cuComplex *C, int ldc)

 performs one of the matrix-matrix operations

    C = alpha * op(A) * op(B) + beta*C,

 where op(X) is one of

    op(X) = X   or   op(X) = transpose  or  op(X) = conjg(transpose(X))

 alpha and beta are single-complex scalars, and A, B and C are matrices
 consisting of single-complex elements, with op(A) an m x k matrix, op(B)
 a k x n matrix and C an m x n matrix.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCgemv-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCgemv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cublasCgemv (char trans, int m, int n, cuComplex alpha, const cuComplex *A,
              int lda, const cuComplex *x, int incx, cuComplex beta, cuComplex *y,
              int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A) or op(A) = conjugate(transpose(A))

 where alpha and beta are single precision scalars, x and y are single
 precision vectors, and A is an m x n matrix consisting of single precision
 elements.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCgerc-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCgerc</a></span>(int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 cublasCgerc (int m, int n, cuComplex alpha, const cuComplex *x, int incx,
             const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * conjugate(transpose(y)) + A,

 where alpha is a single precision complex scalar, x is an m element single
 precision complex vector, y is an n element single precision complex vector, and A
 is an m by n matrix consisting of single precision complex elements.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCgeru-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCgeru</a></span>(int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 cublasCgeru (int m, int n, cuComplex alpha, const cuComplex *x, int incx,
             const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a single precision complex scalar, x is an m element single
 precision complex vector, y is an n element single precision complex vector, and A
 is an m by n matrix consisting of single precision complex elements.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasChbmv-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasChbmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasChbmv (char uplo, int n, int k, cuComplex alpha, const cuComplex *A, int lda,
              const cuComplex *x, int incx, cuComplex beta, cuComplex *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are single precision complex scalars.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasChemm-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasChemm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasChemm (char side, char uplo, int m, int n, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *B, int ldb,
              cuComplex beta, cuComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision complex scalars, A is a hermitian matrix
 consisting of single precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 complex elements.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasChemv-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasChemv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasChemv (char uplo, int n, cuComplex alpha, const cuComplex *A, int lda,
              const cuComplex *x, int incx, cuComplex beta, cuComplex *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are single precision complex scalars, and x and y are single
 precision complex vectors, each with n elements.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCher-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCher</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          float&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 void
 cublasCher (char uplo, int n, float alpha, const cuComplex *x, int incx,
             cuComplex *A, int lda)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a single precision real scalar, x is an n element single
 precision complex vector and A is an n x n hermitian matrix consisting of
 single precision complex elements.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCher2-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCher2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 void cublasCher2 (char uplo, int n, cuComplex alpha, const cuComplex *x, int incx,
                   const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a single precision complex scalar, x and y are n element single
 precision complex vector and A is an n by n hermitian matrix consisting of single
 precision complex elements.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCher2k-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasCher2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            float&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasCher2k (char uplo, char trans, int n, int k, cuComplex alpha,
               const cuComplex *A, int lda, const cuComplex *B, int ldb,
               float beta, cuComplex *C, int ldc)

 performs one of the hermitian rank 2k operations

    C =   alpha * A * conjugate(transpose(B))
        + conjugate(alpha) * B * conjugate(transpose(A))
        + beta * C ,
    or
    C =  alpha * conjugate(transpose(A)) * B
       + conjugate(alpha) * conjugate(transpose(B)) * A
       + beta * C.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCherk-char-char-int-int-float-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasCherk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasCherk (char uplo, char trans, int n, int k, float alpha,
              const cuComplex *A, int lda, float beta, cuComplex *C, int ldc)

 performs one of the hermitian rank k operations

   C = alpha * A * conjugate(transpose(A)) + beta * C, or
   C = alpha * conjugate(transpose(A)) * A + beta * C.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasChpr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-">cublasChpr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          float&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasChpr (char uplo, int n, float alpha, const cuComplex *x, int incx,
             cuComplex *AP)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a single precision real scalar and x is an n element single
 precision complex vector.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasChpr2-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">cublasChpr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasChpr2 (char uplo, int n, cuComplex alpha, const cuComplex *x, int incx,
              const cuComplex *y, int incy, cuComplex *AP)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a single precision complex scalar, and x and y are n element single
 precision complex vectors.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.cuComplex-">cublasCrot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          float&nbsp;c,
          <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;s)</code>
<div class="block">
 void
 cublasCrot (int n, cuComplex *x, int incx, cuComplex *y, int incy, float sc,
             cuComplex cs)

 multiplies a 2x2 matrix ( sc       cs) with the 2xn matrix ( transpose(x) )
                         (-conj(cs) sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCrotg-jcuda.Pointer-jcuda.cuComplex-jcuda.Pointer-jcuda.Pointer-">cublasCrotg</a></span>(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ca,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;cb,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_cs)</code>
<div class="block">
 void
 cublasCrotg (cuComplex *host_ca, cuComplex cb, float *host_sc, cuComplex *host_cs)

 constructs the complex Givens tranformation

        ( sc  cs )
    G = (        ) ,  sc^2 + cabs(cs)^2 = 1,
        (-cs  sc )

 which zeros the second entry of the complex 2-vector transpose(ca, cb).</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCscal-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCscal</a></span>(int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasCscal (int n, cuComplex alpha, cuComplex *x, int incx)

 replaces single-complex vector x with single-complex alpha * x.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCsrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-float-">cublasCsrot</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           float&nbsp;c,
           float&nbsp;s)</code>
<div class="block">
 void
 csrot (int n, cuComplex *x, int incx, cuCumplex *y, int incy, float c,
        float s)

 multiplies a 2x2 rotation matrix ( c s) with a 2xn matrix ( transpose(x) )
                                  (-s c)                   ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCsscal-int-float-jcuda.Pointer-int-">cublasCsscal</a></span>(int&nbsp;n,
            float&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 void
 cublasCsscal (int n, float alpha, cuComplex *x, int incx)

 replaces single-complex vector x with single-complex alpha * x.</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCswap</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasCswap (int n, const cuComplex *x, int incx, cuComplex *y, int incy)

 interchanges the single-complex vector x with the single-complex vector y.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCsymm-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCsymm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasCsymm (char side, char uplo, int m, int n, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *B, int ldb,
              cuComplex beta, cuComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision complex scalars, A is a symmetric matrix
 consisting of single precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 complex elements.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCsyr2k-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCsyr2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasCsyr2k (char uplo, char trans, int n, int k, cuComplex alpha,
               const cuComplex *A, int lda, const cuComplex *B, int ldb,
               cuComplex beta, cuComplex *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCsyrk-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">cublasCsyrk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasCsyrk (char uplo, char trans, int n, int k, cuComplex alpha,
              const cuComplex *A, int lda, cuComplex beta, cuComplex *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtbmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasCtbmv (char uplo, char trans, char diag, int n, int k, const cuComplex *A,
              int lda, cuComplex *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtbsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void cublasCtbsv (char uplo, char trans, char diag, int n, int k,
                   const cuComplex *A, int lda, cuComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasCtpmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasCtpmv (char uplo, char trans, char diag, int n, const cuComplex *AP,
              cuComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)) .</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasCtpsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasCtpsv (char uplo, char trans, char diag, int n, const cuComplex *AP,
              cuComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose)).</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtrmm-char-char-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtrmm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasCtrmm (char side, char uplo, char transa, char diag, int m, int n,
              cuComplex alpha, const cuComplex *A, int lda, const cuComplex *B,
              int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a single-precision complex scalar, B is an m x n matrix composed
 of single precision complex elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of single precision complex elements.</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtrmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">

 cublasCtrmv (char uplo, char trans, char diag, int n, const cuComplex *A,
              int lda, cuComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x,
 where op(A) = A, or op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtrsm-char-char-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtrsm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasCtrsm (char side, char uplo, char transa, char diag, int m, int n,
              cuComplex alpha, const cuComplex *A, int lda,
              cuComplex *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a single precision complex scalar, and X and B are m x n matrices
 that are composed of single precision complex elements.</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasCtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasCtrsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasCtrsv (char uplo, char trans, char diag, int n, const cuComplex *A,
              int lda, cuComplex *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A,
 transpose(A) or conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDasum-int-jcuda.Pointer-int-">cublasDasum</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 double
 cublasDasum (int n, const double *x, int incx)

 computes the sum of the absolute values of the elements of double
 precision vector x; that is, the result is the sum from i = 0 to n - 1 of
 abs(x[1 + i * incx]).</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDaxpy-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDaxpy</a></span>(int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDaxpy (int n, double alpha, const double *x, int incx, double *y,
              int incy)

 multiplies double-precision vector x by double-precision scalar alpha
 and adds the result to double-precision vector y; that is, it overwrites
 double-precision y with double-precision alpha * x + y.</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDcopy</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDcopy (int n, const double *x, int incx, double *y, int incy)

 copies the double-precision vector x to the double-precision vector y.</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDdot-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDdot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy)</code>
<div class="block">
 double
 cublasDdot (int n, const double *x, int incx, const double *y, int incy)

 computes the dot product of two double-precision vectors.</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDgbmv-char-int-int-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDgbmv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;kl,
           int&nbsp;ku,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDgbmv (char trans, int m, int n, int kl, int ku, double alpha,
              const double *A, int lda, const double *x, int incx, double beta,
              double *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are double precision scalars.</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDgemm-char-char-int-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDgemm</a></span>(char&nbsp;transa,
           char&nbsp;transb,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;k,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasDgemm (char transa, char transb, int m, int n, int k, double alpha,
              const double *A, int lda, const double *B, int ldb,
              double beta, double *C, int ldc)

 computes the product of matrix A and matrix B, multiplies the result
 by scalar alpha, and adds the sum to the product of matrix C and
 scalar beta.</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDgemv-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDgemv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cublasDgemv (char trans, int m, int n, double alpha, const double *A,
              int lda, const double *x, int incx, double beta, double *y,
              int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are double precision scalars, x and y are double
 precision vectors, and A is an m x n matrix consisting of double precision
 elements.</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDger-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDger</a></span>(int&nbsp;m,
          int&nbsp;n,
          double&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 cublasDger (int m, int n, double alpha, const double *x, int incx,
             const double *y, int incy, double *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a double precision scalar, x is an m element double
 precision vector, y is an n element double precision vector, and A
 is an m by n matrix consisting of double precision elements.</div>
</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDnrm2-int-jcuda.Pointer-int-">cublasDnrm2</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 double
 dnrm2 (int n, const double *x, int incx)

 computes the Euclidean norm of the double-precision n-vector x (with
 storage increment incx).</div>
</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-double-">cublasDrot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          double&nbsp;sc,
          double&nbsp;ss)</code>
<div class="block">
 void
 cublasDrot (int n, double *x, int incx, double *y, int incy, double sc,
             double ss)

 multiplies a 2x2 matrix ( sc ss) with the 2xn matrix ( transpose(x) )
                         (-ss sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i46" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDrotg-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-">cublasDrotg</a></span>(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sa,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sb,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ss)</code>
<div class="block">
 void
 cublasDrotg (double *host_sa, double *host_sb, double *host_sc, double *host_ss)

 constructs the Givens tranformation

        ( sc  ss )
    G = (        ) ,  sc^2 + ss^2 = 1,
        (-ss  sc )

 which zeros the second entry of the 2-vector transpose(sa, sb).</div>
</td>
</tr>
<tr id="i47" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDrotm-int-jcuda.Pointer-int-jcuda.Pointer-int-double:A-">cublasDrotm</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           double[]&nbsp;sparam)</code>
<div class="block">Wrapper for CUBLAS function.</div>
</td>
</tr>
<tr id="i48" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDrotmg-double:A-double:A-double:A-double-double:A-">cublasDrotmg</a></span>(double[]&nbsp;sd1,
            double[]&nbsp;sd2,
            double[]&nbsp;sx1,
            double&nbsp;sy1,
            double[]&nbsp;sparam)</code>
<div class="block">Wrapper for CUBLAS function.</div>
</td>
</tr>
<tr id="i49" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsbmv-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDsbmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           int&nbsp;k,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDsbmv (char uplo, int n, int k, double alpha, const double *A, int lda,
              const double *x, int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are double precision scalars.</div>
</td>
</tr>
<tr id="i50" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDscal-int-double-jcuda.Pointer-int-">cublasDscal</a></span>(int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDscal (int n, double alpha, double *x, int incx)

 replaces double-precision vector x with double-precision alpha * x.</div>
</td>
</tr>
<tr id="i51" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDspmv-char-int-double-jcuda.Pointer-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDspmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDspmv (char uplo, int n, double alpha, const double *AP, const double *x,
              int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are double precision scalars, and x and y are double
 precision vectors with n elements.</div>
</td>
</tr>
<tr id="i52" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDspr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-">cublasDspr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          double&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasDspr (char uplo, int n, double alpha, const double *x, int incx,
             double *AP)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a double precision scalar and x is an n element double
 precision vector.</div>
</td>
</tr>
<tr id="i53" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDspr2-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">cublasDspr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasDspr2 (char uplo, int n, double alpha, const double *x, int incx,
              const double *y, int incy, double *AP)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a double precision scalar, and x and y are n element double
 precision vectors.</div>
</td>
</tr>
<tr id="i54" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDswap</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDswap (int n, double *x, int incx, double *y, int incy)

 interchanges the double-precision vector x with the double-precision vector y.</div>
</td>
</tr>
<tr id="i55" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsymm-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDsymm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasDsymm (char side, char uplo, int m, int n, double alpha,
              const double *A, int lda, const double *B, int ldb,
              double beta, double *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision scalars, A is a symmetric matrix
 consisting of double precision elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 elements.</div>
</td>
</tr>
<tr id="i56" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsymv-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDsymv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasDsymv (char uplo, int n, double alpha, const double *A, int lda,
              const double *x, int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are double precision scalars, and x and y are double
 precision vectors, each with n elements.</div>
</td>
</tr>
<tr id="i57" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsyr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDsyr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          double&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 void
 cublasDsyr (char uplo, int n, double alpha, const double *x, int incx,
             double *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a double precision scalar, x is an n element double
 precision vector and A is an n x n symmetric matrix consisting of
 double precision elements.</div>
</td>
</tr>
<tr id="i58" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsyr2-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDsyr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 void cublasDsyr2 (char uplo, int n, double alpha, const double *x, int incx,
                   const double *y, int incy, double *A, int lda)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a double precision scalar, x and y are n element double
 precision vector and A is an n by n symmetric matrix consisting of double
 precision elements.</div>
</td>
</tr>
<tr id="i59" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsyr2k-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDsyr2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            double&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            double&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasDsyr2k (char uplo, char trans, int n, int k, double alpha,
               const double *A, int lda, const double *B, int ldb,
               double beta, double *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.</div>
</td>
</tr>
<tr id="i60" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDsyrk-char-char-int-int-double-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasDsyrk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasDsyrk (char uplo, char trans, int n, int k, double alpha,
              const double *A, int lda, double beta, double *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.</div>
</td>
</tr>
<tr id="i61" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtbmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDtbmv (char uplo, char trans, char diag, int n, int k, const double *A,
              int lda, double *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i62" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtbsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void cublasDtbsv (char uplo, char trans, char diag, int n, int k,
                   const double *A, int lda, double *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i63" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasDtpmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDtpmv (char uplo, char trans, char diag, int n, const double *AP,
              double *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i64" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasDtpsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDtpsv (char uplo, char trans, char diag, int n, const double *AP,
              double *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i65" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtrmm-char-char-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtrmm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasDtrmm (char side, char uplo, char transa, char diag, int m, int n,
              double alpha, const double *A, int lda, const double *B, int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a double-precision scalar, B is an m x n matrix composed
 of double precision elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of double precision elements.</div>
</td>
</tr>
<tr id="i66" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtrmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDtrmv (char uplo, char trans, char diag, int n, const double *A,
              int lda, double *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) =
     = A, or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i67" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtrsm-char-char-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtrsm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasDtrsm (char side, char uplo, char transa, char diag, int m, int n,
              double alpha, const double *A, int lda, double *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a double precision scalar, and X and B are m x n matrices
 that are composed of double precision elements.</div>
</td>
</tr>
<tr id="i68" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasDtrsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasDtrsv (char uplo, char trans, char diag, int n, const double *A,
              int lda, double *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A or
 transpose(A).</div>
</td>
</tr>
<tr id="i69" class="rowColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDzasum-int-jcuda.Pointer-int-">cublasDzasum</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 double
 cublasDzasum (int n, const cuDoubleComplex *x, int incx)

 takes the sum of the absolute values of a complex vector and returns a
 double precision result.</div>
</td>
</tr>
<tr id="i70" class="altColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasDznrm2-int-jcuda.Pointer-int-">cublasDznrm2</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 double
 cublasDznrm2 (int n, const cuDoubleComplex *x, int incx)

 computes the Euclidean norm of the double precision complex n-vector x.</div>
</td>
</tr>
<tr id="i71" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasFree-jcuda.Pointer-">cublasFree</a></span>(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;ptr)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasFree (const void *devicePtr)<br />
<br />
 destroys the object in GPU memory space pointed to by devicePtr.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_INTERNAL_ERROR   if the object could not be deallocated<br />
 CUBLAS_STATUS_SUCCESS          if object was destroyed successfully<br /></div>
</td>
</tr>
<tr id="i72" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetError--">cublasGetError</a></span>()</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasGetError()<br />
<br />
 returns the last error that occurred on invocation of any of the
 CUBLAS BLAS functions.</div>
</td>
</tr>
<tr id="i73" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasGetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               int&nbsp;elemSize,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
               int&nbsp;lda,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
               int&nbsp;ldb)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasGetMatrix (int rows, int cols, int elemSize, const void *A,
                  int lda, void *B, int ldb)<br />
<br />
 copies a tile of rows x cols elements from a matrix A in GPU memory
 space to a matrix B in CPU memory space.</div>
</td>
</tr>
<tr id="i74" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrix-int-int-jcuda.Pointer-int-jcuda.cuComplex:A-int-int-">cublasGetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
               int&nbsp;lda,
               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;B,
               int&nbsp;offsetB,
               int&nbsp;ldb)</code>
<div class="block">Extended wrapper for arrays of cuComplex values.</div>
</td>
</tr>
<tr id="i75" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrix-int-int-jcuda.Pointer-int-jcuda.cuDoubleComplex:A-int-int-">cublasGetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
               int&nbsp;lda,
               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;B,
               int&nbsp;offsetB,
               int&nbsp;ldb)</code>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values.</div>
</td>
</tr>
<tr id="i76" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrixAsync-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">cublasGetMatrixAsync</a></span>(int&nbsp;rows,
                    int&nbsp;cols,
                    int&nbsp;elemSize,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                    int&nbsp;lda,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                    int&nbsp;ldb,
                    <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</code>&nbsp;</td>
</tr>
<tr id="i77" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasGetVector</a></span>(int&nbsp;n,
               int&nbsp;elemSize,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
               int&nbsp;incx,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
               int&nbsp;incy)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus<br />
 cublasGetVector (int n, int elemSize, const void *x, int incx,
                  void *y, int incy)<br />
<br />
 copies n elements from a vector x in GPU memory space to a vector y
 in CPU memory space.</div>
</td>
</tr>
<tr id="i78" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetVector-int-jcuda.Pointer-int-jcuda.cuComplex:A-int-int-">cublasGetVector</a></span>(int&nbsp;n,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
               int&nbsp;incx,
               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;y,
               int&nbsp;offsety,
               int&nbsp;incy)</code>
<div class="block">Extended wrapper for arrays of cuComplex values.</div>
</td>
</tr>
<tr id="i79" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetVector-int-jcuda.Pointer-int-jcuda.cuDoubleComplex:A-int-int-">cublasGetVector</a></span>(int&nbsp;n,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
               int&nbsp;incx,
               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;y,
               int&nbsp;offsety,
               int&nbsp;incy)</code>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values.</div>
</td>
</tr>
<tr id="i80" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasGetVectorAsync-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">cublasGetVectorAsync</a></span>(int&nbsp;n,
                    int&nbsp;elemSize,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;devicePtr,
                    int&nbsp;incx,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;hostPtr,
                    int&nbsp;incy,
                    <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</code>&nbsp;</td>
</tr>
<tr id="i81" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIcamax-int-jcuda.Pointer-int-">cublasIcamax</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIcamax (int n, const float *x, int incx)

 finds the smallest index of the element having maximum absolute value
 in single-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that maximizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i82" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIcamin-int-jcuda.Pointer-int-">cublasIcamin</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIcamin (int n, const float *x, int incx)

 finds the smallest index of the element having minimum absolute value
 in single-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that minimizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i83" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIdamax-int-jcuda.Pointer-int-">cublasIdamax</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 idamax (int n, const double *x, int incx)

 finds the smallest index of the maximum magnitude element of double-
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that maximizes abs(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i84" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIdamin-int-jcuda.Pointer-int-">cublasIdamin</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 idamin (int n, const double *x, int incx)

 finds the smallest index of the minimum magnitude element of double-
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that minimizes abs(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i85" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasInit--">cublasInit</a></span>()</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasInit()<br />
<br />
 initializes the CUBLAS library and must be called before any other
 CUBLAS API function is invoked.</div>
</td>
</tr>
<tr id="i86" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIsamax-int-jcuda.Pointer-int-">cublasIsamax</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIsamax (int n, const float *x, int incx)

 finds the smallest index of the maximum magnitude element of single
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that maximizes abs(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i87" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIsamin-int-jcuda.Pointer-int-">cublasIsamin</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIsamin (int n, const float *x, int incx)

 finds the smallest index of the minimum magnitude element of single
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that minimizes abs(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i88" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIzamax-int-jcuda.Pointer-int-">cublasIzamax</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIzamax (int n, const double *x, int incx)

 finds the smallest index of the element having maximum absolute value
 in double-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that maximizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i89" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasIzamin-int-jcuda.Pointer-int-">cublasIzamin</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 int
 cublasIzamin (int n, const cuDoubleComplex *x, int incx)

 finds the smallest index of the element having minimum absolute value
 in double-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that minimizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).</div>
</td>
</tr>
<tr id="i90" class="altColor">
<td class="colFirst"><code>static float</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSasum-int-jcuda.Pointer-int-">cublasSasum</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 float
 cublasSasum (int n, const float *x, int incx)

 computes the sum of the absolute values of the elements of single
 precision vector x; that is, the result is the sum from i = 0 to n - 1 of
 abs(x[1 + i * incx]).</div>
</td>
</tr>
<tr id="i91" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSaxpy-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSaxpy</a></span>(int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSaxpy (int n, float alpha, const float *x, int incx, float *y,
              int incy)

 multiplies single precision vector x by single precision scalar alpha
 and adds the result to single precision vector y; that is, it overwrites
 single precision y with single precision alpha * x + y.</div>
</td>
</tr>
<tr id="i92" class="altColor">
<td class="colFirst"><code>static float</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasScasum-int-jcuda.Pointer-int-">cublasScasum</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 float
 cublasScasum (int n, const cuDouble *x, int incx)

 takes the sum of the absolute values of a complex vector and returns a
 single precision result.</div>
</td>
</tr>
<tr id="i93" class="rowColor">
<td class="colFirst"><code>static float</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasScnrm2-int-jcuda.Pointer-int-">cublasScnrm2</a></span>(int&nbsp;n,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 float
 cublasScnrm2 (int n, const cuComplex *x, int incx)

 computes the Euclidean norm of the single-complex n-vector x.</div>
</td>
</tr>
<tr id="i94" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasScopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasScopy</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasScopy (int n, const float *x, int incx, float *y, int incy)

 copies the single precision vector x to the single precision vector y.</div>
</td>
</tr>
<tr id="i95" class="rowColor">
<td class="colFirst"><code>static float</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSdot-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSdot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy)</code>
<div class="block">
 float
 cublasSdot (int n, const float *x, int incx, const float *y, int incy)

 computes the dot product of two single precision vectors.</div>
</td>
</tr>
<tr id="i96" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetKernelStream-jcuda.runtime.cudaStream_t-">cublasSetKernelStream</a></span>(<a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</code>&nbsp;</td>
</tr>
<tr id="i97" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrix-int-int-jcuda.cuComplex:A-int-int-jcuda.Pointer-int-">cublasSetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;A,
               int&nbsp;offsetA,
               int&nbsp;lda,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
               int&nbsp;ldb)</code>
<div class="block">Extended wrapper for arrays of cuComplex values.</div>
</td>
</tr>
<tr id="i98" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrix-int-int-jcuda.cuDoubleComplex:A-int-int-jcuda.Pointer-int-">cublasSetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;A,
               int&nbsp;offsetA,
               int&nbsp;lda,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
               int&nbsp;ldb)</code>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values.</div>
</td>
</tr>
<tr id="i99" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSetMatrix</a></span>(int&nbsp;rows,
               int&nbsp;cols,
               int&nbsp;elemSize,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
               int&nbsp;lda,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
               int&nbsp;ldb)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasSetMatrix (int rows, int cols, int elemSize, const void *A,
                  int lda, void *B, int ldb)<br />
<br />
 copies a tile of rows x cols elements from a matrix A in CPU memory
 space to a matrix B in GPU memory space.</div>
</td>
</tr>
<tr id="i100" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrixAsync-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">cublasSetMatrixAsync</a></span>(int&nbsp;rows,
                    int&nbsp;cols,
                    int&nbsp;elemSize,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                    int&nbsp;lda,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                    int&nbsp;ldb,
                    <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</code>&nbsp;</td>
</tr>
<tr id="i101" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetVector-int-jcuda.cuComplex:A-int-int-jcuda.Pointer-int-">cublasSetVector</a></span>(int&nbsp;n,
               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;x,
               int&nbsp;offsetx,
               int&nbsp;incx,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
               int&nbsp;incy)</code>
<div class="block">Extended wrapper for arrays of cuComplex values.</div>
</td>
</tr>
<tr id="i102" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetVector-int-jcuda.cuDoubleComplex:A-int-int-jcuda.Pointer-int-">cublasSetVector</a></span>(int&nbsp;n,
               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;x,
               int&nbsp;offsetx,
               int&nbsp;incx,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
               int&nbsp;incy)</code>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values.</div>
</td>
</tr>
<tr id="i103" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSetVector</a></span>(int&nbsp;n,
               int&nbsp;elemSize,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
               int&nbsp;incx,
               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
               int&nbsp;incy)</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus<br />
 cublasSetVector (int n, int elemSize, const void *x, int incx,
                  void *y, int incy)<br />
<br />
 copies n elements from a vector x in CPU memory space to a vector y
 in GPU memory space.</div>
</td>
</tr>
<tr id="i104" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSetVectorAsync-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">cublasSetVectorAsync</a></span>(int&nbsp;n,
                    int&nbsp;elemSize,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;hostPtr,
                    int&nbsp;incx,
                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;devicePtr,
                    int&nbsp;incy,
                    <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</code>&nbsp;</td>
</tr>
<tr id="i105" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSgbmv-char-int-int-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSgbmv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;kl,
           int&nbsp;ku,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSgbmv (char trans, int m, int n, int kl, int ku, float alpha,
              const float *A, int lda, const float *x, int incx, float beta,
              float *y, int incy)

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are single precision scalars.</div>
</td>
</tr>
<tr id="i106" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSgemm-char-char-int-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSgemm</a></span>(char&nbsp;transa,
           char&nbsp;transb,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;k,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasSgemm (char transa, char transb, int m, int n, int k, float alpha,
              const float *A, int lda, const float *B, int ldb, float beta,
              float *C, int ldc)

 computes the product of matrix A and matrix B, multiplies the result
 by a scalar alpha, and adds the sum to the product of matrix C and
 scalar beta.</div>
</td>
</tr>
<tr id="i107" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSgemv-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSgemv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cublasSgemv (char trans, int m, int n, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are single precision scalars, x and y are single
 precision vectors, and A is an m x n matrix consisting of single precision
 elements.</div>
</td>
</tr>
<tr id="i108" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSger-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSger</a></span>(int&nbsp;m,
          int&nbsp;n,
          float&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 cublasSger (int m, int n, float alpha, const float *x, int incx,
             const float *y, int incy, float *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a single precision scalar, x is an m element single
 precision vector, y is an n element single precision vector, and A
 is an m by n matrix consisting of single precision elements.</div>
</td>
</tr>
<tr id="i109" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasShutdown--">cublasShutdown</a></span>()</code>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasShutdown()<br />
<br />
 releases CPU-side resources used by the CUBLAS library.</div>
</td>
</tr>
<tr id="i110" class="altColor">
<td class="colFirst"><code>static float</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSnrm2-int-jcuda.Pointer-int-">cublasSnrm2</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 float
 cublasSnrm2 (int n, const float *x, int incx)

 computes the Euclidean norm of the single precision n-vector x (with
 storage increment incx).</div>
</td>
</tr>
<tr id="i111" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-float-">cublasSrot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          float&nbsp;sc,
          float&nbsp;ss)</code>
<div class="block">
 void
 cublasSrot (int n, float *x, int incx, float *y, int incy, float sc,
             float ss)

 multiplies a 2x2 matrix ( sc ss) with the 2xn matrix ( transpose(x) )
                         (-ss sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i112" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSrotg-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-">cublasSrotg</a></span>(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sa,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sb,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ss)</code>
<div class="block">
 void
 cublasSrotg (float *host_sa, float *host_sb, float *host_sc, float *host_ss)

 constructs the Givens tranformation

        ( sc  ss )
    G = (        ) ,  sc^2 + ss^2 = 1,
        (-ss  sc )

 which zeros the second entry of the 2-vector transpose(sa, sb).</div>
</td>
</tr>
<tr id="i113" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSrotm-int-jcuda.Pointer-int-jcuda.Pointer-int-float:A-">cublasSrotm</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           float[]&nbsp;sparam)</code>
<div class="block">Wrapper for CUBLAS function.</div>
</td>
</tr>
<tr id="i114" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSrotmg-float:A-float:A-float:A-float-float:A-">cublasSrotmg</a></span>(float[]&nbsp;sd1,
            float[]&nbsp;sd2,
            float[]&nbsp;sx1,
            float&nbsp;sy1,
            float[]&nbsp;sparam)</code>
<div class="block">Wrapper for CUBLAS function.</div>
</td>
</tr>
<tr id="i115" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsbmv-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSsbmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           int&nbsp;k,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSsbmv (char uplo, int n, int k, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are single precision scalars.</div>
</td>
</tr>
<tr id="i116" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSscal-int-float-jcuda.Pointer-int-">cublasSscal</a></span>(int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 sscal (int n, float alpha, float *x, int incx)

 replaces single precision vector x with single precision alpha * x.</div>
</td>
</tr>
<tr id="i117" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSspmv-char-int-float-jcuda.Pointer-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSspmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSspmv (char uplo, int n, float alpha, const float *AP, const float *x,
              int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are single precision scalars, and x and y are single
 precision vectors with n elements.</div>
</td>
</tr>
<tr id="i118" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSspr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-">cublasSspr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          float&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasSspr (char uplo, int n, float alpha, const float *x, int incx,
             float *AP)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a single precision scalar and x is an n element single
 precision vector.</div>
</td>
</tr>
<tr id="i119" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSspr2-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">cublasSspr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasSspr2 (char uplo, int n, float alpha, const float *x, int incx,
              const float *y, int incy, float *AP)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a single precision scalar, and x and y are n element single
 precision vectors.</div>
</td>
</tr>
<tr id="i120" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSswap</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSswap (int n, float *x, int incx, float *y, int incy)

 interchanges the single-precision vector x with the single-precision vector y.</div>
</td>
</tr>
<tr id="i121" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsymm-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSsymm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasSsymm (char side, char uplo, int m, int n, float alpha,
              const float *A, int lda, const float *B, int ldb,
              float beta, float *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision scalars, A is a symmetric matrix
 consisting of single precision elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 elements.</div>
</td>
</tr>
<tr id="i122" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsymv-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSsymv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasSsymv (char uplo, int n, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are single precision scalars, and x and y are single
 precision vectors, each with n elements.</div>
</td>
</tr>
<tr id="i123" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsyr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSsyr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          float&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 void
 cublasSsyr (char uplo, int n, float alpha, const float *x, int incx,
             float *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a single precision scalar, x is an n element single
 precision vector and A is an n x n symmetric matrix consisting of
 single precision elements.</div>
</td>
</tr>
<tr id="i124" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsyr2-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasSsyr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 void
 cublasSsyr2 (char uplo, int n, float alpha, const float *x, int incx,
              const float *y, int incy, float *A, int lda)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a single precision scalar, x and y are n element single
 precision vector and A is an n by n symmetric matrix consisting of single
 precision elements.</div>
</td>
</tr>
<tr id="i125" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsyr2k-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSsyr2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            float&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            float&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasSsyr2k (char uplo, char trans, int n, int k, float alpha,
               const float *A, int lda, const float *B, int ldb,
               float beta, float *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.</div>
</td>
</tr>
<tr id="i126" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasSsyrk-char-char-int-int-float-jcuda.Pointer-int-float-jcuda.Pointer-int-">cublasSsyrk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           float&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasSsyrk (char uplo, char trans, int n, int k, float alpha,
              const float *A, int lda, float beta, float *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.</div>
</td>
</tr>
<tr id="i127" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStbmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasStbmv (char uplo, char trans, char diag, int n, int k, const float *A,
              int lda, float *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A
 or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i128" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStbsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void cublasStbsv (char uplo, char trans, char diag, int n, int k,
                   const float *A, int lda, float *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i129" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasStpmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasStpmv (char uplo, char trans, char diag, int n, const float *AP,
              float *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i130" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasStpsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasStpsv (char uplo, char trans, char diag, int n, const float *AP,
              float *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i131" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStrmm-char-char-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStrmm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasStrmm (char side, char uplo, char transa, char diag, int m, int n,
              float alpha, const float *A, int lda, const float *B, int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a single-precision scalar, B is an m x n matrix composed
 of single precision elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of single precision elements.</div>
</td>
</tr>
<tr id="i132" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStrmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasStrmv (char uplo, char trans, char diag, int n, const float *A,
              int lda, float *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) =
     = A, or op(A) = transpose(A).</div>
</td>
</tr>
<tr id="i133" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStrsm-char-char-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStrsm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           float&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasStrsm (char side, char uplo, char transa, char diag, int m, int n,
              float alpha, const float *A, int lda, float *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a single precision scalar, and X and B are m x n matrices
 that are composed of single precision elements.</div>
</td>
</tr>
<tr id="i134" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasStrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasStrsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasStrsv (char uplo, char trans, char diag, int n, const float *A,
              int lda, float *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A or
 transpose(A).</div>
</td>
</tr>
<tr id="i135" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZaxpy-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZaxpy</a></span>(int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZaxpy (int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
              cuDoubleComplex *y, int incy)

 multiplies double-complex vector x by double-complex scalar alpha and adds
 the result to double-complex vector y; that is, it overwrites double-complex
 y with double-complex alpha * x + y.</div>
</td>
</tr>
<tr id="i136" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZcopy</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZcopy (int n, const cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy)

 copies the double-complex vector x to the double-complex vector y.</div>
</td>
</tr>
<tr id="i137" class="rowColor">
<td class="colFirst"><code>static <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZdotc-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZdotc</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cuDoubleComplex
 cublasZdotc (int n, const cuDoubleComplex *x, int incx, const cuDoubleComplex *y, int incy)

 computes the dot product of two double-precision complex vectors.</div>
</td>
</tr>
<tr id="i138" class="altColor">
<td class="colFirst"><code>static <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZdotu-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZdotu</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cuDoubleComplex
 zdotu (int n, const cuDoubleComplex *x, int incx, const cuDoubleComplex *y, int incy)

 computes the dot product of two double-complex vectors.</div>
</td>
</tr>
<tr id="i139" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZdrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-double-">cublasZdrot</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           double&nbsp;c,
           double&nbsp;s)</code>
<div class="block">
 void
 zdrot (int n, cuDoubleComplex *x, int incx, cuCumplex *y, int incy, double c,
        double s)

 multiplies a 2x2 matrix ( c s) with the 2xn matrix ( transpose(x) )
                         (-s c)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i140" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZdscal-int-double-jcuda.Pointer-int-">cublasZdscal</a></span>(int&nbsp;n,
            double&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
            int&nbsp;incx)</code>
<div class="block">
 void
 cublasZdscal (int n, double alpha, cuDoubleComplex *x, int incx)

 replaces double-complex vector x with double-complex alpha * x.</div>
</td>
</tr>
<tr id="i141" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZgbmv-char-int-int-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZgbmv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;kl,
           int&nbsp;ku,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZgbmv (char trans, int m, int n, int kl, int ku, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *x, int incx, cuDoubleComplex beta,
              cuDoubleComplex *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are double precision complex scalars.</div>
</td>
</tr>
<tr id="i142" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZgemm-char-char-int-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZgemm</a></span>(char&nbsp;transa,
           char&nbsp;transb,
           int&nbsp;m,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void cublasZgemm (char transa, char transb, int m, int n, int k,
                   cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
                   const cuDoubleComplex *B, int ldb, cuDoubleComplex beta,
                   cuDoubleComplex *C, int ldc)

 zgemm performs one of the matrix-matrix operations

    C = alpha * op(A) * op(B) + beta*C,

 where op(X) is one of

    op(X) = X   or   op(X) = transpose  or  op(X) = conjg(transpose(X))

 alpha and beta are double-complex scalars, and A, B and C are matrices
 consisting of double-complex elements, with op(A) an m x k matrix, op(B)
 a k x n matrix and C an m x n matrix.</div>
</td>
</tr>
<tr id="i143" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZgemv-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZgemv</a></span>(char&nbsp;trans,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 cublasZgemv (char trans, int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are double precision scalars, x and y are double
 precision vectors, and A is an m x n matrix consisting of double precision
 elements.</div>
</td>
</tr>
<tr id="i144" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZgerc-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZgerc</a></span>(int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 cublasZgerc (int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
             const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * conjugate(transpose(y)) + A,

 where alpha is a double precision complex scalar, x is an m element double
 precision complex vector, y is an n element double precision complex vector, and A
 is an m by n matrix consisting of double precision complex elements.</div>
</td>
</tr>
<tr id="i145" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZgeru-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZgeru</a></span>(int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 cublasZgeru (int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
             const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a double precision complex scalar, x is an m element double
 precision complex vector, y is an n element double precision complex vector, and A
 is an m by n matrix consisting of double precision complex elements.</div>
</td>
</tr>
<tr id="i146" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhbmv-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZhbmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZhbmv (char uplo, int n, int k, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are double precision complex scalars.</div>
</td>
</tr>
<tr id="i147" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhemm-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZhemm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZhemm (char side, char uplo, int m, int n, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
              cuDoubleComplex beta, cuDoubleComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision complex scalars, A is a hermitian matrix
 consisting of double precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 complex elements.</div>
</td>
</tr>
<tr id="i148" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhemv-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZhemv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZhemv (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are double precision complex scalars, and x and y are double
 precision complex vectors, each with n elements.</div>
</td>
</tr>
<tr id="i149" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZher-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZher</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          double&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
          int&nbsp;lda)</code>
<div class="block">
 void
 cublasZher (char uplo, int n, double alpha, const cuDoubleComplex *x, int incx,
             cuDoubleComplex *A, int lda)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x) + A,

 where alpha is a double precision real scalar, x is an n element double
 precision complex vector and A is an n x n hermitian matrix consisting of
 double precision complex elements.</div>
</td>
</tr>
<tr id="i150" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZher2-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZher2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>
<div class="block">
 void cublasZher2 (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
                   const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a double precision complex scalar, x and y are n element double
 precision complex vector and A is an n by n hermitian matrix consisting of double
 precision complex elements.</div>
</td>
</tr>
<tr id="i151" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZher2k-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasZher2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            double&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZher2k (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
               const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
               double beta, cuDoubleComplex *C, int ldc)

 performs one of the hermitian rank 2k operations

    C =   alpha * A * conjugate(transpose(B))
        + conjugate(alpha) * B * conjugate(transpose(A))
        + beta * C ,
    or
    C =  alpha * conjugate(transpose(A)) * B
       + conjugate(alpha) * conjugate(transpose(B)) * A
       + beta * C.</div>
</td>
</tr>
<tr id="i152" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZherk-char-char-int-int-double-jcuda.Pointer-int-double-jcuda.Pointer-int-">cublasZherk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           double&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           double&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZherk (char uplo, char trans, int n, int k, double alpha,
              const cuDoubleComplex *A, int lda, double beta, cuDoubleComplex *C, int ldc)

 performs one of the hermitian rank k operations

   C = alpha * A * conjugate(transpose(A)) + beta * C, or
   C = alpha * conjugate(transpose(A)) * A + beta * C.</div>
</td>
</tr>
<tr id="i153" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhpmv-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZhpmv</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZhpmv (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *AP, const cuDoubleComplex *x,
              int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are double precision complex scalars, and x and y are double
 precision complex vectors with n elements.</div>
</td>
</tr>
<tr id="i154" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhpr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-">cublasZhpr</a></span>(char&nbsp;uplo,
          int&nbsp;n,
          double&nbsp;alpha,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasZhpr (char uplo, int n, double alpha, const cuDoubleComplex *x, int incx,
             cuDoubleComplex *AP)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a double precision real scalar and x is an n element double
 precision complex vector.</div>
</td>
</tr>
<tr id="i155" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZhpr2-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">cublasZhpr2</a></span>(char&nbsp;uplo,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</code>
<div class="block">
 void
 cublasZhpr2 (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
              const cuDoubleComplex *y, int incy, cuDoubleComplex *AP)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a double precision complex scalar, and x and y are n element double
 precision complex vectors.</div>
</td>
</tr>
<tr id="i156" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.cuDoubleComplex-">cublasZrot</a></span>(int&nbsp;n,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
          int&nbsp;incx,
          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
          int&nbsp;incy,
          double&nbsp;sc,
          <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cs)</code>
<div class="block">
 cublasZrot (int n, cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy, double sc,
             cuDoubleComplex cs)

 multiplies a 2x2 matrix ( sc       cs) with the 2xn matrix ( transpose(x) )
                         (-conj(cs) sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ...</div>
</td>
</tr>
<tr id="i157" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZrotg-jcuda.Pointer-jcuda.cuDoubleComplex-jcuda.Pointer-jcuda.Pointer-">cublasZrotg</a></span>(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ca,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cb,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_cs)</code>
<div class="block">
 void
 cublasZrotg (cuDoubleComplex *host_ca, cuDoubleComplex cb, double *host_sc, double *host_cs)

 constructs the complex Givens tranformation

        ( sc  cs )
    G = (        ) ,  sc^2 + cabs(cs)^2 = 1,
        (-cs  sc )

 which zeros the second entry of the complex 2-vector transpose(ca, cb).</div>
</td>
</tr>
<tr id="i158" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZscal-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZscal</a></span>(int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZscal (int n, cuComplex alpha, cuComplex *x, int incx)

 replaces double-complex vector x with double-complex alpha * x.</div>
</td>
</tr>
<tr id="i159" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZswap</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
           int&nbsp;incy)</code>
<div class="block">
 void
 cublasZswap (int n, const cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy)

 interchanges the double-complex vector x with the double-complex vector y.</div>
</td>
</tr>
<tr id="i160" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZsymm-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZsymm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZsymm (char side, char uplo, int m, int n, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
              cuDoubleComplex beta, cuDoubleComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision complex scalars, A is a symmetric matrix
 consisting of double precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 complex elements.</div>
</td>
</tr>
<tr id="i161" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZsyr2k-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZsyr2k</a></span>(char&nbsp;uplo,
            char&nbsp;trans,
            int&nbsp;n,
            int&nbsp;k,
            <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
            int&nbsp;lda,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
            int&nbsp;ldb,
            <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
            <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
            int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZsyr2k (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
               const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
               cuDoubleComplex beta, cuDoubleComplex *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.</div>
</td>
</tr>
<tr id="i162" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZsyrk-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">cublasZsyrk</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
           int&nbsp;ldc)</code>
<div class="block">
 void
 cublasZsyrk (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, cuDoubleComplex beta, cuDoubleComplex *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.</div>
</td>
</tr>
<tr id="i163" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtbmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZtbmv (char uplo, char trans, char diag, int n, int k, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i164" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtbsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           int&nbsp;k,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void cublasZtbsv (char uplo, char trans, char diag, int n, int k,
                   const cuDoubleComplex *A, int lda, cuDoubleComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i165" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasZtpmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZtpmv (char uplo, char trans, char diag, int n, const cuDoubleComplex *AP,
              cuDoubleComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)) .</div>
</td>
</tr>
<tr id="i166" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">cublasZtpsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZtpsv (char uplo, char trans, char diag, int n, const cuDoubleComplex *AP,
              cuDoubleComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose)).</div>
</td>
</tr>
<tr id="i167" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtrmm-char-char-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtrmm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasZtrmm (char side, char uplo, char transa, char diag, int m, int n,
              cuDoubleComplex alpha, const cuDoubleComplex *A, int lda, const cuDoubleComplex *B,
              int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a double-precision complex scalar, B is an m x n matrix composed
 of double precision complex elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of double precision complex elements.</div>
</td>
</tr>
<tr id="i168" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtrmv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZtrmv (char uplo, char trans, char diag, int n, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x,
 where op(A) = A, or op(A) = transpose(A) or op(A) = conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i169" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtrsm-char-char-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtrsm</a></span>(char&nbsp;side,
           char&nbsp;uplo,
           char&nbsp;transa,
           char&nbsp;diag,
           int&nbsp;m,
           int&nbsp;n,
           <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
           int&nbsp;ldb)</code>
<div class="block">
 void
 cublasZtrsm (char side, char uplo, char transa, char diag, int m, int n,
              cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              cuDoubleComplex *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a double precision complex scalar, and X and B are m x n matrices
 that are composed of double precision complex elements.</div>
</td>
</tr>
<tr id="i170" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#cublasZtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">cublasZtrsv</a></span>(char&nbsp;uplo,
           char&nbsp;trans,
           char&nbsp;diag,
           int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
           int&nbsp;incx)</code>
<div class="block">
 void
 cublasZtrsv (char uplo, char trans, char diag, int n, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A,
 transpose(A) or conjugate(transpose(A)).</div>
</td>
</tr>
<tr id="i171" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#initialize--">initialize</a></span>()</code>
<div class="block">Initializes the native library.</div>
</td>
</tr>
<tr id="i172" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#printMatrix-int-jcuda.Pointer-int-">printMatrix</a></span>(int&nbsp;cols,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
           int&nbsp;lda)</code>&nbsp;</td>
</tr>
<tr id="i173" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#printVector-int-jcuda.Pointer-">printVector</a></span>(int&nbsp;n,
           <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x)</code>&nbsp;</td>
</tr>
<tr id="i174" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#setExceptionsEnabled-boolean-">setExceptionsEnabled</a></span>(boolean&nbsp;enabled)</code>
<div class="block">Enables or disables exceptions.</div>
</td>
</tr>
<tr id="i175" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../jcuda/jcublas/JCublas.html#setLogLevel-jcuda.LogLevel-">setLogLevel</a></span>(<a href="../../jcuda/LogLevel.html" title="enum in jcuda">LogLevel</a>&nbsp;logLevel)</code>
<div class="block">Set the specified log level for the JCublas library.<br />
 <br />
 Currently supported log levels:
 <br />
 LOG_QUIET: Never print anything <br />
 LOG_ERROR: Print error messages <br />
 LOG_TRACE: Print a trace of all native function calls <br /></div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.<a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></h3>
<code><a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#clone--" title="class or interface in java.lang">clone</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#equals-java.lang.Object-" title="class or interface in java.lang">equals</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#finalize--" title="class or interface in java.lang">finalize</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#getClass--" title="class or interface in java.lang">getClass</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#hashCode--" title="class or interface in java.lang">hashCode</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#notify--" title="class or interface in java.lang">notify</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#notifyAll--" title="class or interface in java.lang">notifyAll</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#toString--" title="class or interface in java.lang">toString</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait--" title="class or interface in java.lang">wait</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait-long-" title="class or interface in java.lang">wait</a>, <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait-long-int-" title="class or interface in java.lang">wait</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="initialize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initialize</h4>
<pre>public static&nbsp;void&nbsp;initialize()</pre>
<div class="block">Initializes the native library. Note that this method
 does not have to be called explicitly, since it will
 be called automatically when this class is loaded.</div>
</li>
</ul>
<a name="setLogLevel-jcuda.LogLevel-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLogLevel</h4>
<pre>public static&nbsp;void&nbsp;setLogLevel(<a href="../../jcuda/LogLevel.html" title="enum in jcuda">LogLevel</a>&nbsp;logLevel)</pre>
<div class="block">Set the specified log level for the JCublas library.<br />
 <br />
 Currently supported log levels:
 <br />
 LOG_QUIET: Never print anything <br />
 LOG_ERROR: Print error messages <br />
 LOG_TRACE: Print a trace of all native function calls <br /></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>logLevel</code> - The log level to use.</dd>
</dl>
</li>
</ul>
<a name="setExceptionsEnabled-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setExceptionsEnabled</h4>
<pre>public static&nbsp;void&nbsp;setExceptionsEnabled(boolean&nbsp;enabled)</pre>
<div class="block">Enables or disables exceptions. By default, the methods of this class
 only set the result status which may be queried with
 <a href="../../jcuda/jcublas/JCublas.html#cublasGetError--"><code>cublasGetError()</code></a>.
 If exceptions are enabled, a CudaException with a detailed error
 message will be thrown if a method is about to set a result code
 that is not cublasStatus.CUBLAS_STATUS_SUCCESS</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>enabled</code> - Whether exceptions are enabled</dd>
</dl>
</li>
</ul>
<a name="cublasInit--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasInit</h4>
<pre>public static&nbsp;int&nbsp;cublasInit()</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasInit()<br />
<br />
 initializes the CUBLAS library and must be called before any other
 CUBLAS API function is invoked. It allocates hardware resources
 necessary for accessing the GPU.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_ALLOC_FAILED     if resources could not be allocated<br />
 CUBLAS_STATUS_SUCCESS          if CUBLAS library initialized successfully<br /></div>
</li>
</ul>
<a name="cublasShutdown--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasShutdown</h4>
<pre>public static&nbsp;int&nbsp;cublasShutdown()</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasShutdown()<br />
<br />
 releases CPU-side resources used by the CUBLAS library. The release of
 GPU-side resources may be deferred until the application shuts down.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_SUCCESS          if CUBLAS library shut down successfully<br /></div>
</li>
</ul>
<a name="cublasGetError--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetError</h4>
<pre>public static&nbsp;int&nbsp;cublasGetError()</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasGetError()<br />
<br />
 returns the last error that occurred on invocation of any of the
 CUBLAS BLAS functions. While the CUBLAS helper functions return status
 directly, the BLAS functions do not do so for improved
 compatibility with existing environments that do not expect BLAS
 functions to return status. Reading the error status via
 cublasGetError() resets the internal error state to
 CUBLAS_STATUS_SUCCESS.</div>
</li>
</ul>
<a name="cublasAlloc-int-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasAlloc</h4>
<pre>public static&nbsp;int&nbsp;cublasAlloc(int&nbsp;n,
                              int&nbsp;elemSize,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;ptr)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasAlloc (int n, int elemSize, void **devicePtr)<br />
<br />
 creates an object in GPU memory space capable of holding an array of
 n elements, where each element requires elemSize bytes of storage. If
 the function call is successful, a pointer to the object in GPU memory
 space is placed in devicePtr. Note that this is a device pointer that
 cannot be dereferenced in host code.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_INVALID_VALUE    if n <= 0, or elemSize <= 0<br />
 CUBLAS_STATUS_ALLOC_FAILED     if the object could not be allocated due to
                                lack of resources.<br />
 CUBLAS_STATUS_SUCCESS          if storage was successfully allocated<br /></div>
</li>
</ul>
<a name="cublasFree-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasFree</h4>
<pre>public static&nbsp;int&nbsp;cublasFree(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;ptr)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasFree (const void *devicePtr)<br />
<br />
 destroys the object in GPU memory space pointed to by devicePtr.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_INTERNAL_ERROR   if the object could not be deallocated<br />
 CUBLAS_STATUS_SUCCESS          if object was destroyed successfully<br /></div>
</li>
</ul>
<a name="printVector-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printVector</h4>
<pre>public static&nbsp;void&nbsp;printVector(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x)</pre>
</li>
</ul>
<a name="printMatrix-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printMatrix</h4>
<pre>public static&nbsp;void&nbsp;printMatrix(int&nbsp;cols,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
</li>
</ul>
<a name="cublasSetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasSetVector(int&nbsp;n,
                                  int&nbsp;elemSize,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                  int&nbsp;incy)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus<br />
 cublasSetVector (int n, int elemSize, const void *x, int incx,
                  void *y, int incy)<br />
<br />
 copies n elements from a vector x in CPU memory space to a vector y
 in GPU memory space. Elements in both vectors are assumed to have a
 size of elemSize bytes. Storage spacing between consecutive elements
 is incx for the source vector x and incy for the destination vector
 y. In general, y points to an object, or part of an object, allocated
 via cublasAlloc(). Column major format for two-dimensional matrices
 is assumed throughout CUBLAS. Therefore, if the increment for a vector
 is equal to 1, this access a column vector while using an increment
 equal to the leading dimension of the respective matrix accesses a
 row vector.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library not been initialized<br />
 CUBLAS_STATUS_INVALID_VALUE    if incx, incy, or elemSize <= 0<br />
 CUBLAS_STATUS_MAPPING_ERROR    if an error occurred accessing GPU memory<br />
 CUBLAS_STATUS_SUCCESS          if the operation completed successfully<br /></div>
</li>
</ul>
<a name="cublasSetVector-int-jcuda.cuComplex:A-int-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasSetVector(int&nbsp;n,
                                  <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;x,
                                  int&nbsp;offsetx,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                  int&nbsp;incy)</pre>
<div class="block">Extended wrapper for arrays of cuComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a float array containing
 the complex numbers, where each pair of consecutive numbers in the array
 describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasSetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasSetVector(int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasGetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasGetVector(int&nbsp;n,
                                  int&nbsp;elemSize,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                  int&nbsp;incy)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus<br />
 cublasGetVector (int n, int elemSize, const void *x, int incx,
                  void *y, int incy)<br />
<br />
 copies n elements from a vector x in GPU memory space to a vector y
 in CPU memory space. Elements in both vectors are assumed to have a
 size of elemSize bytes. Storage spacing between consecutive elements
 is incx for the source vector x and incy for the destination vector
 y. In general, x points to an object, or part of an object, allocated
 via cublasAlloc(). Column major format for two-dimensional matrices
 is assumed throughout CUBLAS. Therefore, if the increment for a vector
 is equal to 1, this access a column vector while using an increment
 equal to the leading dimension of the respective matrix accesses a
 row vector.<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library not been initialized<br />
 CUBLAS_STATUS_INVALID_VALUE    if incx, incy, or elemSize <= 0<br />
 CUBLAS_STATUS_MAPPING_ERROR    if an error occurred accessing GPU memory<br />
 CUBLAS_STATUS_SUCCESS          if the operation completed successfully<br /></div>
</li>
</ul>
<a name="cublasGetVector-int-jcuda.Pointer-int-jcuda.cuComplex:A-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasGetVector(int&nbsp;n,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;y,
                                  int&nbsp;offsety,
                                  int&nbsp;incy)</pre>
<div class="block">Extended wrapper for arrays of cuComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a float array that may
 store the complex numbers, where each pair of consecutive numbers in
 the array describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasGetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasGetVector(int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasSetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasSetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  int&nbsp;elemSize,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                  int&nbsp;ldb)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasSetMatrix (int rows, int cols, int elemSize, const void *A,
                  int lda, void *B, int ldb)<br />
<br />
 copies a tile of rows x cols elements from a matrix A in CPU memory
 space to a matrix B in GPU memory space. Each element requires storage
 of elemSize bytes. Both matrices are assumed to be stored in column
 major format, with the leading dimension (i.e. number of rows) of
 source matrix A provided in lda, and the leading dimension of matrix B
 provided in ldb. In general, B points to an object, or part of an
 object, that was allocated via cublasAlloc().<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_INVALID_VALUE    if rows or cols < 0, or elemSize, lda, or
                                ldb <= 0<br />
 CUBLAS_STATUS_MAPPING_ERROR    if error occurred accessing GPU memory<br />
 CUBLAS_STATUS_SUCCESS          if the operation completed successfully<br /></div>
</li>
</ul>
<a name="cublasSetMatrix-int-int-jcuda.cuComplex:A-int-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasSetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;A,
                                  int&nbsp;offsetA,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                  int&nbsp;ldb)</pre>
<div class="block">Extended wrapper for arrays of cuComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a float array containing
 the complex numbers, where each pair of consecutive numbers in the array
 describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasSetMatrix(int, int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasGetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasGetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  int&nbsp;elemSize,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                  int&nbsp;ldb)</pre>
<div class="block">Wrapper for CUBLAS function.<br />
 <br />
 cublasStatus
 cublasGetMatrix (int rows, int cols, int elemSize, const void *A,
                  int lda, void *B, int ldb)<br />
<br />
 copies a tile of rows x cols elements from a matrix A in GPU memory
 space to a matrix B in CPU memory space. Each element requires storage
 of elemSize bytes. Both matrices are assumed to be stored in column
 major format, with the leading dimension (i.e. number of rows) of
 source matrix A provided in lda, and the leading dimension of matrix B
 provided in ldb. In general, A points to an object, or part of an
 object, that was allocated via cublasAlloc().<br />
<br />
 Return Values<br />
 -------------<br />
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized<br />
 CUBLAS_STATUS_INVALID_VALUE    if rows, cols, eleSize, lda, or ldb <= 0<br />
 CUBLAS_STATUS_MAPPING_ERROR    if error occurred accessing GPU memory<br />
 CUBLAS_STATUS_SUCCESS          if the operation completed successfully<br /></div>
</li>
</ul>
<a name="cublasGetMatrix-int-int-jcuda.Pointer-int-jcuda.cuComplex:A-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasGetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>[]&nbsp;B,
                                  int&nbsp;offsetB,
                                  int&nbsp;ldb)</pre>
<div class="block">Extended wrapper for arrays of cuComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a float array that may
 store the complex numbers, where each pair of consecutive numbers in
 the array describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasGetMatrix(int, int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasSetVector-int-jcuda.cuDoubleComplex:A-int-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasSetVector(int&nbsp;n,
                                  <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;x,
                                  int&nbsp;offsetx,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                  int&nbsp;incy)</pre>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a double array containing
 the complex numbers, where each pair of consecutive numbers in the array
 describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasSetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasSetVector(int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasGetVector-int-jcuda.Pointer-int-jcuda.cuDoubleComplex:A-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetVector</h4>
<pre>public static&nbsp;int&nbsp;cublasGetVector(int&nbsp;n,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx,
                                  <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;y,
                                  int&nbsp;offsety,
                                  int&nbsp;incy)</pre>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a double array that may
 store the complex numbers, where each pair of consecutive numbers in
 the array describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasGetVector-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasGetVector(int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasSetMatrix-int-int-jcuda.cuDoubleComplex:A-int-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasSetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;A,
                                  int&nbsp;offsetA,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                  int&nbsp;ldb)</pre>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a double array containing
 the complex numbers, where each pair of consecutive numbers in the array
 describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasSetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasSetMatrix(int, int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasGetMatrix-int-int-jcuda.Pointer-int-jcuda.cuDoubleComplex:A-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetMatrix</h4>
<pre>public static&nbsp;int&nbsp;cublasGetMatrix(int&nbsp;rows,
                                  int&nbsp;cols,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                  int&nbsp;lda,
                                  <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>[]&nbsp;B,
                                  int&nbsp;offsetB,
                                  int&nbsp;ldb)</pre>
<div class="block">Extended wrapper for arrays of cuDoubleComplex values. Note that this method
 only exists for convenience and compatibility with native C code. It
 is much more efficient to provide a Pointer to a double array that may
 store the complex numbers, where each pair of consecutive numbers in
 the array describes the real- and imaginary part of one complex number.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../jcuda/jcublas/JCublas.html#cublasGetMatrix-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-"><code>cublasGetMatrix(int, int, int, Pointer, int, Pointer, int)</code></a></dd>
</dl>
</li>
</ul>
<a name="cublasSetKernelStream-jcuda.runtime.cudaStream_t-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetKernelStream</h4>
<pre>public static&nbsp;int&nbsp;cublasSetKernelStream(<a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</pre>
</li>
</ul>
<a name="cublasSetVectorAsync-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetVectorAsync</h4>
<pre>public static&nbsp;int&nbsp;cublasSetVectorAsync(int&nbsp;n,
                                       int&nbsp;elemSize,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;hostPtr,
                                       int&nbsp;incx,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;devicePtr,
                                       int&nbsp;incy,
                                       <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</pre>
</li>
</ul>
<a name="cublasGetVectorAsync-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetVectorAsync</h4>
<pre>public static&nbsp;int&nbsp;cublasGetVectorAsync(int&nbsp;n,
                                       int&nbsp;elemSize,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;devicePtr,
                                       int&nbsp;incx,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;hostPtr,
                                       int&nbsp;incy,
                                       <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</pre>
</li>
</ul>
<a name="cublasSetMatrixAsync-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSetMatrixAsync</h4>
<pre>public static&nbsp;int&nbsp;cublasSetMatrixAsync(int&nbsp;rows,
                                       int&nbsp;cols,
                                       int&nbsp;elemSize,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                       int&nbsp;lda,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                       int&nbsp;ldb,
                                       <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</pre>
</li>
</ul>
<a name="cublasGetMatrixAsync-int-int-int-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.runtime.cudaStream_t-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasGetMatrixAsync</h4>
<pre>public static&nbsp;int&nbsp;cublasGetMatrixAsync(int&nbsp;rows,
                                       int&nbsp;cols,
                                       int&nbsp;elemSize,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                       int&nbsp;lda,
                                       <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                       int&nbsp;ldb,
                                       <a href="../../jcuda/runtime/cudaStream_t.html" title="class in jcuda.runtime">cudaStream_t</a>&nbsp;stream)</pre>
</li>
</ul>
<a name="cublasSrotm-int-jcuda.Pointer-int-jcuda.Pointer-int-float:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSrotm</h4>
<pre>public static&nbsp;void&nbsp;cublasSrotm(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               float[]&nbsp;sparam)</pre>
<div class="block">Wrapper for CUBLAS function.
 <pre>
 void
 cublasSrotm (int n, float *x, int incx, float *y, int incy,
              const float* sparam)

 applies the modified Givens transformation, h, to the 2 x n matrix

    ( transpose(x) )
    ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 to n-1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy. With sparam[0] = sflag, h has one of the following forms:

        sflag = -1.0f   sflag = 0.0f    sflag = 1.0f    sflag = -2.0f

        (sh00  sh01)    (1.0f  sh01)    (sh00  1.0f)    (1.0f  0.0f)
    h = (          )    (          )    (          )    (          )
        (sh10  sh11)    (sh10  1.0f)    (-1.0f sh11)    (0.0f  1.0f)

 Input
 -----
 n      number of elements in input vectors
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y
 sparam 5-element vector. sparam[0] is sflag described above. sparam[1]
        through sparam[4] contain the 2x2 rotation matrix h: sparam[1]
        contains sh00, sparam[2] contains sh10, sparam[3] contains sh01,
        and sprams[4] contains sh11.

 Output
 ------
 x     rotated vector x (unchanged if n <= 0)
 y     rotated vector y (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/srotm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSrotmg-float:A-float:A-float:A-float-float:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSrotmg</h4>
<pre>public static&nbsp;void&nbsp;cublasSrotmg(float[]&nbsp;sd1,
                                float[]&nbsp;sd2,
                                float[]&nbsp;sx1,
                                float&nbsp;sy1,
                                float[]&nbsp;sparam)</pre>
<div class="block">Wrapper for CUBLAS function.
 <pre>
 void
 cublasSrotmg (float *psd1, float *psd2, float *psx1, const float *psy1,
                float *sparam)

 constructs the modified Givens transformation matrix h which zeros
 the second component of the 2-vector transpose(sqrt(sd1)*sx1,sqrt(sd2)*sy1).
 With sparam[0] = sflag, h has one of the following forms:

        sflag = -1.0f   sflag = 0.0f    sflag = 1.0f    sflag = -2.0f

        (sh00  sh01)    (1.0f  sh01)    (sh00  1.0f)    (1.0f  0.0f)
    h = (          )    (          )    (          )    (          )
        (sh10  sh11)    (sh10  1.0f)    (-1.0f sh11)    (0.0f  1.0f)

 sparam[1] through sparam[4] contain sh00, sh10, sh01, sh11,
 respectively. Values of 1.0f, -1.0f, or 0.0f implied by the value
 of sflag are not stored in sparam.

 Input
 -----
 sd1    single precision scalar
 sd2    single precision scalar
 sx1    single precision scalar
 sy1    single precision scalar

 Output
 ------
 sd1    changed to represent the effect of the transformation
 sd2    changed to represent the effect of the transformation
 sx1    changed to represent the effect of the transformation
 sparam 5-element vector. sparam[0] is sflag described above. sparam[1]
        through sparam[4] contain the 2x2 rotation matrix h: sparam[1]
        contains sh00, sparam[2] contains sh10, sparam[3] contains sh01,
        and sprams[4] contains sh11.

 Reference: http://www.netlib.org/blas/srotmg.f

 This functions does not set any error status.
 </pre></div>
</li>
</ul>
<a name="cublasDrotm-int-jcuda.Pointer-int-jcuda.Pointer-int-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDrotm</h4>
<pre>public static&nbsp;void&nbsp;cublasDrotm(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               double[]&nbsp;sparam)</pre>
<div class="block">Wrapper for CUBLAS function.
 <pre>
 void
 cublasDrotm (int n, double *x, int incx, double *y, int incy,
              const double* sparam)

 applies the modified Givens transformation, h, to the 2 x n matrix

    ( transpose(x) )
    ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 to n-1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy. With sparam[0] = sflag, h has one of the following forms:

        sflag = -1.0    sflag = 0.0     sflag = 1.0     sflag = -2.0

        (sh00  sh01)    (1.0   sh01)    (sh00   1.0)    (1.0    0.0)
    h = (          )    (          )    (          )    (          )
        (sh10  sh11)    (sh10   1.0)    (-1.0  sh11)    (0.0    1.0)

 Input
 -----
 n      number of elements in input vectors
 x      double-precision vector with n elements
 incx   storage spacing between elements of x
 y      double-precision vector with n elements
 incy   storage spacing between elements of y
 sparam 5-element vector. sparam[0] is sflag described above. sparam[1]
        through sparam[4] contain the 2x2 rotation matrix h: sparam[1]
        contains sh00, sparam[2] contains sh10, sparam[3] contains sh01,
        and sprams[4] contains sh11.

 Output
 ------
 x     rotated vector x (unchanged if n <= 0)
 y     rotated vector y (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/drotm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDrotmg-double:A-double:A-double:A-double-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDrotmg</h4>
<pre>public static&nbsp;void&nbsp;cublasDrotmg(double[]&nbsp;sd1,
                                double[]&nbsp;sd2,
                                double[]&nbsp;sx1,
                                double&nbsp;sy1,
                                double[]&nbsp;sparam)</pre>
<div class="block">Wrapper for CUBLAS function.
 <pre>
 void
 cublasDrotmg (double *psd1, double *psd2, double *psx1, const double *psy1,
               double *sparam)

 constructs the modified Givens transformation matrix h which zeros
 the second component of the 2-vector transpose(sqrt(sd1)*sx1,sqrt(sd2)*sy1).
 With sparam[0] = sflag, h has one of the following forms:

        sflag = -1.0    sflag = 0.0     sflag = 1.0     sflag = -2.0

        (sh00  sh01)    (1.0   sh01)    (sh00   1.0)    (1.0    0.0)
    h = (          )    (          )    (          )    (          )
        (sh10  sh11)    (sh10   1.0)    (-1.0  sh11)    (0.0    1.0)

 sparam[1] through sparam[4] contain sh00, sh10, sh01, sh11,
 respectively. Values of 1.0, -1.0, or 0.0 implied by the value
 of sflag are not stored in sparam.

 Input
 -----
 sd1    single precision scalar
 sd2    single precision scalar
 sx1    single precision scalar
 sy1    single precision scalar

 Output
 ------
 sd1    changed to represent the effect of the transformation
 sd2    changed to represent the effect of the transformation
 sx1    changed to represent the effect of the transformation
 sparam 5-element vector. sparam[0] is sflag described above. sparam[1]
        through sparam[4] contain the 2x2 rotation matrix h: sparam[1]
        contains sh00, sparam[2] contains sh10, sparam[3] contains sh01,
        and sprams[4] contains sh11.

 Reference: http://www.netlib.org/blas/drotmg.f

 This functions does not set any error status.

 </pre></div>
</li>
</ul>
<a name="cublasIsamax-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIsamax</h4>
<pre>public static&nbsp;int&nbsp;cublasIsamax(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIsamax (int n, const float *x, int incx)

 finds the smallest index of the maximum magnitude element of single
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that maximizes abs(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      single precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/isamax.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIsamin-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIsamin</h4>
<pre>public static&nbsp;int&nbsp;cublasIsamin(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIsamin (int n, const float *x, int incx)

 finds the smallest index of the minimum magnitude element of single
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that minimizes abs(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      single precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/scilib/blass.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSasum-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSasum</h4>
<pre>public static&nbsp;float&nbsp;cublasSasum(int&nbsp;n,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                int&nbsp;incx)</pre>
<div class="block"><pre>
 float
 cublasSasum (int n, const float *x, int incx)

 computes the sum of the absolute values of the elements of single
 precision vector x; that is, the result is the sum from i = 0 to n - 1 of
 abs(x[1 + i * incx]).

 Input
 -----
 n      number of elements in input vector
 x      single precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the single precision sum of absolute values
 (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/sasum.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSaxpy-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSaxpy</h4>
<pre>public static&nbsp;void&nbsp;cublasSaxpy(int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSaxpy (int n, float alpha, const float *x, int incx, float *y,
              int incy)

 multiplies single precision vector x by single precision scalar alpha
 and adds the result to single precision vector y; that is, it overwrites
 single precision y with single precision alpha * x + y. For i = 0 to n - 1,
 it replaces y[ly + i * incy] with alpha * x[lx + i * incx] + y[ly + i *
 incy], where lx = 1 if incx >= 0, else lx = 1 +(1 - n) * incx, and ly is
 defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 alpha  single precision scalar multiplier
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      single precision result (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/saxpy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasScopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasScopy</h4>
<pre>public static&nbsp;void&nbsp;cublasScopy(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasScopy (int n, const float *x, int incx, float *y, int incy)

 copies the single precision vector x to the single precision vector y. For
 i = 0 to n-1, copies x[lx + i * incx] to y[ly + i * incy], where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a similar
 way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      contains single precision vector x

 Reference: http://www.netlib.org/blas/scopy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSdot-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSdot</h4>
<pre>public static&nbsp;float&nbsp;cublasSdot(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 float
 cublasSdot (int n, const float *x, int incx, const float *y, int incy)

 computes the dot product of two single precision vectors. It returns the
 dot product of the single precision vectors x and y if successful, and
 0.0f otherwise. It computes the sum for i = 0 to n - 1 of x[lx + i *
 incx] * y[ly + i * incy], where lx = 1 if incx >= 0, else lx = 1 + (1 - n)
 *incx, and ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns single precision dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/sdot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSnrm2-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSnrm2</h4>
<pre>public static&nbsp;float&nbsp;cublasSnrm2(int&nbsp;n,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                int&nbsp;incx)</pre>
<div class="block"><pre>
 float
 cublasSnrm2 (int n, const float *x, int incx)

 computes the Euclidean norm of the single precision n-vector x (with
 storage increment incx). This code uses a multiphase model of
 accumulation to avoid intermediate underflow and overflow.

 Input
 -----
 n      number of elements in input vector
 x      single precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns Euclidian norm (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/snrm2.f
 Reference: http://www.netlib.org/slatec/lin/snrm2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-float-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSrot</h4>
<pre>public static&nbsp;void&nbsp;cublasSrot(int&nbsp;n,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              float&nbsp;sc,
                              float&nbsp;ss)</pre>
<div class="block"><pre>
 void
 cublasSrot (int n, float *x, int incx, float *y, int incy, float sc,
             float ss)

 multiplies a 2x2 matrix ( sc ss) with the 2xn matrix ( transpose(x) )
                         (-ss sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y
 sc     element of rotation matrix
 ss     element of rotation matrix

 Output
 ------
 x      rotated vector x (unchanged if n <= 0)
 y      rotated vector y (unchanged if n <= 0)

 Reference  http://www.netlib.org/blas/srot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSrotg-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSrotg</h4>
<pre>public static&nbsp;void&nbsp;cublasSrotg(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sa,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sb,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ss)</pre>
<div class="block"><pre>
 void
 cublasSrotg (float *host_sa, float *host_sb, float *host_sc, float *host_ss)

 constructs the Givens tranformation

        ( sc  ss )
    G = (        ) ,  sc^2 + ss^2 = 1,
        (-ss  sc )

 which zeros the second entry of the 2-vector transpose(sa, sb).

 The quantity r = (+/-) sqrt (sa^2 + sb^2) overwrites sa in storage. The
 value of sb is overwritten by a value z which allows sc and ss to be
 recovered by the following algorithm:

    if z=1          set sc = 0.0 and ss = 1.0
    if abs(z) < 1   set sc = sqrt(1-z^2) and ss = z
    if abs(z) > 1   set sc = 1/z and ss = sqrt(1-sc^2)

 The function srot (n, x, incx, y, incy, sc, ss) normally is called next
 to apply the transformation to a 2 x n matrix.
 Note that is function is provided for completeness and run exclusively
 on the Host.

 Input
 -----
 sa     single precision scalar
 sb     single precision scalar

 Output
 ------
 sa     single precision r
 sb     single precision z
 sc     single precision result
 ss     single precision result

 Reference: http://www.netlib.org/blas/srotg.f

 This function does not set any error status.
 </pre></div>
</li>
</ul>
<a name="cublasSscal-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSscal</h4>
<pre>public static&nbsp;void&nbsp;cublasSscal(int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 sscal (int n, float alpha, float *x, int incx)

 replaces single precision vector x with single precision alpha * x. For i
 = 0 to n - 1, it replaces x[ix + i * incx] with alpha * x[ix + i * incx],
 where ix = 1 if incx >= 0, else ix = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vectors
 alpha  single precision scalar multiplier
 x      single precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      single precision result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/sscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSswap</h4>
<pre>public static&nbsp;void&nbsp;cublasSswap(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSswap (int n, float *x, int incx, float *y, int incy)

 interchanges the single-precision vector x with the single-precision vector y.
 For i = 0 to n-1, interchanges x[lx + i * incx] with y[ly + i * incy], where
 lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single precision vector with n elements
 incx   storage spacing between elements of x
 y      single precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 x      contains single precision vector y
 y      contains single precision vector x

 Reference: http://www.netlib.org/blas/sscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCaxpy-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCaxpy</h4>
<pre>public static&nbsp;void&nbsp;cublasCaxpy(int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasCaxpy (int n, cuComplex alpha, const cuComplex *x, int incx,
              cuComplex *y, int incy)

 multiplies single-complex vector x by single-complex scalar alpha and adds
 the result to single-complex vector y; that is, it overwrites single-complex
 y with single-complex alpha * x + y. For i = 0 to n - 1, it replaces
 y[ly + i * incy] with alpha * x[lx + i * incx] + y[ly + i * incy], where
 lx = 0 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 alpha  single-complex scalar multiplier
 x      single-complex vector with n elements
 incx   storage spacing between elements of x
 y      single-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      single-complex result (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/caxpy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCcopy</h4>
<pre>public static&nbsp;void&nbsp;cublasCcopy(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasCcopy (int n, const cuComplex *x, int incx, cuComplex *y, int incy)

 copies the single-complex vector x to the single-complex vector y. For
 i = 0 to n-1, copies x[lx + i * incx] to y[ly + i * incy], where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a similar
 way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-complex vector with n elements
 incx   storage spacing between elements of x
 y      single-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      contains single complex vector x

 Reference: http://www.netlib.org/blas/ccopy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZcopy</h4>
<pre>public static&nbsp;void&nbsp;cublasZcopy(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZcopy (int n, const cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy)

 copies the double-complex vector x to the double-complex vector y. For
 i = 0 to n-1, copies x[lx + i * incx] to y[ly + i * incy], where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a similar
 way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-complex vector with n elements
 incx   storage spacing between elements of x
 y      double-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      contains double complex vector x

 Reference: http://www.netlib.org/blas/zcopy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCscal-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCscal</h4>
<pre>public static&nbsp;void&nbsp;cublasCscal(int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCscal (int n, cuComplex alpha, cuComplex *x, int incx)

 replaces single-complex vector x with single-complex alpha * x. For i
 = 0 to n - 1, it replaces x[ix + i * incx] with alpha * x[ix + i * incx],
 where ix = 1 if incx >= 0, else ix = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vectors
 alpha  single-complex scalar multiplier
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      single-complex result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/cscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCrotg-jcuda.Pointer-jcuda.cuComplex-jcuda.Pointer-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCrotg</h4>
<pre>public static&nbsp;void&nbsp;cublasCrotg(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ca,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;cb,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_cs)</pre>
<div class="block"><pre>
 void
 cublasCrotg (cuComplex *host_ca, cuComplex cb, float *host_sc, cuComplex *host_cs)

 constructs the complex Givens tranformation

        ( sc  cs )
    G = (        ) ,  sc^2 + cabs(cs)^2 = 1,
        (-cs  sc )

 which zeros the second entry of the complex 2-vector transpose(ca, cb).

 The quantity ca/cabs(ca)*norm(ca,cb) overwrites ca in storage. The
 function crot (n, x, incx, y, incy, sc, cs) is normally called next
 to apply the transformation to a 2 x n matrix.
 Note that is function is provided for completeness and run exclusively
 on the Host.

 Input
 -----
 ca     single-precision complex precision scalar
 cb     single-precision complex scalar

 Output
 ------
 ca     single-precision complex ca/cabs(ca)*norm(ca,cb)
 sc     single-precision cosine component of rotation matrix
 cs     single-precision complex sine component of rotation matrix

 Reference: http://www.netlib.org/blas/crotg.f

 This function does not set any error status.
 </pre></div>
</li>
</ul>
<a name="cublasCrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.cuComplex-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCrot</h4>
<pre>public static&nbsp;void&nbsp;cublasCrot(int&nbsp;n,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              float&nbsp;c,
                              <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;s)</pre>
<div class="block"><pre>
 void
 cublasCrot (int n, cuComplex *x, int incx, cuComplex *y, int incy, float sc,
             cuComplex cs)

 multiplies a 2x2 matrix ( sc       cs) with the 2xn matrix ( transpose(x) )
                         (-conj(cs) sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-precision complex vector with n elements
 incx   storage spacing between elements of x
 y      single-precision complex vector with n elements
 incy   storage spacing between elements of y
 sc     single-precision cosine component of rotation matrix
 cs     single-precision complex sine component of rotation matrix

 Output
 ------
 x      rotated single-precision complex vector x (unchanged if n <= 0)
 y      rotated single-precision complex vector y (unchanged if n <= 0)

 Reference: http://netlib.org/lapack/explore-html/crot.f.html

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCsrot-int-jcuda.Pointer-int-jcuda.Pointer-int-float-float-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCsrot</h4>
<pre>public static&nbsp;void&nbsp;cublasCsrot(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               float&nbsp;c,
                               float&nbsp;s)</pre>
<div class="block"><pre>
 void
 csrot (int n, cuComplex *x, int incx, cuCumplex *y, int incy, float c,
        float s)

 multiplies a 2x2 rotation matrix ( c s) with a 2xn matrix ( transpose(x) )
                                  (-s c)                   ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-precision complex vector with n elements
 incx   storage spacing between elements of x
 y      single-precision complex vector with n elements
 incy   storage spacing between elements of y
 c      cosine component of rotation matrix
 s      sine component of rotation matrix

 Output
 ------
 x      rotated vector x (unchanged if n <= 0)
 y      rotated vector y (unchanged if n <= 0)

 Reference  http://www.netlib.org/blas/csrot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCsscal-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCsscal</h4>
<pre>public static&nbsp;void&nbsp;cublasCsscal(int&nbsp;n,
                                float&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCsscal (int n, float alpha, cuComplex *x, int incx)

 replaces single-complex vector x with single-complex alpha * x. For i
 = 0 to n - 1, it replaces x[ix + i * incx] with alpha * x[ix + i * incx],
 where ix = 1 if incx >= 0, else ix = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vectors
 alpha  single precision scalar multiplier
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      single-complex result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/csscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCswap</h4>
<pre>public static&nbsp;void&nbsp;cublasCswap(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasCswap (int n, const cuComplex *x, int incx, cuComplex *y, int incy)

 interchanges the single-complex vector x with the single-complex vector y.
 For i = 0 to n-1, interchanges x[lx + i * incx] with y[ly + i * incy], where
 lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-complex vector with n elements
 incx   storage spacing between elements of x
 y      single-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 x      contains-single complex vector y
 y      contains-single complex vector x

 Reference: http://www.netlib.org/blas/cswap.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZswap</h4>
<pre>public static&nbsp;void&nbsp;cublasZswap(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZswap (int n, const cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy)

 interchanges the double-complex vector x with the double-complex vector y.
 For i = 0 to n-1, interchanges x[lx + i * incx] with y[ly + i * incy], where
 lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-complex vector with n elements
 incx   storage spacing between elements of x
 y      double-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 x      contains-double complex vector y
 y      contains-double complex vector x

 Reference: http://www.netlib.org/blas/zswap.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCdotu-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCdotu</h4>
<pre>public static&nbsp;<a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;cublasCdotu(int&nbsp;n,
                                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                    int&nbsp;incx,
                                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                    int&nbsp;incy)</pre>
<div class="block"><pre>
 cuComplex
 cdotu (int n, const cuComplex *x, int incx, const cuComplex *y, int incy)

 computes the dot product of two single-complex vectors. It returns the
 dot product of the single-complex vectors x and y if successful, and complex
 zero otherwise. It computes the sum for i = 0 to n - 1 of x[lx + i * incx] *
 y[ly + i * incy], where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx;
 ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-complex vector with n elements
 incx   storage spacing between elements of x
 y      single-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns single-complex dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/cdotu.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCdotc-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCdotc</h4>
<pre>public static&nbsp;<a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;cublasCdotc(int&nbsp;n,
                                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                    int&nbsp;incx,
                                    <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                    int&nbsp;incy)</pre>
<div class="block"><pre>
 cuComplex
 cublasCdotc (int n, const cuComplex *x, int incx, const cuComplex *y,
              int incy)

 computes the dot product of two single-complex vectors. It returns the
 dot product of the single-complex vectors x and y if successful, and complex
 zero otherwise. It computes the sum for i = 0 to n - 1 of x[lx + i * incx] *
 y[ly + i * incy], where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx;
 ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      single-complex vector with n elements
 incx   storage spacing between elements of x
 y      single-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns single-complex dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/cdotc.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIcamax-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIcamax</h4>
<pre>public static&nbsp;int&nbsp;cublasIcamax(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIcamax (int n, const float *x, int incx)

 finds the smallest index of the element having maximum absolute value
 in single-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that maximizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/icamax.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIcamin-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIcamin</h4>
<pre>public static&nbsp;int&nbsp;cublasIcamin(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIcamin (int n, const float *x, int incx)

 finds the smallest index of the element having minimum absolute value
 in single-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that minimizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: see ICAMAX.

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasScasum-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasScasum</h4>
<pre>public static&nbsp;float&nbsp;cublasScasum(int&nbsp;n,
                                 <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                 int&nbsp;incx)</pre>
<div class="block"><pre>
 float
 cublasScasum (int n, const cuDouble *x, int incx)

 takes the sum of the absolute values of a complex vector and returns a
 single precision result. Note that this is not the L1 norm of the vector.
 The result is the sum from 0 to n-1 of abs(real(x[ix+i*incx])) +
 abs(imag(x(ix+i*incx))), where ix = 1 if incx <= 0, else ix = 1+(1-n)*incx.

 Input
 -----
 n      number of elements in input vector
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the single precision sum of absolute values of real and imaginary
 parts (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/scasum.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasScnrm2-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasScnrm2</h4>
<pre>public static&nbsp;float&nbsp;cublasScnrm2(int&nbsp;n,
                                 <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                 int&nbsp;incx)</pre>
<div class="block"><pre>
 float
 cublasScnrm2 (int n, const cuComplex *x, int incx)

 computes the Euclidean norm of the single-complex n-vector x. This code
 uses simple scaling to avoid intermediate underflow and overflow.

 Input
 -----
 n      number of elements in input vector
 x      single-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns Euclidian norm (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/scnrm2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZaxpy-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZaxpy</h4>
<pre>public static&nbsp;void&nbsp;cublasZaxpy(int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZaxpy (int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
              cuDoubleComplex *y, int incy)

 multiplies double-complex vector x by double-complex scalar alpha and adds
 the result to double-complex vector y; that is, it overwrites double-complex
 y with double-complex alpha * x + y. For i = 0 to n - 1, it replaces
 y[ly + i * incy] with alpha * x[lx + i * incx] + y[ly + i * incy], where
 lx = 0 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 alpha  double-complex scalar multiplier
 x      double-complex vector with n elements
 incx   storage spacing between elements of x
 y      double-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      double-complex result (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/zaxpy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZdotu-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZdotu</h4>
<pre>public static&nbsp;<a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cublasZdotu(int&nbsp;n,
                                          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                          int&nbsp;incx,
                                          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                          int&nbsp;incy)</pre>
<div class="block"><pre>
 cuDoubleComplex
 zdotu (int n, const cuDoubleComplex *x, int incx, const cuDoubleComplex *y, int incy)

 computes the dot product of two double-complex vectors. It returns the
 dot product of the double-complex vectors x and y if successful, and double-complex
 zero otherwise. It computes the sum for i = 0 to n - 1 of x[lx + i * incx] *
 y[ly + i * incy], where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx;
 ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-complex vector with n elements
 incx   storage spacing between elements of x
 y      double-complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns double-complex dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/zdotu.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZdotc-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZdotc</h4>
<pre>public static&nbsp;<a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cublasZdotc(int&nbsp;n,
                                          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                          int&nbsp;incx,
                                          <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                          int&nbsp;incy)</pre>
<div class="block"><pre>
 cuDoubleComplex
 cublasZdotc (int n, const cuDoubleComplex *x, int incx, const cuDoubleComplex *y, int incy)

 computes the dot product of two double-precision complex vectors. It returns the
 dot product of the double-precision complex vectors conjugate(x) and y if successful,
 and double-precision complex zero otherwise. It computes the
 sum for i = 0 to n - 1 of conjugate(x[lx + i * incx]) *  y[ly + i * incy],
 where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx;
 ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision complex vector with n elements
 incx   storage spacing between elements of x
 y      double-precision complex vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns double-complex dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/zdotc.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZscal-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZscal</h4>
<pre>public static&nbsp;void&nbsp;cublasZscal(int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZscal (int n, cuComplex alpha, cuComplex *x, int incx)

 replaces double-complex vector x with double-complex alpha * x. For i
 = 0 to n - 1, it replaces x[ix + i * incx] with alpha * x[ix + i * incx],
 where ix = 1 if incx >= 0, else ix = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vectors
 alpha  double-complex scalar multiplier
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      double-complex result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/zscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZdscal-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZdscal</h4>
<pre>public static&nbsp;void&nbsp;cublasZdscal(int&nbsp;n,
                                double&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZdscal (int n, double alpha, cuDoubleComplex *x, int incx)

 replaces double-complex vector x with double-complex alpha * x. For i
 = 0 to n - 1, it replaces x[ix + i * incx] with alpha * x[ix + i * incx],
 where ix = 1 if incx >= 0, else ix = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vectors
 alpha  double precision scalar multiplier
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      double-complex result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/zdscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDznrm2-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDznrm2</h4>
<pre>public static&nbsp;double&nbsp;cublasDznrm2(int&nbsp;n,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx)</pre>
<div class="block"><pre>
 double
 cublasDznrm2 (int n, const cuDoubleComplex *x, int incx)

 computes the Euclidean norm of the double precision complex n-vector x. This code
 uses simple scaling to avoid intermediate underflow and overflow.

 Input
 -----
 n      number of elements in input vector
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns Euclidian norm (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/dznrm2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZrotg-jcuda.Pointer-jcuda.cuDoubleComplex-jcuda.Pointer-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZrotg</h4>
<pre>public static&nbsp;void&nbsp;cublasZrotg(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ca,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cb,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_cs)</pre>
<div class="block"><pre>
 void
 cublasZrotg (cuDoubleComplex *host_ca, cuDoubleComplex cb, double *host_sc, double *host_cs)

 constructs the complex Givens tranformation

        ( sc  cs )
    G = (        ) ,  sc^2 + cabs(cs)^2 = 1,
        (-cs  sc )

 which zeros the second entry of the complex 2-vector transpose(ca, cb).

 The quantity ca/cabs(ca)*norm(ca,cb) overwrites ca in storage. The
 function crot (n, x, incx, y, incy, sc, cs) is normally called next
 to apply the transformation to a 2 x n matrix.
 Note that is function is provided for completeness and run exclusively
 on the Host.

 Input
 -----
 ca     double-precision complex precision scalar
 cb     double-precision complex scalar

 Output
 ------
 ca     double-precision complex ca/cabs(ca)*norm(ca,cb)
 sc     double-precision cosine component of rotation matrix
 cs     double-precision complex sine component of rotation matrix

 Reference: http://www.netlib.org/blas/zrotg.f

 This function does not set any error status.
 </pre></div>
</li>
</ul>
<a name="cublasZrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.cuDoubleComplex-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZrot</h4>
<pre>public static&nbsp;void&nbsp;cublasZrot(int&nbsp;n,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              double&nbsp;sc,
                              <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;cs)</pre>
<div class="block"><pre>
 cublasZrot (int n, cuDoubleComplex *x, int incx, cuDoubleComplex *y, int incy, double sc,
             cuDoubleComplex cs)

 multiplies a 2x2 matrix ( sc       cs) with the 2xn matrix ( transpose(x) )
                         (-conj(cs) sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision complex vector with n elements
 incx   storage spacing between elements of x
 y      double-precision complex vector with n elements
 incy   storage spacing between elements of y
 sc     double-precision cosine component of rotation matrix
 cs     double-precision complex sine component of rotation matrix

 Output
 ------
 x      rotated double-precision complex vector x (unchanged if n <= 0)
 y      rotated double-precision complex vector y (unchanged if n <= 0)

 Reference: http://netlib.org/lapack/explore-html/zrot.f.html

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZdrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZdrot</h4>
<pre>public static&nbsp;void&nbsp;cublasZdrot(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               double&nbsp;c,
                               double&nbsp;s)</pre>
<div class="block"><pre>
 void
 zdrot (int n, cuDoubleComplex *x, int incx, cuCumplex *y, int incy, double c,
        double s)

 multiplies a 2x2 matrix ( c s) with the 2xn matrix ( transpose(x) )
                         (-s c)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision complex vector with n elements
 incx   storage spacing between elements of x
 y      double-precision complex vector with n elements
 incy   storage spacing between elements of y
 c      cosine component of rotation matrix
 s      sine component of rotation matrix

 Output
 ------
 x      rotated vector x (unchanged if n <= 0)
 y      rotated vector y (unchanged if n <= 0)

 Reference  http://www.netlib.org/blas/zdrot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIzamax-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIzamax</h4>
<pre>public static&nbsp;int&nbsp;cublasIzamax(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIzamax (int n, const double *x, int incx)

 finds the smallest index of the element having maximum absolute value
 in double-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that maximizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/izamax.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIzamin-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIzamin</h4>
<pre>public static&nbsp;int&nbsp;cublasIzamin(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 cublasIzamin (int n, const cuDoubleComplex *x, int incx)

 finds the smallest index of the element having minimum absolute value
 in double-complex vector x; that is, the result is the first i, i = 0
 to n - 1 that minimizes abs(real(x[1+i*incx]))+abs(imag(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: Analogous to IZAMAX, see there.

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDzasum-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDzasum</h4>
<pre>public static&nbsp;double&nbsp;cublasDzasum(int&nbsp;n,
                                  <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                  int&nbsp;incx)</pre>
<div class="block"><pre>
 double
 cublasDzasum (int n, const cuDoubleComplex *x, int incx)

 takes the sum of the absolute values of a complex vector and returns a
 double precision result. Note that this is not the L1 norm of the vector.
 The result is the sum from 0 to n-1 of abs(real(x[ix+i*incx])) +
 abs(imag(x(ix+i*incx))), where ix = 1 if incx <= 0, else ix = 1+(1-n)*incx.

 Input
 -----
 n      number of elements in input vector
 x      double-complex vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the double precision sum of absolute values of real and imaginary
 parts (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/dzasum.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSgbmv-char-int-int-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSgbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasSgbmv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;kl,
                               int&nbsp;ku,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSgbmv (char trans, int m, int n, int kl, int ku, float alpha,
              const float *A, int lda, const float *x, int incx, float beta,
              float *y, int incy)

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are single precision scalars. x and y are single precision
 vectors. A is an m by n band matrix consisting of single precision elements
 with kl sub-diagonals and ku super-diagonals.

 Input
 -----
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 kl     specifies the number of sub-diagonals of matrix A. It must be at
        least zero.
 ku     specifies the number of super-diagonals of matrix A. It must be at
        least zero.
 alpha  single precision scalar multiplier applied to op(A).
 A      single precision array of dimensions (lda, n). The leading
        (kl + ku + 1) x n part of the array A must contain the band matrix A,
        supplied column by column, with the leading diagonal of the matrix
        in row (ku + 1) of the array, the first super-diagonal starting at
        position 2 in row ku, the first sub-diagonal starting at position 1
        in row (ku + 2), and so on. Elements in the array A that do not
        correspond to elements in the band matrix (such as the top left
        ku x ku triangle) are not referenced.
 lda    leading dimension of A. lda must be at least (kl + ku + 1).
 x      single precision array of length at least (1+(n-1)*abs(incx)) when
        trans == 'N' or 'n' and at least (1+(m-1)*abs(incx)) otherwise.
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      single precision array of length at least (1+(m-1)*abs(incy)) when
        trans == 'N' or 'n' and at least (1+(n-1)*abs(incy)) otherwise. If
        beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*op(A)*x + beta*y

 Reference: http://www.netlib.org/blas/sgbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n, kl, or ku < 0; if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSgemv-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSgemv</h4>
<pre>public static&nbsp;void&nbsp;cublasSgemv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 cublasSgemv (char trans, int m, int n, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are single precision scalars, x and y are single
 precision vectors, and A is an m x n matrix consisting of single precision
 elements. Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array in which A is stored.

 Input
 -----
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If trans =
        trans = 't', 'T', 'c', or 'C', op(A) = transpose(A)
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 alpha  single precision scalar multiplier applied to op(A).
 A      single precision array of dimensions (lda, n) if trans = 'n' or
        'N'), and of dimensions (lda, m) otherwise. lda must be at least
        max(1, m) and at least max(1, n) otherwise.
 lda    leading dimension of two-dimensional array used to store matrix A
 x      single precision array of length at least (1 + (n - 1) * abs(incx))
        when trans = 'N' or 'n' and at least (1 + (m - 1) * abs(incx))
        otherwise.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 beta   single precision scalar multiplier applied to vector y. If beta
        is zero, y is not read.
 y      single precision array of length at least (1 + (m - 1) * abs(incy))
        when trans = 'N' or 'n' and at least (1 + (n - 1) * abs(incy))
        otherwise.
 incy   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 y      updated according to alpha * op(A) * x + beta * y

 Reference: http://www.netlib.org/blas/sgemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSger-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSger</h4>
<pre>public static&nbsp;void&nbsp;cublasSger(int&nbsp;m,
                              int&nbsp;n,
                              float&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasSger (int m, int n, float alpha, const float *x, int incx,
             const float *y, int incy, float *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a single precision scalar, x is an m element single
 precision vector, y is an n element single precision vector, and A
 is an m by n matrix consisting of single precision elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  single precision scalar multiplier applied to x * transpose(y)
 x      single precision array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      single precision array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      single precision array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * transpose(y) + A

 Reference: http://www.netlib.org/blas/sger.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsbmv-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasSsbmv(char&nbsp;uplo,
                               int&nbsp;n,
                               int&nbsp;k,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSsbmv (char uplo, int n, int k, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are single precision scalars. x and y are single precision
 vectors with n elements. A is an n x n symmetric band matrix consisting
 of single precision elements, with k super-diagonals and the same number
 of sub-diagonals.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the symmetric
        band matrix A is being supplied. If uplo == 'U' or 'u', the upper
        triangular part is being supplied. If uplo == 'L' or 'l', the lower
        triangular part is being supplied.
 n      specifies the number of rows and the number of columns of the
        symmetric matrix A. n must be at least zero.
 k      specifies the number of super-diagonals of matrix A. Since the matrix
        is symmetric, this is also the number of sub-diagonals. k must be at
        least zero.
 alpha  single precision scalar multiplier applied to A*x.
 A      single precision array of dimensions (lda, n). When uplo == 'U' or
        'u', the leading (k + 1) x n part of array A must contain the upper
        triangular band of the symmetric matrix, supplied column by column,
        with the leading diagonal of the matrix in row (k+1) of the array,
        the first super-diagonal starting at position 2 in row k, and so on.
        The top left k x k triangle of the array A is not referenced. When
        uplo == 'L' or 'l', the leading (k + 1) x n part of the array A must
        contain the lower triangular band part of the symmetric matrix,
        supplied column by column, with the leading diagonal of the matrix in
        row 1 of the array, the first sub-diagonal starting at position 1 in
        row 2, and so on. The bottom right k x k triangle of the array A is
        not referenced.
 lda    leading dimension of A. lda must be at least (k + 1).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      single precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/ssbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_INVALID_VALUE    if k or n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSspmv-char-int-float-jcuda.Pointer-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSspmv</h4>
<pre>public static&nbsp;void&nbsp;cublasSspmv(char&nbsp;uplo,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSspmv (char uplo, int n, float alpha, const float *AP, const float *x,
              int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are single precision scalars, and x and y are single
 precision vectors with n elements. A is a symmetric n x n matrix
 consisting of single precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision scalar multiplier applied to A*x.
 AP     single precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision scalar multiplier applied to vector y;
 y      single precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/sspmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSspr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSspr</h4>
<pre>public static&nbsp;void&nbsp;cublasSspr(char&nbsp;uplo,
                              int&nbsp;n,
                              float&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasSspr (char uplo, int n, float alpha, const float *x, int incx,
             float *AP)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a single precision scalar and x is an n element single
 precision vector. A is a symmetric n x n matrix consisting of single
 precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision scalar multiplier applied to x * transpose(x).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 AP     single precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].

 Output
 ------
 A      updated according to A = alpha * x * transpose(x) + A

 Reference: http://www.netlib.org/blas/sspr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSspr2-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSspr2</h4>
<pre>public static&nbsp;void&nbsp;cublasSspr2(char&nbsp;uplo,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasSspr2 (char uplo, int n, float alpha, const float *x, int incx,
              const float *y, int incy, float *AP)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a single precision scalar, and x and y are n element single
 precision vectors. A is a symmetric n x n matrix consisting of single
 precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision scalar multiplier applied to x * transpose(y) +
        y * transpose(x).
 x      single precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      single precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 AP     single precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].

 Output
 ------
 A      updated according to A = alpha*x*transpose(y)+alpha*y*transpose(x)+A

 Reference: http://www.netlib.org/blas/sspr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsymv-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsymv</h4>
<pre>public static&nbsp;void&nbsp;cublasSsymv(char&nbsp;uplo,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasSsymv (char uplo, int n, float alpha, const float *A, int lda,
              const float *x, int incx, float beta, float *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are single precision scalars, and x and y are single
 precision vectors, each with n elements. A is a symmetric n x n matrix
 consisting of single precision elements that is stored in either upper or
 lower storage mode.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the array A
        is to be referenced. If uplo == 'U' or 'u', the symmetric matrix A
        is stored in upper storage mode, i.e. only the upper triangular part
        of A is to be referenced while the lower triangular part of A is to
        be inferred. If uplo == 'L' or 'l', the symmetric matrix A is stored
        in lower storage mode, i.e. only the lower triangular part of A is
        to be referenced while the upper triangular part of A is to be
        inferred.
 n      specifies the number of rows and the number of columns of the
        symmetric matrix A. n must be at least zero.
 alpha  single precision scalar multiplier applied to A*x.
 A      single precision array of dimensions (lda, n). If uplo == 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular part of the symmetric matrix and the strictly
        lower triangular part of A is not referenced. If uplo == 'L' or 'l',
        the leading n x n lower triangular part of the array A must contain
        the lower triangular part of the symmetric matrix and the strictly
        upper triangular part of A is not referenced.
 lda    leading dimension of A. It must be at least max (1, n).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision scalar multiplier applied to vector y.
 y      single precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/ssymv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsyr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsyr</h4>
<pre>public static&nbsp;void&nbsp;cublasSsyr(char&nbsp;uplo,
                              int&nbsp;n,
                              float&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 void
 cublasSsyr (char uplo, int n, float alpha, const float *x, int incx,
             float *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a single precision scalar, x is an n element single
 precision vector and A is an n x n symmetric matrix consisting of
 single precision elements. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array
 containing A.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or
        the lower triangular part of array A. If uplo = 'U' or 'u',
        then only the upper triangular part of A may be referenced.
        If uplo = 'L' or 'l', then only the lower triangular part of
        A may be referenced.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 alpha  single precision scalar multiplier applied to x * transpose(x)
 x      single precision array of length at least (1 + (n - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must
        not be zero.
 A      single precision array of dimensions (lda, n). If uplo = 'U' or
        'u', then A must contain the upper triangular part of a symmetric
        matrix, and the strictly lower triangular part is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part
        of a symmetric matrix, and the strictly upper triangular part is
        not referenced.
 lda    leading dimension of the two-dimensional array containing A. lda
        must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha * x * transpose(x) + A

 Reference: http://www.netlib.org/blas/ssyr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsyr2-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsyr2</h4>
<pre>public static&nbsp;void&nbsp;cublasSsyr2(char&nbsp;uplo,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 void
 cublasSsyr2 (char uplo, int n, float alpha, const float *x, int incx,
              const float *y, int incy, float *A, int lda)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a single precision scalar, x and y are n element single
 precision vector and A is an n by n symmetric matrix consisting of single
 precision elements.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision scalar multiplier applied to x * transpose(y) +
        y * transpose(x).
 x      single precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      single precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 A      single precision array of dimensions (lda, n). If uplo == 'U' or 'u',
        then A must contains the upper triangular part of a symmetric matrix,
        and the strictly lower triangular parts is not referenced. If uplo ==
        'L' or 'l', then A contains the lower triangular part of a symmetric
        matrix, and the strictly upper triangular part is not referenced.
 lda    leading dimension of A. It must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha*x*transpose(y)+alpha*y*transpose(x)+A

 Reference: http://www.netlib.org/blas/ssyr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasStbmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasStbmv (char uplo, char trans, char diag, int n, int k, const float *A,
              int lda, float *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A
 or op(A) = transpose(A). x is an n-element single precision vector, and A is
 an n x n, unit or non-unit upper or lower triangular band matrix consisting
 of single precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular band
        matrix. If uplo == 'U' or 'u', A is an upper triangular band matrix.
        If uplo == 'L' or 'l', A is a lower triangular band matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A).
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero. In the current implementation n must not exceed 4070.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      single precision array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first
        super-diagonal starting at position 2 in row k, and so on. The top
        left k x k triangle of the array A is not referenced. If uplo == 'L'
        or 'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal startingat position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 lda    is the leading dimension of A. It must be at least (k + 1).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x

 Reference: http://www.netlib.org/blas/stbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, k < 0, or incx == 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStbsv</h4>
<pre>public static&nbsp;void&nbsp;cublasStbsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void cublasStbsv (char uplo, char trans, char diag, int n, int k,
                   const float *A, int lda, float *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A). b and x are n-element vectors, and A is
 an n x n unit or non-unit, upper or lower triangular band matrix with k + 1
 diagonals. No test for singularity or near-singularity is included in this
 function. Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular band
        matrix as follows: If uplo == 'U' or 'u', A is an upper triangular
        band matrix. If uplo == 'L' or 'l', A is a lower triangular band
        matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must be at least
        zero.
 A      single precision array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first super-
        diagonal starting at position 2 in row k, and so on. The top left
        k x k triangle of the array A is not referenced. If uplo == 'L' or
        'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal starting at position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n-element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   storage spacing between elements of x. incx must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/stbsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0, n < 0 or n > 4070
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStpmv</h4>
<pre>public static&nbsp;void&nbsp;cublasStpmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasStpmv (char uplo, char trans, char diag, int n, const float *AP,
              float *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A). x is an n element single precision vector, and A
 is an n x n, unit or non-unit, upper or lower triangular matrix composed
 of single precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo == 'U' or 'u', then A is an upper triangular matrix.
        If uplo == 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 AP     single precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored in AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/stpmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStpsv</h4>
<pre>public static&nbsp;void&nbsp;cublasStpsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasStpsv (char uplo, char trans, char diag, int n, const float *AP,
              float *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A). b and x are n element vectors, and A is
 an n x n unit or non-unit, upper or lower triangular matrix. No test for
 singularity or near-singularity is included in this function. Such tests
 must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular matrix
        as follows: If uplo == 'U' or 'u', A is an upper triangluar matrix.
        If uplo == 'L' or 'l', A is a lower triangular matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero. In the current implementation n must not exceed 4070.
 AP     single precision array with at least ((n*(n+1))/2) elements. If uplo
        == 'U' or 'u', the array AP contains the upper triangular matrix A,
        packed sequentially, column by column; that is, if i <= j, then
        A[i,j] is stored is AP[i+(j*(j+1)/2)]. If uplo == 'L' or 'L', the
        array AP contains the lower triangular matrix A, packed sequentially,
        column by column; that is, if i >= j, then A[i,j] is stored in
        AP[i+((2*n-j+1)*j)/2]. When diag = 'U' or 'u', the diagonal elements
        of A are not referenced and are assumed to be unity.
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n-element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/stpsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0, n < 0, or n > 4070
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStrmv</h4>
<pre>public static&nbsp;void&nbsp;cublasStrmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasStrmv (char uplo, char trans, char diag, int n, const float *A,
              int lda, float *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) =
     = A, or op(A) = transpose(A). x is an n-element single precision vector, and
 A is an n x n, unit or non-unit, upper or lower, triangular matrix composed
 of single precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', then A is an upper triangular matrix.
        If uplo = 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa = 'N' or 'n', op(A) = A. If trans = 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 diag   specifies whether or not matrix A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 A      single precision array of dimension (lda, n). If uplo = 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular matrix and the strictly lower triangular part
        of A is not referenced. If uplo = 'L' or 'l', the leading n x n lower
        triangular part of the array A must contain the lower triangular
        matrix and the strictly upper triangular part of A is not referenced.
        When diag = 'U' or 'u', the diagonal elements of A are not referenced
        either, but are are assumed to be unity.
 lda    is the leading dimension of A. It must be at least max (1, n).
 x      single precision array of length at least (1 + (n - 1) * abs(incx) ).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/strmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStrsv</h4>
<pre>public static&nbsp;void&nbsp;cublasStrsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasStrsv (char uplo, char trans, char diag, int n, const float *A,
              int lda, float *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A or
 transpose(A). b and x are single precision vectors consisting of n
 elements, and A is an n x n matrix composed of a unit or non-unit, upper
 or lower triangular matrix. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array containing
 A.

 No test for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the
        lower triangular part of array A. If uplo = 'U' or 'u', then only
        the upper triangular part of A may be referenced. If uplo = 'L' or
        'l', then only the lower triangular part of A may be referenced.
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If transa = 't',
        'T', 'c', or 'C', op(A) = transpose(A)
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 A      is a single precision array of dimensions (lda, n). If uplo = 'U'
        or 'u', then A must contains the upper triangular part of a symmetric
        matrix, and the strictly lower triangular parts is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part of
        a symmetric matrix, and the strictly upper triangular part is not
        referenced.
 lda    is the leading dimension of the two-dimensional array containing A.
        lda must be at least max(1, n).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/strsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtrmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtrmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZtrmv (char uplo, char trans, char diag, int n, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x,
 where op(A) = A, or op(A) = transpose(A) or op(A) = conjugate(transpose(A)).
 x is an n-element double precision complex vector, and
 A is an n x n, unit or non-unit, upper or lower, triangular matrix composed
 of double precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', then A is an upper triangular matrix.
        If uplo = 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If trans = 'n' or 'N', op(A) = A. If trans = 't' or
        'T', op(A) = transpose(A).  If trans = 'c' or 'C', op(A) =
        conjugate(transpose(A)).
 diag   specifies whether or not matrix A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 A      double precision array of dimension (lda, n). If uplo = 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular matrix and the strictly lower triangular part
        of A is not referenced. If uplo = 'L' or 'l', the leading n x n lower
        triangular part of the array A must contain the lower triangular
        matrix and the strictly upper triangular part of A is not referenced.
        When diag = 'U' or 'u', the diagonal elements of A are not referenced
        either, but are are assumed to be unity.
 lda    is the leading dimension of A. It must be at least max (1, n).
 x      double precision array of length at least (1 + (n - 1) * abs(incx) ).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/ztrmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZgbmv-char-int-int-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZgbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZgbmv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;kl,
                               int&nbsp;ku,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZgbmv (char trans, int m, int n, int kl, int ku, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *x, int incx, cuDoubleComplex beta,
              cuDoubleComplex *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are double precision complex scalars. x and y are double precision
 complex vectors. A is an m by n band matrix consisting of double precision complex elements
 with kl sub-diagonals and ku super-diagonals.

 Input
 -----
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 kl     specifies the number of sub-diagonals of matrix A. It must be at
        least zero.
 ku     specifies the number of super-diagonals of matrix A. It must be at
        least zero.
 alpha  double precision complex scalar multiplier applied to op(A).
 A      double precision complex array of dimensions (lda, n). The leading
        (kl + ku + 1) x n part of the array A must contain the band matrix A,
        supplied column by column, with the leading diagonal of the matrix
        in row (ku + 1) of the array, the first super-diagonal starting at
        position 2 in row ku, the first sub-diagonal starting at position 1
        in row (ku + 2), and so on. Elements in the array A that do not
        correspond to elements in the band matrix (such as the top left
        ku x ku triangle) are not referenced.
 lda    leading dimension of A. lda must be at least (kl + ku + 1).
 x      double precision complex array of length at least (1+(n-1)*abs(incx)) when
        trans == 'N' or 'n' and at least (1+(m-1)*abs(incx)) otherwise.
 incx   specifies the increment for the elements of x. incx must not be zero.
 beta   double precision complex scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      double precision complex array of length at least (1+(m-1)*abs(incy)) when
        trans == 'N' or 'n' and at least (1+(n-1)*abs(incy)) otherwise. If
        beta is zero, y is not read.
 incy   On entry, incy specifies the increment for the elements of y. incy
        must not be zero.

 Output
 ------
 y      updated according to y = alpha*op(A)*x + beta*y

 Reference: http://www.netlib.org/blas/zgbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtbmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZtbmv (char uplo, char trans, char diag, int n, int k, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)). x is an n-element
 double precision complex vector, and A is an n x n, unit or non-unit, upper
 or lower triangular band matrix composed of double precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular band
        matrix. If uplo == 'U' or 'u', A is an upper triangular band matrix.
        If uplo == 'L' or 'l', A is a lower triangular band matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      double precision complex array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first
        super-diagonal starting at position 2 in row k, and so on. The top
        left k x k triangle of the array A is not referenced. If uplo == 'L'
        or 'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal startingat position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 lda    is the leading dimension of A. It must be at least (k + 1).
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x

 Reference: http://www.netlib.org/blas/ztbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n or k < 0, or if incx == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtbsv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtbsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void cublasZtbsv (char uplo, char trans, char diag, int n, int k,
                   const cuDoubleComplex *A, int lda, cuDoubleComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose(A)).
 b and x are n element vectors, and A is an n x n unit or non-unit,
 upper or lower triangular band matrix with k + 1 diagonals. No test
 for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular band
        matrix as follows: If uplo == 'U' or 'u', A is an upper triangular
        band matrix. If uplo == 'L' or 'l', A is a lower triangular band
        matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      double precision complex array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first super-
        diagonal starting at position 2 in row k, and so on. The top left
        k x k triangle of the array A is not referenced. If uplo == 'L' or
        'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal starting at position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 x      double precision complex array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ztbsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0, n < 0 or n > 1016
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhemv-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZhemv</h4>
<pre>public static&nbsp;void&nbsp;cublasZhemv(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZhemv (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are double precision complex scalars, and x and y are double
 precision complex vectors, each with n elements. A is a hermitian n x n matrix
 consisting of double precision complex elements that is stored in either upper or
 lower storage mode.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the array A
        is to be referenced. If uplo == 'U' or 'u', the hermitian matrix A
        is stored in upper storage mode, i.e. only the upper triangular part
        of A is to be referenced while the lower triangular part of A is to
        be inferred. If uplo == 'L' or 'l', the hermitian matrix A is stored
        in lower storage mode, i.e. only the lower triangular part of A is
        to be referenced while the upper triangular part of A is to be
        inferred.
 n      specifies the number of rows and the number of columns of the
        hermitian matrix A. n must be at least zero.
 alpha  double precision complex scalar multiplier applied to A*x.
 A      double precision complex array of dimensions (lda, n). If uplo == 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular part of the hermitian matrix and the strictly
        lower triangular part of A is not referenced. If uplo == 'L' or 'l',
        the leading n x n lower triangular part of the array A must contain
        the lower triangular part of the hermitian matrix and the strictly
        upper triangular part of A is not referenced. The imaginary parts
        of the diagonal elements need not be set, they are assumed to be zero.
 lda    leading dimension of A. It must be at least max (1, n).
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision complex scalar multiplier applied to vector y.
 y      double precision complex array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/zhemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhpmv-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZhpmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZhpmv(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZhpmv (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *AP, const cuDoubleComplex *x,
              int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are double precision complex scalars, and x and y are double
 precision complex vectors with n elements. A is an hermitian n x n matrix
 consisting of double precision complex elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision complex scalar multiplier applied to A*x.
 AP     double precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
        The imaginary parts of the diagonal elements need not be set, they
        are assumed to be zero.
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision complex scalar multiplier applied to vector y;
 y      double precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/zhpmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZgemv-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZgemv</h4>
<pre>public static&nbsp;void&nbsp;cublasZgemv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 cublasZgemv (char trans, int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are double precision scalars, x and y are double
 precision vectors, and A is an m x n matrix consisting of double precision
 elements. Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array in which A is stored.

 Input
 -----
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If trans =
        trans = 't', 'T', 'c', or 'C', op(A) = transpose(A)
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 alpha  double precision scalar multiplier applied to op(A).
 A      double precision array of dimensions (lda, n) if trans = 'n' or
        'N'), and of dimensions (lda, m) otherwise. lda must be at least
        max(1, m) and at least max(1, n) otherwise.
 lda    leading dimension of two-dimensional array used to store matrix A
 x      double precision array of length at least (1 + (n - 1) * abs(incx))
        when trans = 'N' or 'n' and at least (1 + (m - 1) * abs(incx))
        otherwise.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 beta   double precision scalar multiplier applied to vector y. If beta
        is zero, y is not read.
 y      double precision array of length at least (1 + (m - 1) * abs(incy))
        when trans = 'N' or 'n' and at least (1 + (n - 1) * abs(incy))
        otherwise.
 incy   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 y      updated according to alpha * op(A) * x + beta * y

 Reference: http://www.netlib.org/blas/zgemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtpmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtpmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZtpmv (char uplo, char trans, char diag, int n, const cuDoubleComplex *AP,
              cuDoubleComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)) . x is an n element
 double precision complex vector, and A is an n x n, unit or non-unit, upper
 or lower triangular matrix composed of double precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo == 'U' or 'u', then A is an upper triangular matrix.
        If uplo == 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).

 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero. In the current implementation n must not exceed 4070.
 AP     double precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored in AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/ztpmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or n < 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtpsv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtpsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZtpsv (char uplo, char trans, char diag, int n, const cuDoubleComplex *AP,
              cuDoubleComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose)). b and
 x are n element complex vectors, and A is an n x n unit or non-unit,
 upper or lower triangular matrix. No test for singularity or near-singularity
 is included in this routine. Such tests must be performed before calling this routine.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular matrix
        as follows: If uplo == 'U' or 'u', A is an upper triangluar matrix.
        If uplo == 'L' or 'l', A is a lower triangular matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T'
        or 't', op(A) = transpose(A). If trans == 'C' or 'c', op(A) =
        conjugate(transpose(A)).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 AP     double precision complex array with at least ((n*(n+1))/2) elements.
        If uplo == 'U' or 'u', the array AP contains the upper triangular
        matrix A, packed sequentially, column by column; that is, if i <= j, then
        A[i,j] is stored is AP[i+(j*(j+1)/2)]. If uplo == 'L' or 'L', the
        array AP contains the lower triangular matrix A, packed sequentially,
        column by column; that is, if i >= j, then A[i,j] is stored in
        AP[i+((2*n-j+1)*j)/2]. When diag = 'U' or 'u', the diagonal elements
        of A are not referenced and are assumed to be unity.
 x      double precision complex array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ztpsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0 or n > 2035
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCgemv-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCgemv</h4>
<pre>public static&nbsp;void&nbsp;cublasCgemv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 cublasCgemv (char trans, int m, int n, cuComplex alpha, const cuComplex *A,
              int lda, const cuComplex *x, int incx, cuComplex beta, cuComplex *y,
              int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A) or op(A) = conjugate(transpose(A))

 where alpha and beta are single precision scalars, x and y are single
 precision vectors, and A is an m x n matrix consisting of single precision
 elements. Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array in which A is stored.

 Input
 -----
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If trans =
        trans = 't' or 'T', op(A) = transpose(A). If trans = 'c' or 'C',
        op(A) = conjugate(transpose(A))
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 alpha  single precision scalar multiplier applied to op(A).
 A      single precision array of dimensions (lda, n) if trans = 'n' or
        'N'), and of dimensions (lda, m) otherwise. lda must be at least
        max(1, m) and at least max(1, n) otherwise.
 lda    leading dimension of two-dimensional array used to store matrix A
 x      single precision array of length at least (1 + (n - 1) * abs(incx))
        when trans = 'N' or 'n' and at least (1 + (m - 1) * abs(incx))
        otherwise.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 beta   single precision scalar multiplier applied to vector y. If beta
        is zero, y is not read.
 y      single precision array of length at least (1 + (m - 1) * abs(incy))
        when trans = 'N' or 'n' and at least (1 + (n - 1) * abs(incy))
        otherwise.
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.

 Output
 ------
 y      updated according to alpha * op(A) * x + beta * y

 Reference: http://www.netlib.org/blas/cgemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCgbmv-char-int-int-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCgbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasCgbmv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;kl,
                               int&nbsp;ku,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasCgbmv (char trans, int m, int n, int kl, int ku, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *x, int incx, cuComplex beta,
              cuComplex *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are single precision complex scalars. x and y are single precision
 complex vectors. A is an m by n band matrix consisting of single precision complex elements
 with kl sub-diagonals and ku super-diagonals.

 Input
 -----
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 kl     specifies the number of sub-diagonals of matrix A. It must be at
        least zero.
 ku     specifies the number of super-diagonals of matrix A. It must be at
        least zero.
 alpha  single precision complex scalar multiplier applied to op(A).
 A      single precision complex array of dimensions (lda, n). The leading
        (kl + ku + 1) x n part of the array A must contain the band matrix A,
        supplied column by column, with the leading diagonal of the matrix
        in row (ku + 1) of the array, the first super-diagonal starting at
        position 2 in row ku, the first sub-diagonal starting at position 1
        in row (ku + 2), and so on. Elements in the array A that do not
        correspond to elements in the band matrix (such as the top left
        ku x ku triangle) are not referenced.
 lda    leading dimension of A. lda must be at least (kl + ku + 1).
 x      single precision complex array of length at least (1+(n-1)*abs(incx)) when
        trans == 'N' or 'n' and at least (1+(m-1)*abs(incx)) otherwise.
 incx   specifies the increment for the elements of x. incx must not be zero.
 beta   single precision complex scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      single precision complex array of length at least (1+(m-1)*abs(incy)) when
        trans == 'N' or 'n' and at least (1+(n-1)*abs(incy)) otherwise. If
        beta is zero, y is not read.
 incy   On entry, incy specifies the increment for the elements of y. incy
        must not be zero.

 Output
 ------
 y      updated according to y = alpha*op(A)*x + beta*y

 Reference: http://www.netlib.org/blas/cgbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasChemv-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasChemv</h4>
<pre>public static&nbsp;void&nbsp;cublasChemv(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasChemv (char uplo, int n, cuComplex alpha, const cuComplex *A, int lda,
              const cuComplex *x, int incx, cuComplex beta, cuComplex *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are single precision complex scalars, and x and y are single
 precision complex vectors, each with n elements. A is a hermitian n x n matrix
 consisting of single precision complex elements that is stored in either upper or
 lower storage mode.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the array A
        is to be referenced. If uplo == 'U' or 'u', the hermitian matrix A
        is stored in upper storage mode, i.e. only the upper triangular part
        of A is to be referenced while the lower triangular part of A is to
        be inferred. If uplo == 'L' or 'l', the hermitian matrix A is stored
        in lower storage mode, i.e. only the lower triangular part of A is
        to be referenced while the upper triangular part of A is to be
        inferred.
 n      specifies the number of rows and the number of columns of the
        hermitian matrix A. n must be at least zero.
 alpha  single precision complex scalar multiplier applied to A*x.
 A      single precision complex array of dimensions (lda, n). If uplo == 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular part of the hermitian matrix and the strictly
        lower triangular part of A is not referenced. If uplo == 'L' or 'l',
        the leading n x n lower triangular part of the array A must contain
        the lower triangular part of the hermitian matrix and the strictly
        upper triangular part of A is not referenced. The imaginary parts
        of the diagonal elements need not be set, they are assumed to be zero.
 lda    leading dimension of A. It must be at least max (1, n).
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision complex scalar multiplier applied to vector y.
 y      single precision complex array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/chemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasChbmv-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasChbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasChbmv(char&nbsp;uplo,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasChbmv (char uplo, int n, int k, cuComplex alpha, const cuComplex *A, int lda,
              const cuComplex *x, int incx, cuComplex beta, cuComplex *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are single precision complex scalars. x and y are single precision
 complex vectors with n elements. A is an n by n hermitian band matrix consisting
 of single precision complex elements, with k super-diagonals and the same number
 of subdiagonals.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the hermitian
        band matrix A is being supplied. If uplo == 'U' or 'u', the upper
        triangular part is being supplied. If uplo == 'L' or 'l', the lower
        triangular part is being supplied.
 n      specifies the number of rows and the number of columns of the
        hermitian matrix A. n must be at least zero.
 k      specifies the number of super-diagonals of matrix A. Since the matrix
        is hermitian, this is also the number of sub-diagonals. k must be at
        least zero.
 alpha  single precision complex scalar multiplier applied to A*x.
 A      single precision complex array of dimensions (lda, n). When uplo == 'U' or
        'u', the leading (k + 1) x n part of array A must contain the upper
        triangular band of the hermitian matrix, supplied column by column,
        with the leading diagonal of the matrix in row (k+1) of the array,
        the first super-diagonal starting at position 2 in row k, and so on.
        The top left k x k triangle of the array A is not referenced. When
        uplo == 'L' or 'l', the leading (k + 1) x n part of the array A must
        contain the lower triangular band part of the hermitian matrix,
        supplied column by column, with the leading diagonal of the matrix in
        row 1 of the array, the first sub-diagonal starting at position 1 in
        row 2, and so on. The bottom right k x k triangle of the array A is
        not referenced. The imaginary parts of the diagonal elements need
        not be set, they are assumed to be zero.
 lda    leading dimension of A. lda must be at least (k + 1).
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   single precision complex scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      single precision complex array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/chbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if k or n < 0, or if incx or incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtrmv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtrmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>

 cublasCtrmv (char uplo, char trans, char diag, int n, const cuComplex *A,
              int lda, cuComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x,
 where op(A) = A, or op(A) = transpose(A) or op(A) = conjugate(transpose(A)).
 x is an n-element signle precision complex vector, and
 A is an n x n, unit or non-unit, upper or lower, triangular matrix composed
 of single precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', then A is an upper triangular matrix.
        If uplo = 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If trans = 'n' or 'N', op(A) = A. If trans = 't' or
        'T', op(A) = transpose(A).  If trans = 'c' or 'C', op(A) =
        conjugate(transpose(A)).
 diag   specifies whether or not matrix A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 A      single precision array of dimension (lda, n). If uplo = 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular matrix and the strictly lower triangular part
        of A is not referenced. If uplo = 'L' or 'l', the leading n x n lower
        triangular part of the array A must contain the lower triangular
        matrix and the strictly upper triangular part of A is not referenced.
        When diag = 'U' or 'u', the diagonal elements of A are not referenced
        either, but are are assumed to be unity.
 lda    is the leading dimension of A. It must be at least max (1, n).
 x      single precision array of length at least (1 + (n - 1) * abs(incx) ).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/ctrmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtbmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCtbmv (char uplo, char trans, char diag, int n, int k, const cuComplex *A,
              int lda, cuComplex *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)). x is an n-element
 single precision complex vector, and A is an n x n, unit or non-unit, upper
 or lower triangular band matrix composed of single precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular band
        matrix. If uplo == 'U' or 'u', A is an upper triangular band matrix.
        If uplo == 'L' or 'l', A is a lower triangular band matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      single precision complex array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first
        super-diagonal starting at position 2 in row k, and so on. The top
        left k x k triangle of the array A is not referenced. If uplo == 'L'
        or 'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal startingat position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 lda    is the leading dimension of A. It must be at least (k + 1).
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x

 Reference: http://www.netlib.org/blas/ctbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n or k < 0, or if incx == 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtpmv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtpmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCtpmv (char uplo, char trans, char diag, int n, const cuComplex *AP,
              cuComplex *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 op(A) = transpose(A) or op(A) = conjugate(transpose(A)) . x is an n element
 single precision complex vector, and A is an n x n, unit or non-unit, upper
 or lower triangular matrix composed of single precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo == 'U' or 'u', then A is an upper triangular matrix.
        If uplo == 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        or 't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).

 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero. In the current implementation n must not exceed 4070.
 AP     single precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored in AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/ctpmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or n < 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtrsv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtrsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCtrsv (char uplo, char trans, char diag, int n, const cuComplex *A,
              int lda, cuComplex *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A,
 transpose(A) or conjugate(transpose(A)). b and x are single precision
 complex vectors consisting of n elements, and A is an n x n matrix
 composed of a unit or non-unit, upper or lower triangular matrix.
 Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array containing A.

 No test for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the
        lower triangular part of array A. If uplo = 'U' or 'u', then only
        the upper triangular part of A may be referenced. If uplo = 'L' or
        'l', then only the lower triangular part of A may be referenced.
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If transa = 't',
        'T', 'c', or 'C', op(A) = transpose(A)
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 A      is a single precision complex array of dimensions (lda, n). If uplo = 'U'
        or 'u', then A must contains the upper triangular part of a symmetric
        matrix, and the strictly lower triangular parts is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part of
        a symmetric matrix, and the strictly upper triangular part is not
        referenced.
 lda    is the leading dimension of the two-dimensional array containing A.
        lda must be at least max(1, n).
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ctrsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtbsv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtbsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void cublasCtbsv (char uplo, char trans, char diag, int n, int k,
                   const cuComplex *A, int lda, cuComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose(A)).
 b and x are n element vectors, and A is an n x n unit or non-unit,
 upper or lower triangular band matrix with k + 1 diagonals. No test
 for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular band
        matrix as follows: If uplo == 'U' or 'u', A is an upper triangular
        band matrix. If uplo == 'L' or 'l', A is a lower triangular band
        matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', op(A) = transpose(A). If trans == 'C' or 'c',
        op(A) = conjugate(transpose(A)).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      single precision complex array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first super-
        diagonal starting at position 2 in row k, and so on. The top left
        k x k triangle of the array A is not referenced. If uplo == 'L' or
        'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal starting at position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 x      single precision complex array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ctbsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0, n < 0 or n > 2035
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtpsv</h4>
<pre>public static&nbsp;void&nbsp;cublasCtpsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasCtpsv (char uplo, char trans, char diag, int n, const cuComplex *AP,
              cuComplex *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A , op(A) = transpose(A) or op(A) = conjugate(transpose)). b and
 x are n element complex vectors, and A is an n x n unit or non-unit,
 upper or lower triangular matrix. No test for singularity or near-singularity
 is included in this routine. Such tests must be performed before calling this routine.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular matrix
        as follows: If uplo == 'U' or 'u', A is an upper triangluar matrix.
        If uplo == 'L' or 'l', A is a lower triangular matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T'
        or 't', op(A) = transpose(A). If trans == 'C' or 'c', op(A) =
        conjugate(transpose(A)).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 AP     single precision complex array with at least ((n*(n+1))/2) elements.
        If uplo == 'U' or 'u', the array AP contains the upper triangular
        matrix A, packed sequentially, column by column; that is, if i <= j, then
        A[i,j] is stored is AP[i+(j*(j+1)/2)]. If uplo == 'L' or 'L', the
        array AP contains the lower triangular matrix A, packed sequentially,
        column by column; that is, if i >= j, then A[i,j] is stored in
        AP[i+((2*n-j+1)*j)/2]. When diag = 'U' or 'u', the diagonal elements
        of A are not referenced and are assumed to be unity.
 x      single precision complex array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ctpsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0 or n > 2035
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCgeru-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCgeru</h4>
<pre>public static&nbsp;void&nbsp;cublasCgeru(int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasCgeru (int m, int n, cuComplex alpha, const cuComplex *x, int incx,
             const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a single precision complex scalar, x is an m element single
 precision complex vector, y is an n element single precision complex vector, and A
 is an m by n matrix consisting of single precision complex elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  single precision complex scalar multiplier applied to x * transpose(y)
 x      single precision complex array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      single precision complex array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      single precision complex array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * transpose(y) + A

 Reference: http://www.netlib.org/blas/cgeru.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m <0, n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCgerc-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCgerc</h4>
<pre>public static&nbsp;void&nbsp;cublasCgerc(int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasCgerc (int m, int n, cuComplex alpha, const cuComplex *x, int incx,
             const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * conjugate(transpose(y)) + A,

 where alpha is a single precision complex scalar, x is an m element single
 precision complex vector, y is an n element single precision complex vector, and A
 is an m by n matrix consisting of single precision complex elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  single precision complex scalar multiplier applied to x * transpose(y)
 x      single precision complex array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      single precision complex array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      single precision complex array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(y)) + A

 Reference: http://www.netlib.org/blas/cgerc.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m <0, n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCher-char-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCher</h4>
<pre>public static&nbsp;void&nbsp;cublasCher(char&nbsp;uplo,
                              int&nbsp;n,
                              float&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 void
 cublasCher (char uplo, int n, float alpha, const cuComplex *x, int incx,
             cuComplex *A, int lda)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a single precision real scalar, x is an n element single
 precision complex vector and A is an n x n hermitian matrix consisting of
 single precision complex elements. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array
 containing A.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or
        the lower triangular part of array A. If uplo = 'U' or 'u',
        then only the upper triangular part of A may be referenced.
        If uplo = 'L' or 'l', then only the lower triangular part of
        A may be referenced.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 alpha  single precision real scalar multiplier applied to
        x * conjugate(transpose(x))
 x      single precision complex array of length at least (1 + (n - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must
        not be zero.
 A      single precision complex array of dimensions (lda, n). If uplo = 'U' or
        'u', then A must contain the upper triangular part of a hermitian
        matrix, and the strictly lower triangular part is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part
        of a hermitian matrix, and the strictly upper triangular part is
        not referenced. The imaginary parts of the diagonal elements need
        not be set, they are assumed to be zero, and on exit they
        are set to zero.
 lda    leading dimension of the two-dimensional array containing A. lda
        must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(x)) + A

 Reference: http://www.netlib.org/blas/cher.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasChpr-char-int-float-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasChpr</h4>
<pre>public static&nbsp;void&nbsp;cublasChpr(char&nbsp;uplo,
                              int&nbsp;n,
                              float&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasChpr (char uplo, int n, float alpha, const cuComplex *x, int incx,
             cuComplex *AP)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a single precision real scalar and x is an n element single
 precision complex vector. A is a hermitian n x n matrix consisting of single
 precision complex elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision real scalar multiplier applied to x * conjugate(transpose(x)).
 x      single precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 AP     single precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
        The imaginary parts of the diagonal elements need not be set, they
        are assumed to be zero, and on exit they are set to zero.

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(x)) + A

 Reference: http://www.netlib.org/blas/chpr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasChpr2-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasChpr2</h4>
<pre>public static&nbsp;void&nbsp;cublasChpr2(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasChpr2 (char uplo, int n, cuComplex alpha, const cuComplex *x, int incx,
              const cuComplex *y, int incy, cuComplex *AP)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a single precision complex scalar, and x and y are n element single
 precision complex vectors. A is a hermitian n x n matrix consisting of single
 precision complex elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision complex scalar multiplier applied to x * conjugate(transpose(y)) +
        y * conjugate(transpose(x)).
 x      single precision complex array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      single precision complex array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 AP     single precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
        The imaginary parts of the diagonal elements need not be set, they
        are assumed to be zero, and on exit they are set to zero.

 Output
 ------
 A      updated according to A = alpha*x*conjugate(transpose(y))
                               + conjugate(alpha)*y*conjugate(transpose(x))+A

 Reference: http://www.netlib.org/blas/chpr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCher2-char-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCher2</h4>
<pre>public static&nbsp;void&nbsp;cublasCher2(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 void cublasCher2 (char uplo, int n, cuComplex alpha, const cuComplex *x, int incx,
                   const cuComplex *y, int incy, cuComplex *A, int lda)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a single precision complex scalar, x and y are n element single
 precision complex vector and A is an n by n hermitian matrix consisting of single
 precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  single precision complex scalar multiplier applied to x * conjugate(transpose(y)) +
        y * conjugate(transpose(x)).
 x      single precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      single precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 A      single precision complex array of dimensions (lda, n). If uplo == 'U' or 'u',
        then A must contains the upper triangular part of a hermitian matrix,
        and the strictly lower triangular parts is not referenced. If uplo ==
        'L' or 'l', then A contains the lower triangular part of a hermitian
        matrix, and the strictly upper triangular part is not referenced.
        The imaginary parts of the diagonal elements need not be set,
        they are assumed to be zero, and on exit they are set to zero.

 lda    leading dimension of A. It must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha*x*conjugate(transpose(y))
                               + conjugate(alpha)*y*conjugate(transpose(x))+A

 Reference: http://www.netlib.org/blas/cher2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSgemm-char-char-int-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSgemm</h4>
<pre>public static&nbsp;void&nbsp;cublasSgemm(char&nbsp;transa,
                               char&nbsp;transb,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;k,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasSgemm (char transa, char transb, int m, int n, int k, float alpha,
              const float *A, int lda, const float *B, int ldb, float beta,
              float *C, int ldc)

 computes the product of matrix A and matrix B, multiplies the result
 by a scalar alpha, and adds the sum to the product of matrix C and
 scalar beta. sgemm() performs one of the matrix-matrix operations:

     C = alpha * op(A) * op(B) + beta * C,

 where op(X) is one of

     op(X) = X   or   op(X) = transpose(X)

 alpha and beta are single precision scalars, and A, B and C are
 matrices consisting of single precision elements, with op(A) an m x k
 matrix, op(B) a k x n matrix, and C an m x n matrix. Matrices A, B,
 and C are stored in column major format, and lda, ldb, and ldc are
 the leading dimensions of the two-dimensional arrays containing A,
 B, and C.

 Input
 -----
 transa specifies op(A). If transa = 'n' or 'N', op(A) = A. If
        transa = 't', 'T', 'c', or 'C', op(A) = transpose(A)
 transb specifies op(B). If transb = 'n' or 'N', op(B) = B. If
        transb = 't', 'T', 'c', or 'C', op(B) = transpose(B)
 m      number of rows of matrix op(A) and rows of matrix C
 n      number of columns of matrix op(B) and number of columns of C
 k      number of columns of matrix op(A) and number of rows of op(B)
 alpha  single precision scalar multiplier applied to op(A)op(B)
 A      single precision array of dimensions (lda, k) if transa =
        'n' or 'N'), and of dimensions (lda, m) otherwise. When transa =
        'N' or 'n' then lda must be at least  max( 1, m ), otherwise lda
        must be at least max(1, k).
 lda    leading dimension of two-dimensional array used to store matrix A
 B      single precision array of dimensions  (ldb, n) if transb =
        'n' or 'N'), and of dimensions (ldb, k) otherwise. When transb =
        'N' or 'n' then ldb must be at least  max (1, k), otherwise ldb
        must be at least max (1, n).
 ldb    leading dimension of two-dimensional array used to store matrix B
 beta   single precision scalar multiplier applied to C. If 0, C does
        not have to be a valid input
 C      single precision array of dimensions (ldc, n). ldc must be at
        least max (1, m).
 ldc    leading dimension of two-dimensional array used to store matrix C

 Output
 ------
 C      updated based on C = alpha * op(A)*op(B) + beta * C

 Reference: http://www.netlib.org/blas/sgemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if any of m, n, or k are < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsymm-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsymm</h4>
<pre>public static&nbsp;void&nbsp;cublasSsymm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasSsymm (char side, char uplo, int m, int n, float alpha,
              const float *A, int lda, const float *B, int ldb,
              float beta, float *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision scalars, A is a symmetric matrix
 consisting of single precision elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 elements.

 Input
 -----
 side   specifies whether the symmetric matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the symmetric matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of symmetric matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of symmetric
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  single precision scalar multiplier applied to A * B, or B * A
 A      single precision array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the symmetric matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the symmetric matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        symmetric matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the symmetric matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        symmetric matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the symmetric matrix and the
        strictly upper triangular part is not referenced.
 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      single precision array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   single precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      single precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/ssymm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsyrk-char-char-int-int-float-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsyrk</h4>
<pre>public static&nbsp;void&nbsp;cublasSsyrk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasSsyrk (char uplo, char trans, int n, int k, float alpha,
              const float *A, int lda, float beta, float *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.

 Alpha and beta are single precision scalars. C is an n x n symmetric matrix
 consisting of single precision elements and stored in either lower or
 upper storage mode. A is a matrix consisting of single precision elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * transpose(A) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = transpose(A) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision scalar multiplier applied to A * transpose(A) or
        transpose(A) * A.
 A      single precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   single precision scalar multiplier applied to C. If beta izs zero, C
        does not have to be a valid input
 C      single precision array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * transpose(A) + beta * C, or C =
        alpha * transpose(A) * A + beta * C

 Reference: http://www.netlib.org/blas/ssyrk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasSsyr2k-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasSsyr2k</h4>
<pre>public static&nbsp;void&nbsp;cublasSsyr2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                float&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                float&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasSsyr2k (char uplo, char trans, int n, int k, float alpha,
               const float *A, int lda, const float *B, int ldb,
               float beta, float *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.

 Alpha and beta are single precision scalars. C is an n x n symmetric matrix
 consisting of single precision elements and stored in either lower or upper
 storage mode. A and B are matrices consisting of single precision elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C,
        If trans == 'T', 't', 'C', or 'c', C = alpha * transpose(A) * B +
        alpha * transpose(B) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision scalar multiplier.
 A      single precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      single precision array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   single precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      single precision array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*transpose(B) + alpha*B*transpose(A) +
        beta*C or alpha*transpose(A)*B + alpha*transpose(B)*A + beta*C

 Reference:   http://www.netlib.org/blas/ssyr2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStrmm-char-char-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStrmm</h4>
<pre>public static&nbsp;void&nbsp;cublasStrmm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasStrmm (char side, char uplo, char transa, char diag, int m, int n,
              float alpha, const float *A, int lda, const float *B, int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a single-precision scalar, B is an m x n matrix composed
 of single precision elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of single precision elements. op(A) is one of

   op(A) = A  or  op(A) = transpose(A)

 Matrices A and B are stored in column major format, and lda and ldb are
 the leading dimensions of the two-dimensonials arrays that contain A and
 B, respectively.

 Input
 -----
 side   specifies whether op(A) multiplies B from the left or right.
        If side = 'L' or 'l', then B = alpha * op(A) * B. If side =
        'R' or 'r', then B = alpha * B * op(A).
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', A is an upper triangular matrix.
        If uplo = 'L' or 'l', A is a lower triangular matrix.
 transa specifies the form of op(A) to be used in the matrix
        multiplication. If transa = 'N' or 'n', then op(A) = A. If
        transa = 'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or
        'n', A is not assumed to be unit triangular.
 m      the number of rows of matrix B. m must be at least zero.
 n      the number of columns of matrix B. n must be at least zero.
 alpha  single precision scalar multiplier applied to op(A)*B, or
        B*op(A), respectively. If alpha is zero no accesses are made
        to matrix A, and no read accesses are made to matrix B.
 A      single precision array of dimensions (lda, k). k = m if side =
        'L' or 'l', k = n if side = 'R' or 'r'. If uplo = 'U' or 'u'
        the leading k x k upper triangular part of the array A must
        contain the upper triangular matrix, and the strictly lower
        triangular part of A is not referenced. If uplo = 'L' or 'l'
        the leading k x k lower triangular part of the array A must
        contain the lower triangular matrix, and the strictly upper
        triangular part of A is not referenced. When diag = 'U' or 'u'
        the diagonal elements of A are no referenced and are assumed
        to be unity.
 lda    leading dimension of A. When side = 'L' or 'l', it must be at
        least max(1,m) and at least max(1,n) otherwise
 B      single precision array of dimensions (ldb, n). On entry, the
        leading m x n part of the array contains the matrix B. It is
        overwritten with the transformed matrix on exit.
 ldb    leading dimension of B. It must be at least max (1, m).

 Output
 ------
 B      updated according to B = alpha * op(A) * B  or B = alpha * B * op(A)

 Reference: http://www.netlib.org/blas/strmm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasStrsm-char-char-char-char-int-int-float-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasStrsm</h4>
<pre>public static&nbsp;void&nbsp;cublasStrsm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasStrsm (char side, char uplo, char transa, char diag, int m, int n,
              float alpha, const float *A, int lda, float *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a single precision scalar, and X and B are m x n matrices
 that are composed of single precision elements. A is a unit or non-unit,
 upper or lower triangular matrix, and op(A) is one of

    op(A) = A  or  op(A) = transpose(A)

 The result matrix X overwrites input matrix B; that is, on exit the result
 is stored in B. Matrices A and B are stored in column major format, and
 lda and ldb are the leading dimensions of the two-dimensonials arrays that
 contain A and B, respectively.

 Input
 -----
 side   specifies whether op(A) appears on the left or right of X as
        follows: side = 'L' or 'l' indicates solve op(A) * X = alpha * B.
        side = 'R' or 'r' indicates solve X * op(A) = alpha * B.
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix as follows: uplo = 'U' or 'u' indicates A is an upper
        triangular matrix. uplo = 'L' or 'l' indicates A is a lower
        triangular matrix.
 transa specifies the form of op(A) to be used in matrix multiplication
        as follows: If transa = 'N' or 'N', then op(A) = A. If transa =
        'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 m      specifies the number of rows of B. m must be at least zero.
 n      specifies the number of columns of B. n must be at least zero.
 alpha  is a single precision scalar to be multiplied with B. When alpha is
        zero, then A is not referenced and B need not be set before entry.
 A      is a single precision array of dimensions (lda, k), where k is
        m when side = 'L' or 'l', and is n when side = 'R' or 'r'. If
        uplo = 'U' or 'u', the leading k x k upper triangular part of
        the array A must contain the upper triangular matrix and the
        strictly lower triangular matrix of A is not referenced. When
        uplo = 'L' or 'l', the leading k x k lower triangular part of
        the array A must contain the lower triangular matrix and the
        strictly upper triangular part of A is not referenced. Note that
        when diag = 'U' or 'u', the diagonal elements of A are not
        referenced, and are assumed to be unity.
 lda    is the leading dimension of the two dimensional array containing A.
        When side = 'L' or 'l' then lda must be at least max(1, m), when
        side = 'R' or 'r' then lda must be at least max(1, n).
 B      is a single precision array of dimensions (ldb, n). ldb must be
        at least max (1,m). The leading m x n part of the array B must
        contain the right-hand side matrix B. On exit B is overwritten
        by the solution matrix X.
 ldb    is the leading dimension of the two dimensional array containing B.
        ldb must be at least max(1, m).

 Output
 ------
 B      contains the solution matrix X satisfying op(A) * X = alpha * B,
        or X * op(A) = alpha * B

 Reference: http://www.netlib.org/blas/strsm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCgemm-char-char-int-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCgemm</h4>
<pre>public static&nbsp;void&nbsp;cublasCgemm(char&nbsp;transa,
                               char&nbsp;transb,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void cublasCgemm (char transa, char transb, int m, int n, int k,
                   cuComplex alpha, const cuComplex *A, int lda,
                   const cuComplex *B, int ldb, cuComplex beta,
                   cuComplex *C, int ldc)

 performs one of the matrix-matrix operations

    C = alpha * op(A) * op(B) + beta*C,

 where op(X) is one of

    op(X) = X   or   op(X) = transpose  or  op(X) = conjg(transpose(X))

 alpha and beta are single-complex scalars, and A, B and C are matrices
 consisting of single-complex elements, with op(A) an m x k matrix, op(B)
 a k x n matrix and C an m x n matrix.

 Input
 -----
 transa specifies op(A). If transa == 'N' or 'n', op(A) = A. If transa ==
        'T' or 't', op(A) = transpose(A). If transa == 'C' or 'c', op(A) =
        conjg(transpose(A)).
 transb specifies op(B). If transa == 'N' or 'n', op(B) = B. If transb ==
        'T' or 't', op(B) = transpose(B). If transb == 'C' or 'c', op(B) =
        conjg(transpose(B)).
 m      number of rows of matrix op(A) and rows of matrix C. It must be at
        least zero.
 n      number of columns of matrix op(B) and number of columns of C. It
        must be at least zero.
 k      number of columns of matrix op(A) and number of rows of op(B). It
        must be at least zero.
 alpha  single-complex scalar multiplier applied to op(A)op(B)
 A      single-complex array of dimensions (lda, k) if transa ==  'N' or
        'n'), and of dimensions (lda, m) otherwise.
 lda    leading dimension of A. When transa == 'N' or 'n', it must be at
        least max(1, m) and at least max(1, k) otherwise.
 B      single-complex array of dimensions (ldb, n) if transb == 'N' or 'n',
        and of dimensions (ldb, k) otherwise
 ldb    leading dimension of B. When transb == 'N' or 'n', it must be at
        least max(1, k) and at least max(1, n) otherwise.
 beta   single-complex scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      single precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m).

 Output
 ------
 C      updated according to C = alpha*op(A)*op(B) + beta*C

 Reference: http://www.netlib.org/blas/cgemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if any of m, n, or k are < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCsymm-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCsymm</h4>
<pre>public static&nbsp;void&nbsp;cublasCsymm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasCsymm (char side, char uplo, int m, int n, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *B, int ldb,
              cuComplex beta, cuComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision complex scalars, A is a symmetric matrix
 consisting of single precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 complex elements.

 Input
 -----
 side   specifies whether the symmetric matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the symmetric matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of symmetric matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of symmetric
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  single precision scalar multiplier applied to A * B, or B * A
 A      single precision array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the symmetric matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the symmetric matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        symmetric matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the symmetric matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        symmetric matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the symmetric matrix and the
        strictly upper triangular part is not referenced.
 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      single precision array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   single precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      single precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/csymm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasChemm-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasChemm</h4>
<pre>public static&nbsp;void&nbsp;cublasChemm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasChemm (char side, char uplo, int m, int n, cuComplex alpha,
              const cuComplex *A, int lda, const cuComplex *B, int ldb,
              cuComplex beta, cuComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are single precision complex scalars, A is a hermitian matrix
 consisting of single precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of single precision
 complex elements.

 Input
 -----
 side   specifies whether the hermitian matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the hermitian matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of hermitian matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of hermitian
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  single precision complex scalar multiplier applied to A * B, or B * A
 A      single precision complex array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the hermitian matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the hermitian matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        hermitian matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the hermitian matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        hermitian matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the hermitian matrix and the
        strictly upper triangular part is not referenced. The imaginary parts
        of the diagonal elements need not be set, they are assumed to be zero.
 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      single precision complex array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   single precision complex scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      single precision complex array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/chemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCsyrk-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCsyrk</h4>
<pre>public static&nbsp;void&nbsp;cublasCsyrk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasCsyrk (char uplo, char trans, int n, int k, cuComplex alpha,
              const cuComplex *A, int lda, cuComplex beta, cuComplex *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.

 Alpha and beta are single precision complex scalars. C is an n x n symmetric matrix
 consisting of single precision complex elements and stored in either lower or
 upper storage mode. A is a matrix consisting of single precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * transpose(A) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = transpose(A) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision complex scalar multiplier applied to A * transpose(A) or
        transpose(A) * A.
 A      single precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   single precision complex scalar multiplier applied to C. If beta izs zero, C
        does not have to be a valid input
 C      single precision complex array of dimensions (ldc, n). If uplo = 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo = 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * transpose(A) + beta * C, or C =
        alpha * transpose(A) * A + beta * C

 Reference: http://www.netlib.org/blas/csyrk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCherk-char-char-int-int-float-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCherk</h4>
<pre>public static&nbsp;void&nbsp;cublasCherk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               float&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               float&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasCherk (char uplo, char trans, int n, int k, float alpha,
              const cuComplex *A, int lda, float beta, cuComplex *C, int ldc)

 performs one of the hermitian rank k operations

   C = alpha * A * conjugate(transpose(A)) + beta * C, or
   C = alpha * conjugate(transpose(A)) * A + beta * C.

 Alpha and beta are single precision real scalars. C is an n x n hermitian matrix
 consisting of single precision complex elements and stored in either lower or
 upper storage mode. A is a matrix consisting of single precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the hermitian matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * A * conjugate(transpose(A)) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = alpha * conjugate(transpose(A)) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of columns of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision scalar multiplier applied to A * conjugate(transpose(A)) or
        conjugate(transpose(A)) * A.
 A      single precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   single precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      single precision complex array of dimensions (ldc, n). If uplo = 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the hermitian matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo = 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the hermitian matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
        The imaginary parts of the diagonal elements need
        not be set,  they are assumed to be zero,  and on exit they
        are set to zero.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * conjugate(transpose(A)) + beta * C, or C =
        alpha * conjugate(transpose(A)) * A + beta * C

 Reference: http://www.netlib.org/blas/cherk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCsyr2k-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCsyr2k</h4>
<pre>public static&nbsp;void&nbsp;cublasCsyr2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasCsyr2k (char uplo, char trans, int n, int k, cuComplex alpha,
               const cuComplex *A, int lda, const cuComplex *B, int ldb,
               cuComplex beta, cuComplex *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.

 Alpha and beta are single precision complex scalars. C is an n x n symmetric matrix
 consisting of single precision complex elements and stored in either lower or upper
 storage mode. A and B are matrices consisting of single precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C,
        If trans == 'T', 't', 'C', or 'c', C = alpha * transpose(A) * B +
        alpha * transpose(B) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision complex scalar multiplier.
 A      single precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      single precision complex array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   single precision complex scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      single precision complex array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*transpose(B) + alpha*B*transpose(A) +
        beta*C or alpha*transpose(A)*B + alpha*transpose(B)*A + beta*C

 Reference:   http://www.netlib.org/blas/csyr2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCher2k-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-float-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCher2k</h4>
<pre>public static&nbsp;void&nbsp;cublasCher2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                float&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasCher2k (char uplo, char trans, int n, int k, cuComplex alpha,
               const cuComplex *A, int lda, const cuComplex *B, int ldb,
               float beta, cuComplex *C, int ldc)

 performs one of the hermitian rank 2k operations

    C =   alpha * A * conjugate(transpose(B))
        + conjugate(alpha) * B * conjugate(transpose(A))
        + beta * C ,
    or
    C =  alpha * conjugate(transpose(A)) * B
       + conjugate(alpha) * conjugate(transpose(B)) * A
       + beta * C.

 Alpha is single precision complex scalar whereas Beta is a single preocision real scalar.
 C is an n x n hermitian matrix consisting of single precision complex elements
 and stored in either lower or upper storage mode. A and B are matrices consisting
 of single precision complex elements with dimension of n x k in the first case,
 and k x n in the second case.

 Input
 -----
 uplo   specifies whether the hermitian matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C =   alpha * A * conjugate(transpose(B))
            + conjugate(alpha) * B * conjugate(transpose(A))
            + beta * C .
        If trans == 'T', 't', 'C', or 'c',
        C =  alpha * conjugate(transpose(A)) * B
          + conjugate(alpha) * conjugate(transpose(B)) * A
          + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  single precision complex scalar multiplier.
 A      single precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      single precision complex array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   single precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      single precision complex array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the hermitian matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the hermitian matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
        The imaginary parts of the diagonal elements need
        not be set,  they are assumed to be zero,  and on exit they
        are set to zero.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*conjugate(transpose(B)) +
        + conjugate(alpha)*B*conjugate(transpose(A)) + beta*C or
        alpha*conjugate(transpose(A))*B + conjugate(alpha)*conjugate(transpose(B))*A
        + beta*C.

 Reference:   http://www.netlib.org/blas/cher2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtrmm-char-char-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtrmm</h4>
<pre>public static&nbsp;void&nbsp;cublasCtrmm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasCtrmm (char side, char uplo, char transa, char diag, int m, int n,
              cuComplex alpha, const cuComplex *A, int lda, const cuComplex *B,
              int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a single-precision complex scalar, B is an m x n matrix composed
 of single precision complex elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of single precision complex elements. op(A) is one of

   op(A) = A  , op(A) = transpose(A) or op(A) = conjugate(transpose(A))

 Matrices A and B are stored in column major format, and lda and ldb are
 the leading dimensions of the two-dimensonials arrays that contain A and
 B, respectively.

 Input
 -----
 side   specifies whether op(A) multiplies B from the left or right.
        If side = 'L' or 'l', then B = alpha * op(A) * B. If side =
        'R' or 'r', then B = alpha * B * op(A).
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', A is an upper triangular matrix.
        If uplo = 'L' or 'l', A is a lower triangular matrix.
 transa specifies the form of op(A) to be used in the matrix
        multiplication. If transa = 'N' or 'n', then op(A) = A. If
        transa = 'T' or 't', then op(A) = transpose(A).
        If transa = 'C' or 'c', then op(A) = conjugate(transpose(A)).
 diag   specifies whether or not A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or
        'n', A is not assumed to be unit triangular.
 m      the number of rows of matrix B. m must be at least zero.
 n      the number of columns of matrix B. n must be at least zero.
 alpha  single precision complex scalar multiplier applied to op(A)*B, or
        B*op(A), respectively. If alpha is zero no accesses are made
        to matrix A, and no read accesses are made to matrix B.
 A      single precision complex array of dimensions (lda, k). k = m if side =
        'L' or 'l', k = n if side = 'R' or 'r'. If uplo = 'U' or 'u'
        the leading k x k upper triangular part of the array A must
        contain the upper triangular matrix, and the strictly lower
        triangular part of A is not referenced. If uplo = 'L' or 'l'
        the leading k x k lower triangular part of the array A must
        contain the lower triangular matrix, and the strictly upper
        triangular part of A is not referenced. When diag = 'U' or 'u'
        the diagonal elements of A are no referenced and are assumed
        to be unity.
 lda    leading dimension of A. When side = 'L' or 'l', it must be at
        least max(1,m) and at least max(1,n) otherwise
 B      single precision complex array of dimensions (ldb, n). On entry, the
        leading m x n part of the array contains the matrix B. It is
        overwritten with the transformed matrix on exit.
 ldb    leading dimension of B. It must be at least max (1, m).

 Output
 ------
 B      updated according to B = alpha * op(A) * B  or B = alpha * B * op(A)

 Reference: http://www.netlib.org/blas/ctrmm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasCtrsm-char-char-char-char-int-int-jcuda.cuComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasCtrsm</h4>
<pre>public static&nbsp;void&nbsp;cublasCtrsm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuComplex.html" title="class in jcuda">cuComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasCtrsm (char side, char uplo, char transa, char diag, int m, int n,
              cuComplex alpha, const cuComplex *A, int lda,
              cuComplex *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a single precision complex scalar, and X and B are m x n matrices
 that are composed of single precision complex elements. A is a unit or non-unit,
 upper or lower triangular matrix, and op(A) is one of

    op(A) = A  or  op(A) = transpose(A)  or  op( A ) = conj( A' ).

 The result matrix X overwrites input matrix B; that is, on exit the result
 is stored in B. Matrices A and B are stored in column major format, and
 lda and ldb are the leading dimensions of the two-dimensonials arrays that
 contain A and B, respectively.

 Input
 -----
 side   specifies whether op(A) appears on the left or right of X as
        follows: side = 'L' or 'l' indicates solve op(A) * X = alpha * B.
        side = 'R' or 'r' indicates solve X * op(A) = alpha * B.
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix as follows: uplo = 'U' or 'u' indicates A is an upper
        triangular matrix. uplo = 'L' or 'l' indicates A is a lower
        triangular matrix.
 transa specifies the form of op(A) to be used in matrix multiplication
        as follows: If transa = 'N' or 'N', then op(A) = A. If transa =
        'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 m      specifies the number of rows of B. m must be at least zero.
 n      specifies the number of columns of B. n must be at least zero.
 alpha  is a single precision complex scalar to be multiplied with B. When alpha is
        zero, then A is not referenced and B need not be set before entry.
 A      is a single precision complex array of dimensions (lda, k), where k is
        m when side = 'L' or 'l', and is n when side = 'R' or 'r'. If
        uplo = 'U' or 'u', the leading k x k upper triangular part of
        the array A must contain the upper triangular matrix and the
        strictly lower triangular matrix of A is not referenced. When
        uplo = 'L' or 'l', the leading k x k lower triangular part of
        the array A must contain the lower triangular matrix and the
        strictly upper triangular part of A is not referenced. Note that
        when diag = 'U' or 'u', the diagonal elements of A are not
        referenced, and are assumed to be unity.
 lda    is the leading dimension of the two dimensional array containing A.
        When side = 'L' or 'l' then lda must be at least max(1, m), when
        side = 'R' or 'r' then lda must be at least max(1, n).
 B      is a single precision complex array of dimensions (ldb, n). ldb must be
        at least max (1,m). The leading m x n part of the array B must
        contain the right-hand side matrix B. On exit B is overwritten
        by the solution matrix X.
 ldb    is the leading dimension of the two dimensional array containing B.
        ldb must be at least max(1, m).

 Output
 ------
 B      contains the solution matrix X satisfying op(A) * X = alpha * B,
        or X * op(A) = alpha * B

 Reference: http://www.netlib.org/blas/ctrsm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDasum-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDasum</h4>
<pre>public static&nbsp;double&nbsp;cublasDasum(int&nbsp;n,
                                 <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                 int&nbsp;incx)</pre>
<div class="block"><pre>
 double
 cublasDasum (int n, const double *x, int incx)

 computes the sum of the absolute values of the elements of double
 precision vector x; that is, the result is the sum from i = 0 to n - 1 of
 abs(x[1 + i * incx]).

 Input
 -----
 n      number of elements in input vector
 x      double-precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the double-precision sum of absolute values
 (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/dasum.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDaxpy-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDaxpy</h4>
<pre>public static&nbsp;void&nbsp;cublasDaxpy(int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDaxpy (int n, double alpha, const double *x, int incx, double *y,
              int incy)

 multiplies double-precision vector x by double-precision scalar alpha
 and adds the result to double-precision vector y; that is, it overwrites
 double-precision y with double-precision alpha * x + y. For i = 0 to n-1,
 it replaces y[ly + i * incy] with alpha * x[lx + i * incx] + y[ly + i*incy],
 where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx; ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 alpha  double-precision scalar multiplier
 x      double-precision vector with n elements
 incx   storage spacing between elements of x
 y      double-precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      double-precision result (unchanged if n <= 0)

 Reference: http://www.netlib.org/blas/daxpy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library was not initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDcopy-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDcopy</h4>
<pre>public static&nbsp;void&nbsp;cublasDcopy(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDcopy (int n, const double *x, int incx, double *y, int incy)

 copies the double-precision vector x to the double-precision vector y. For
 i = 0 to n-1, copies x[lx + i * incx] to y[ly + i * incy], where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a similar
 way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision vector with n elements
 incx   storage spacing between elements of x
 y      double-precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 y      contains double precision vector x

 Reference: http://www.netlib.org/blas/dcopy.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDdot-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDdot</h4>
<pre>public static&nbsp;double&nbsp;cublasDdot(int&nbsp;n,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                int&nbsp;incx,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                                int&nbsp;incy)</pre>
<div class="block"><pre>
 double
 cublasDdot (int n, const double *x, int incx, const double *y, int incy)

 computes the dot product of two double-precision vectors. It returns the
 dot product of the double precision vectors x and y if successful, and
 0.0f otherwise. It computes the sum for i = 0 to n - 1 of x[lx + i *
 incx] * y[ly + i * incy], where lx = 1 if incx >= 0, else lx = 1 + (1 - n)
 *incx, and ly is defined in a similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision vector with n elements
 incx   storage spacing between elements of x
 y      double-precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 returns double-precision dot product (zero if n <= 0)

 Reference: http://www.netlib.org/blas/ddot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has nor been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to execute on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDnrm2-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDnrm2</h4>
<pre>public static&nbsp;double&nbsp;cublasDnrm2(int&nbsp;n,
                                 <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                                 int&nbsp;incx)</pre>
<div class="block"><pre>
 double
 dnrm2 (int n, const double *x, int incx)

 computes the Euclidean norm of the double-precision n-vector x (with
 storage increment incx). This code uses a multiphase model of
 accumulation to avoid intermediate underflow and overflow.

 Input
 -----
 n      number of elements in input vector
 x      double-precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns Euclidian norm (0 if n <= 0 or incx <= 0, or if an error occurs)

 Reference: http://www.netlib.org/blas/dnrm2.f
 Reference: http://www.netlib.org/slatec/lin/dnrm2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDrot-int-jcuda.Pointer-int-jcuda.Pointer-int-double-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDrot</h4>
<pre>public static&nbsp;void&nbsp;cublasDrot(int&nbsp;n,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              double&nbsp;sc,
                              double&nbsp;ss)</pre>
<div class="block"><pre>
 void
 cublasDrot (int n, double *x, int incx, double *y, int incy, double sc,
             double ss)

 multiplies a 2x2 matrix ( sc ss) with the 2xn matrix ( transpose(x) )
                         (-ss sc)                     ( transpose(y) )

 The elements of x are in x[lx + i * incx], i = 0 ... n - 1, where lx = 1 if
 incx >= 0, else lx = 1 + (1 - n) * incx, and similarly for y using ly and
 incy.

 Input
 -----
 n      number of elements in input vectors
 x      double-precision vector with n elements
 incx   storage spacing between elements of x
 y      double-precision vector with n elements
 incy   storage spacing between elements of y
 sc     element of rotation matrix
 ss     element of rotation matrix

 Output
 ------
 x      rotated vector x (unchanged if n <= 0)
 y      rotated vector y (unchanged if n <= 0)

 Reference  http://www.netlib.org/blas/drot.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDrotg-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDrotg</h4>
<pre>public static&nbsp;void&nbsp;cublasDrotg(<a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sa,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sb,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_sc,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;host_ss)</pre>
<div class="block"><pre>
 void
 cublasDrotg (double *host_sa, double *host_sb, double *host_sc, double *host_ss)

 constructs the Givens tranformation

        ( sc  ss )
    G = (        ) ,  sc^2 + ss^2 = 1,
        (-ss  sc )

 which zeros the second entry of the 2-vector transpose(sa, sb).

 The quantity r = (+/-) sqrt (sa^2 + sb^2) overwrites sa in storage. The
 value of sb is overwritten by a value z which allows sc and ss to be
 recovered by the following algorithm:

    if z=1          set sc = 0.0 and ss = 1.0
    if abs(z) < 1   set sc = sqrt(1-z^2) and ss = z
    if abs(z) > 1   set sc = 1/z and ss = sqrt(1-sc^2)

 The function drot (n, x, incx, y, incy, sc, ss) normally is called next
 to apply the transformation to a 2 x n matrix.
 Note that is function is provided for completeness and run exclusively
 on the Host.

 Input
 -----
 sa     double-precision scalar
 sb     double-precision scalar

 Output
 ------
 sa     double-precision r
 sb     double-precision z
 sc     double-precision result
 ss     double-precision result

 Reference: http://www.netlib.org/blas/drotg.f

 This function does not set any error status.
 </pre></div>
</li>
</ul>
<a name="cublasDscal-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDscal</h4>
<pre>public static&nbsp;void&nbsp;cublasDscal(int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDscal (int n, double alpha, double *x, int incx)

 replaces double-precision vector x with double-precision alpha * x. For
 i = 0 to n-1, it replaces x[lx + i * incx] with alpha * x[lx + i * incx],
 where lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx.

 Input
 -----
 n      number of elements in input vector
 alpha  double-precision scalar multiplier
 x      double-precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 x      double-precision result (unchanged if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/dscal.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library was not initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDswap-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDswap</h4>
<pre>public static&nbsp;void&nbsp;cublasDswap(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDswap (int n, double *x, int incx, double *y, int incy)

 interchanges the double-precision vector x with the double-precision vector y.
 For i = 0 to n-1, interchanges x[lx + i * incx] with y[ly + i * incy], where
 lx = 1 if incx >= 0, else lx = 1 + (1 - n) * incx, and ly is defined in a
 similar way using incy.

 Input
 -----
 n      number of elements in input vectors
 x      double precision vector with n elements
 incx   storage spacing between elements of x
 y      double precision vector with n elements
 incy   storage spacing between elements of y

 Output
 ------
 x      contains double precision vector y
 y      contains double precision vector x

 Reference: http://www.netlib.org/blas/dswap.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIdamax-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIdamax</h4>
<pre>public static&nbsp;int&nbsp;cublasIdamax(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 idamax (int n, const double *x, int incx)

 finds the smallest index of the maximum magnitude element of double-
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that maximizes abs(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      double-precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/blas/idamax.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasIdamin-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasIdamin</h4>
<pre>public static&nbsp;int&nbsp;cublasIdamin(int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 int
 idamin (int n, const double *x, int incx)

 finds the smallest index of the minimum magnitude element of double-
 precision vector x; that is, the result is the first i, i = 0 to n - 1,
 that minimizes abs(x[1 + i * incx])).

 Input
 -----
 n      number of elements in input vector
 x      double-precision vector with n elements
 incx   storage spacing between elements of x

 Output
 ------
 returns the smallest index (0 if n <= 0 or incx <= 0)

 Reference: http://www.netlib.org/scilib/blass.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDgemv-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDgemv</h4>
<pre>public static&nbsp;void&nbsp;cublasDgemv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 cublasDgemv (char trans, int m, int n, double alpha, const double *A,
              int lda, const double *x, int incx, double beta, double *y,
              int incy)

 performs one of the matrix-vector operations

    y = alpha * op(A) * x + beta * y,

 where op(A) is one of

    op(A) = A   or   op(A) = transpose(A)

 where alpha and beta are double precision scalars, x and y are double
 precision vectors, and A is an m x n matrix consisting of double precision
 elements. Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array in which A is stored.

 Input
 -----
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If trans =
        trans = 't', 'T', 'c', or 'C', op(A) = transpose(A)
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 alpha  double precision scalar multiplier applied to op(A).
 A      double precision array of dimensions (lda, n) if trans = 'n' or
        'N'), and of dimensions (lda, m) otherwise. lda must be at least
        max(1, m) and at least max(1, n) otherwise.
 lda    leading dimension of two-dimensional array used to store matrix A
 x      double precision array of length at least (1 + (n - 1) * abs(incx))
        when trans = 'N' or 'n' and at least (1 + (m - 1) * abs(incx))
        otherwise.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 beta   double precision scalar multiplier applied to vector y. If beta
        is zero, y is not read.
 y      double precision array of length at least (1 + (m - 1) * abs(incy))
        when trans = 'N' or 'n' and at least (1 + (n - 1) * abs(incy))
        otherwise.
 incy   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 y      updated according to alpha * op(A) * x + beta * y

 Reference: http://www.netlib.org/blas/dgemv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDger-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDger</h4>
<pre>public static&nbsp;void&nbsp;cublasDger(int&nbsp;m,
                              int&nbsp;n,
                              double&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                              int&nbsp;incy,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasDger (int m, int n, double alpha, const double *x, int incx,
             const double *y, int incy, double *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a double precision scalar, x is an m element double
 precision vector, y is an n element double precision vector, and A
 is an m by n matrix consisting of double precision elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  double precision scalar multiplier applied to x * transpose(y)
 x      double precision array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      double precision array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      double precision array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * transpose(y) + A

 Reference: http://www.netlib.org/blas/dger.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsyr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsyr</h4>
<pre>public static&nbsp;void&nbsp;cublasDsyr(char&nbsp;uplo,
                              int&nbsp;n,
                              double&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 void
 cublasDsyr (char uplo, int n, double alpha, const double *x, int incx,
             double *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a double precision scalar, x is an n element double
 precision vector and A is an n x n symmetric matrix consisting of
 double precision elements. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array
 containing A.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or
        the lower triangular part of array A. If uplo = 'U' or 'u',
        then only the upper triangular part of A may be referenced.
        If uplo = 'L' or 'l', then only the lower triangular part of
        A may be referenced.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 alpha  double precision scalar multiplier applied to x * transpose(x)
 x      double precision array of length at least (1 + (n - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must
        not be zero.
 A      double precision array of dimensions (lda, n). If uplo = 'U' or
        'u', then A must contain the upper triangular part of a symmetric
        matrix, and the strictly lower triangular part is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part
        of a symmetric matrix, and the strictly upper triangular part is
        not referenced.
 lda    leading dimension of the two-dimensional array containing A. lda
        must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha * x * transpose(x) + A

 Reference: http://www.netlib.org/blas/dsyr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsyr2-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsyr2</h4>
<pre>public static&nbsp;void&nbsp;cublasDsyr2(char&nbsp;uplo,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 void cublasDsyr2 (char uplo, int n, double alpha, const double *x, int incx,
                   const double *y, int incy, double *A, int lda)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a double precision scalar, x and y are n element double
 precision vector and A is an n by n symmetric matrix consisting of double
 precision elements.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision scalar multiplier applied to x * transpose(y) +
        y * transpose(x).
 x      double precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      double precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 A      double precision array of dimensions (lda, n). If uplo == 'U' or 'u',
        then A must contains the upper triangular part of a symmetric matrix,
        and the strictly lower triangular parts is not referenced. If uplo ==
        'L' or 'l', then A contains the lower triangular part of a symmetric
        matrix, and the strictly upper triangular part is not referenced.
 lda    leading dimension of A. It must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha*x*transpose(y)+alpha*y*transpose(x)+A

 Reference: http://www.netlib.org/blas/dsyr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDspr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDspr</h4>
<pre>public static&nbsp;void&nbsp;cublasDspr(char&nbsp;uplo,
                              int&nbsp;n,
                              double&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasDspr (char uplo, int n, double alpha, const double *x, int incx,
             double *AP)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(x) + A,

 where alpha is a double precision scalar and x is an n element double
 precision vector. A is a symmetric n x n matrix consisting of double
 precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision scalar multiplier applied to x * transpose(x).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 AP     double precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].

 Output
 ------
 A      updated according to A = alpha * x * transpose(x) + A

 Reference: http://www.netlib.org/blas/dspr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDspr2-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDspr2</h4>
<pre>public static&nbsp;void&nbsp;cublasDspr2(char&nbsp;uplo,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasDspr2 (char uplo, int n, double alpha, const double *x, int incx,
              const double *y, int incy, double *AP)

 performs the symmetric rank 2 operation

    A = alpha*x*transpose(y) + alpha*y*transpose(x) + A,

 where alpha is a double precision scalar, and x and y are n element double
 precision vectors. A is a symmetric n x n matrix consisting of double
 precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision scalar multiplier applied to x * transpose(y) +
        y * transpose(x).
 x      double precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      double precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 AP     double precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].

 Output
 ------
 A      updated according to A = alpha*x*transpose(y)+alpha*y*transpose(x)+A

 Reference: http://www.netlib.org/blas/dspr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtrsv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtrsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDtrsv (char uplo, char trans, char diag, int n, const double *A,
              int lda, double *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A or
 transpose(A). b and x are double precision vectors consisting of n
 elements, and A is an n x n matrix composed of a unit or non-unit, upper
 or lower triangular matrix. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array containing
 A.

 No test for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the
        lower triangular part of array A. If uplo = 'U' or 'u', then only
        the upper triangular part of A may be referenced. If uplo = 'L' or
        'l', then only the lower triangular part of A may be referenced.
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If transa = 't',
        'T', 'c', or 'C', op(A) = transpose(A)
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 A      is a double precision array of dimensions (lda, n). If uplo = 'U'
        or 'u', then A must contains the upper triangular part of a symmetric
        matrix, and the strictly lower triangular parts is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part of
        a symmetric matrix, and the strictly upper triangular part is not
        referenced.
 lda    is the leading dimension of the two-dimensional array containing A.
        lda must be at least max(1, n).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/dtrsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtrmv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtrmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtrmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDtrmv (char uplo, char trans, char diag, int n, const double *A,
              int lda, double *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) =
     = A, or op(A) = transpose(A). x is an n-element single precision vector, and
 A is an n x n, unit or non-unit, upper or lower, triangular matrix composed
 of single precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', then A is an upper triangular matrix.
        If uplo = 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa = 'N' or 'n', op(A) = A. If trans = 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 diag   specifies whether or not matrix A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 A      single precision array of dimension (lda, n). If uplo = 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular matrix and the strictly lower triangular part
        of A is not referenced. If uplo = 'L' or 'l', the leading n x n lower
        triangular part of the array A must contain the lower triangular
        matrix and the strictly upper triangular part of A is not referenced.
        When diag = 'U' or 'u', the diagonal elements of A are not referenced
        either, but are are assumed to be unity.
 lda    is the leading dimension of A. It must be at least max (1, n).
 x      single precision array of length at least (1 + (n - 1) * abs(incx) ).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/dtrmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDgbmv-char-int-int-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDgbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDgbmv(char&nbsp;trans,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;kl,
                               int&nbsp;ku,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDgbmv (char trans, int m, int n, int kl, int ku, double alpha,
              const double *A, int lda, const double *x, int incx, double beta,
              double *y, int incy);

 performs one of the matrix-vector operations

    y = alpha*op(A)*x + beta*y,  op(A)=A or op(A) = transpose(A)

 alpha and beta are double precision scalars. x and y are double precision
 vectors. A is an m by n band matrix consisting of double precision elements
 with kl sub-diagonals and ku super-diagonals.

 Input
 -----
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 m      specifies the number of rows of the matrix A. m must be at least
        zero.
 n      specifies the number of columns of the matrix A. n must be at least
        zero.
 kl     specifies the number of sub-diagonals of matrix A. It must be at
        least zero.
 ku     specifies the number of super-diagonals of matrix A. It must be at
        least zero.
 alpha  double precision scalar multiplier applied to op(A).
 A      double precision array of dimensions (lda, n). The leading
        (kl + ku + 1) x n part of the array A must contain the band matrix A,
        supplied column by column, with the leading diagonal of the matrix
        in row (ku + 1) of the array, the first super-diagonal starting at
        position 2 in row ku, the first sub-diagonal starting at position 1
        in row (ku + 2), and so on. Elements in the array A that do not
        correspond to elements in the band matrix (such as the top left
        ku x ku triangle) are not referenced.
 lda    leading dimension of A. lda must be at least (kl + ku + 1).
 x      double precision array of length at least (1+(n-1)*abs(incx)) when
        trans == 'N' or 'n' and at least (1+(m-1)*abs(incx)) otherwise.
 incx   specifies the increment for the elements of x. incx must not be zero.
 beta   double precision scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      double precision array of length at least (1+(m-1)*abs(incy)) when
        trans == 'N' or 'n' and at least (1+(n-1)*abs(incy)) otherwise. If
        beta is zero, y is not read.
 incy   On entry, incy specifies the increment for the elements of y. incy
        must not be zero.

 Output
 ------
 y      updated according to y = alpha*op(A)*x + beta*y

 Reference: http://www.netlib.org/blas/dgbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtbmv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtbmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDtbmv (char uplo, char trans, char diag, int n, int k, const double *A,
              int lda, double *x, int incx)

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A). x is an n-element double precision vector, and A is
 an n x n, unit or non-unit, upper or lower triangular band matrix composed
 of double precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular band
        matrix. If uplo == 'U' or 'u', A is an upper triangular band matrix.
        If uplo == 'L' or 'l', A is a lower triangular band matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      double precision array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first
        super-diagonal starting at position 2 in row k, and so on. The top
        left k x k triangle of the array A is not referenced. If uplo == 'L'
        or 'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal startingat position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 lda    is the leading dimension of A. It must be at least (k + 1).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x

 Reference: http://www.netlib.org/blas/dtbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n or k < 0, or if incx == 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtpmv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtpmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtpmv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDtpmv (char uplo, char trans, char diag, int n, const double *AP,
              double *x, int incx);

 performs one of the matrix-vector operations x = op(A) * x, where op(A) = A,
 or op(A) = transpose(A). x is an n element double precision vector, and A
 is an n x n, unit or non-unit, upper or lower triangular matrix composed
 of double precision elements.

 Input
 -----
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo == 'U' or 'u', then A is an upper triangular matrix.
        If uplo == 'L' or 'l', then A is a lower triangular matrix.
 trans  specifies op(A). If transa == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A)
 diag   specifies whether or not matrix A is unit triangular. If diag == 'U'
        or 'u', A is assumed to be unit triangular. If diag == 'N' or 'n', A
        is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero. In the current implementation n must not exceed 4070.
 AP     double precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored in AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the source vector. On exit, x is overwritten
        with the result vector.
 incx   specifies the storage spacing for elements of x. incx must not be
        zero.

 Output
 ------
 x      updated according to x = op(A) * x,

 Reference: http://www.netlib.org/blas/dtpmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or n < 0
 CUBLAS_STATUS_ALLOC_FAILED     if function cannot allocate enough internal scratch vector memory
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtpsv-char-char-char-int-jcuda.Pointer-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtpsv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtpsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasDtpsv (char uplo, char trans, char diag, int n, const double *AP,
              double *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A). b and x are n element vectors, and A is
 an n x n unit or non-unit, upper or lower triangular matrix. No test for
 singularity or near-singularity is included in this routine. Such tests
 must be performed before calling this routine.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular matrix
        as follows: If uplo == 'U' or 'u', A is an upper triangluar matrix.
        If uplo == 'L' or 'l', A is a lower triangular matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 AP     double precision array with at least ((n*(n+1))/2) elements. If uplo
        == 'U' or 'u', the array AP contains the upper triangular matrix A,
        packed sequentially, column by column; that is, if i <= j, then
        A[i,j] is stored is AP[i+(j*(j+1)/2)]. If uplo == 'L' or 'L', the
        array AP contains the lower triangular matrix A, packed sequentially,
        column by column; that is, if i >= j, then A[i,j] is stored in
        AP[i+((2*n-j+1)*j)/2]. When diag = 'U' or 'u', the diagonal elements
        of A are not referenced and are assumed to be unity.
 x      double precision array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/dtpsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0 or n > 2035
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtbsv-char-char-char-int-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtbsv</h4>
<pre>public static&nbsp;void&nbsp;cublasDtbsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void cublasDtbsv (char uplo, char trans, char diag, int n, int k,
                   const double *A, int lda, double *X, int incx)

 solves one of the systems of equations op(A)*x = b, where op(A) is either
 op(A) = A or op(A) = transpose(A). b and x are n element vectors, and A is
 an n x n unit or non-unit, upper or lower triangular band matrix with k + 1
 diagonals. No test for singularity or near-singularity is included in this
 function. Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix is an upper or lower triangular band
        matrix as follows: If uplo == 'U' or 'u', A is an upper triangular
        band matrix. If uplo == 'L' or 'l', A is a lower triangular band
        matrix.
 trans  specifies op(A). If trans == 'N' or 'n', op(A) = A. If trans == 'T',
        't', 'C', or 'c', op(A) = transpose(A).
 diag   specifies whether A is unit triangular. If diag == 'U' or 'u', A is
        assumed to be unit triangular; thas is, diagonal elements are not
        read and are assumed to be unity. If diag == 'N' or 'n', A is not
        assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. n must be
        at least zero.
 k      specifies the number of super- or sub-diagonals. If uplo == 'U' or
        'u', k specifies the number of super-diagonals. If uplo == 'L' or
        'l', k specifies the number of sub-diagonals. k must at least be
        zero.
 A      double precision array of dimension (lda, n). If uplo == 'U' or 'u',
        the leading (k + 1) x n part of the array A must contain the upper
        triangular band matrix, supplied column by column, with the leading
        diagonal of the matrix in row (k + 1) of the array, the first super-
        diagonal starting at position 2 in row k, and so on. The top left
        k x k triangle of the array A is not referenced. If uplo == 'L' or
        'l', the leading (k + 1) x n part of the array A must constain the
        lower triangular band matrix, supplied column by column, with the
        leading diagonal of the matrix in row 1 of the array, the first
        sub-diagonal starting at position 1 in row 2, and so on. The bottom
        right k x k triangle of the array is not referenced.
 x      double precision array of length at least (1+(n-1)*abs(incx)).
 incx   storage spacing between elements of x. It must not be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/dtbsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0, n < 0 or n > 2035
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsymv-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsymv</h4>
<pre>public static&nbsp;void&nbsp;cublasDsymv(char&nbsp;uplo,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDsymv (char uplo, int n, double alpha, const double *A, int lda,
              const double *x, int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

     y = alpha*A*x + beta*y

 Alpha and beta are double precision scalars, and x and y are double
 precision vectors, each with n elements. A is a symmetric n x n matrix
 consisting of double precision elements that is stored in either upper or
 lower storage mode.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the array A
        is to be referenced. If uplo == 'U' or 'u', the symmetric matrix A
        is stored in upper storage mode, i.e. only the upper triangular part
        of A is to be referenced while the lower triangular part of A is to
        be inferred. If uplo == 'L' or 'l', the symmetric matrix A is stored
        in lower storage mode, i.e. only the lower triangular part of A is
        to be referenced while the upper triangular part of A is to be
        inferred.
 n      specifies the number of rows and the number of columns of the
        symmetric matrix A. n must be at least zero.
 alpha  double precision scalar multiplier applied to A*x.
 A      double precision array of dimensions (lda, n). If uplo == 'U' or 'u',
        the leading n x n upper triangular part of the array A must contain
        the upper triangular part of the symmetric matrix and the strictly
        lower triangular part of A is not referenced. If uplo == 'L' or 'l',
        the leading n x n lower triangular part of the array A must contain
        the lower triangular part of the symmetric matrix and the strictly
        upper triangular part of A is not referenced.
 lda    leading dimension of A. It must be at least max (1, n).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision scalar multiplier applied to vector y.
 y      double precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/dsymv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsbmv-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDsbmv(char&nbsp;uplo,
                               int&nbsp;n,
                               int&nbsp;k,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDsbmv (char uplo, int n, int k, double alpha, const double *A, int lda,
              const double *x, int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are double precision scalars. x and y are double precision
 vectors with n elements. A is an n by n symmetric band matrix consisting
 of double precision elements, with k super-diagonals and the same number
 of subdiagonals.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the symmetric
        band matrix A is being supplied. If uplo == 'U' or 'u', the upper
        triangular part is being supplied. If uplo == 'L' or 'l', the lower
        triangular part is being supplied.
 n      specifies the number of rows and the number of columns of the
        symmetric matrix A. n must be at least zero.
 k      specifies the number of super-diagonals of matrix A. Since the matrix
        is symmetric, this is also the number of sub-diagonals. k must be at
        least zero.
 alpha  double precision scalar multiplier applied to A*x.
 A      double precision array of dimensions (lda, n). When uplo == 'U' or
        'u', the leading (k + 1) x n part of array A must contain the upper
        triangular band of the symmetric matrix, supplied column by column,
        with the leading diagonal of the matrix in row (k+1) of the array,
        the first super-diagonal starting at position 2 in row k, and so on.
        The top left k x k triangle of the array A is not referenced. When
        uplo == 'L' or 'l', the leading (k + 1) x n part of the array A must
        contain the lower triangular band part of the symmetric matrix,
        supplied column by column, with the leading diagonal of the matrix in
        row 1 of the array, the first sub-diagonal starting at position 1 in
        row 2, and so on. The bottom right k x k triangle of the array A is
        not referenced.
 lda    leading dimension of A. lda must be at least (k + 1).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      double precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/dsbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if k or n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDspmv-char-int-double-jcuda.Pointer-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDspmv</h4>
<pre>public static&nbsp;void&nbsp;cublasDspmv(char&nbsp;uplo,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasDspmv (char uplo, int n, double alpha, const double *AP, const double *x,
              int incx, double beta, double *y, int incy)

 performs the matrix-vector operation

    y = alpha * A * x + beta * y

 Alpha and beta are double precision scalars, and x and y are double
 precision vectors with n elements. A is a symmetric n x n matrix
 consisting of double precision elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision scalar multiplier applied to A*x.
 AP     double precision array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the symmetric matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision scalar multiplier applied to vector y;
 y      double precision array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to y = alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/dspmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDgemm-char-char-int-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDgemm</h4>
<pre>public static&nbsp;void&nbsp;cublasDgemm(char&nbsp;transa,
                               char&nbsp;transb,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;k,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasDgemm (char transa, char transb, int m, int n, int k, double alpha,
              const double *A, int lda, const double *B, int ldb,
              double beta, double *C, int ldc)

 computes the product of matrix A and matrix B, multiplies the result
 by scalar alpha, and adds the sum to the product of matrix C and
 scalar beta. It performs one of the matrix-matrix operations:

 C = alpha * op(A) * op(B) + beta * C,
 where op(X) = X or op(X) = transpose(X),

 and alpha and beta are double-precision scalars. A, B and C are matrices
 consisting of double-precision elements, with op(A) an m x k matrix,
 op(B) a k x n matrix, and C an m x n matrix. Matrices A, B, and C are
 stored in column-major format, and lda, ldb, and ldc are the leading
 dimensions of the two-dimensional arrays containing A, B, and C.

 Input
 -----
 transa specifies op(A). If transa == 'N' or 'n', op(A) = A.
        If transa == 'T', 't', 'C', or 'c', op(A) = transpose(A).
 transb specifies op(B). If transb == 'N' or 'n', op(B) = B.
        If transb == 'T', 't', 'C', or 'c', op(B) = transpose(B).
 m      number of rows of matrix op(A) and rows of matrix C; m must be at
        least zero.
 n      number of columns of matrix op(B) and number of columns of C;
        n must be at least zero.
 k      number of columns of matrix op(A) and number of rows of op(B);
        k must be at least zero.
 alpha  double-precision scalar multiplier applied to op(A) * op(B).
 A      double-precision array of dimensions (lda, k) if transa == 'N' or
        'n', and of dimensions (lda, m) otherwise. If transa == 'N' or
        'n' lda must be at least max(1, m), otherwise lda must be at
        least max(1, k).
 lda    leading dimension of two-dimensional array used to store matrix A.
 B      double-precision array of dimensions (ldb, n) if transb == 'N' or
        'n', and of dimensions (ldb, k) otherwise. If transb == 'N' or
        'n' ldb must be at least max (1, k), otherwise ldb must be at
        least max(1, n).
 ldb    leading dimension of two-dimensional array used to store matrix B.
 beta   double-precision scalar multiplier applied to C. If zero, C does not
        have to be a valid input
 C      double-precision array of dimensions (ldc, n); ldc must be at least
        max(1, m).
 ldc    leading dimension of two-dimensional array used to store matrix C.

 Output
 ------
 C      updated based on C = alpha * op(A)*op(B) + beta * C.

 Reference: http://www.netlib.org/blas/sgemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS was not initialized
 CUBLAS_STATUS_INVALID_VALUE    if m < 0, n < 0, or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtrsm-char-char-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtrsm</h4>
<pre>public static&nbsp;void&nbsp;cublasDtrsm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasDtrsm (char side, char uplo, char transa, char diag, int m, int n,
              double alpha, const double *A, int lda, double *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a double precision scalar, and X and B are m x n matrices
 that are composed of double precision elements. A is a unit or non-unit,
 upper or lower triangular matrix, and op(A) is one of

    op(A) = A  or  op(A) = transpose(A)

 The result matrix X overwrites input matrix B; that is, on exit the result
 is stored in B. Matrices A and B are stored in column major format, and
 lda and ldb are the leading dimensions of the two-dimensonials arrays that
 contain A and B, respectively.

 Input
 -----
 side   specifies whether op(A) appears on the left or right of X as
        follows: side = 'L' or 'l' indicates solve op(A) * X = alpha * B.
        side = 'R' or 'r' indicates solve X * op(A) = alpha * B.
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix as follows: uplo = 'U' or 'u' indicates A is an upper
        triangular matrix. uplo = 'L' or 'l' indicates A is a lower
        triangular matrix.
 transa specifies the form of op(A) to be used in matrix multiplication
        as follows: If transa = 'N' or 'N', then op(A) = A. If transa =
        'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 m      specifies the number of rows of B. m must be at least zero.
 n      specifies the number of columns of B. n must be at least zero.
 alpha  is a double precision scalar to be multiplied with B. When alpha is
        zero, then A is not referenced and B need not be set before entry.
 A      is a double precision array of dimensions (lda, k), where k is
        m when side = 'L' or 'l', and is n when side = 'R' or 'r'. If
        uplo = 'U' or 'u', the leading k x k upper triangular part of
        the array A must contain the upper triangular matrix and the
        strictly lower triangular matrix of A is not referenced. When
        uplo = 'L' or 'l', the leading k x k lower triangular part of
        the array A must contain the lower triangular matrix and the
        strictly upper triangular part of A is not referenced. Note that
        when diag = 'U' or 'u', the diagonal elements of A are not
        referenced, and are assumed to be unity.
 lda    is the leading dimension of the two dimensional array containing A.
        When side = 'L' or 'l' then lda must be at least max(1, m), when
        side = 'R' or 'r' then lda must be at least max(1, n).
 B      is a double precision array of dimensions (ldb, n). ldb must be
        at least max (1,m). The leading m x n part of the array B must
        contain the right-hand side matrix B. On exit B is overwritten
        by the solution matrix X.
 ldb    is the leading dimension of the two dimensional array containing B.
        ldb must be at least max(1, m).

 Output
 ------
 B      contains the solution matrix X satisfying op(A) * X = alpha * B,
        or X * op(A) = alpha * B

 Reference: http://www.netlib.org/blas/dtrsm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtrsm-char-char-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtrsm</h4>
<pre>public static&nbsp;void&nbsp;cublasZtrsm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasZtrsm (char side, char uplo, char transa, char diag, int m, int n,
              cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              cuDoubleComplex *B, int ldb)

 solves one of the matrix equations

    op(A) * X = alpha * B,   or   X * op(A) = alpha * B,

 where alpha is a double precision complex scalar, and X and B are m x n matrices
 that are composed of double precision complex elements. A is a unit or non-unit,
 upper or lower triangular matrix, and op(A) is one of

    op(A) = A  or  op(A) = transpose(A)  or  op( A ) = conj( A' ).

 The result matrix X overwrites input matrix B; that is, on exit the result
 is stored in B. Matrices A and B are stored in column major format, and
 lda and ldb are the leading dimensions of the two-dimensonials arrays that
 contain A and B, respectively.

 Input
 -----
 side   specifies whether op(A) appears on the left or right of X as
        follows: side = 'L' or 'l' indicates solve op(A) * X = alpha * B.
        side = 'R' or 'r' indicates solve X * op(A) = alpha * B.
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix as follows: uplo = 'U' or 'u' indicates A is an upper
        triangular matrix. uplo = 'L' or 'l' indicates A is a lower
        triangular matrix.
 transa specifies the form of op(A) to be used in matrix multiplication
        as follows: If transa = 'N' or 'N', then op(A) = A. If transa =
        'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 m      specifies the number of rows of B. m must be at least zero.
 n      specifies the number of columns of B. n must be at least zero.
 alpha  is a double precision complex scalar to be multiplied with B. When alpha is
        zero, then A is not referenced and B need not be set before entry.
 A      is a double precision complex array of dimensions (lda, k), where k is
        m when side = 'L' or 'l', and is n when side = 'R' or 'r'. If
        uplo = 'U' or 'u', the leading k x k upper triangular part of
        the array A must contain the upper triangular matrix and the
        strictly lower triangular matrix of A is not referenced. When
        uplo = 'L' or 'l', the leading k x k lower triangular part of
        the array A must contain the lower triangular matrix and the
        strictly upper triangular part of A is not referenced. Note that
        when diag = 'U' or 'u', the diagonal elements of A are not
        referenced, and are assumed to be unity.
 lda    is the leading dimension of the two dimensional array containing A.
        When side = 'L' or 'l' then lda must be at least max(1, m), when
        side = 'R' or 'r' then lda must be at least max(1, n).
 B      is a double precision complex array of dimensions (ldb, n). ldb must be
        at least max (1,m). The leading m x n part of the array B must
        contain the right-hand side matrix B. On exit B is overwritten
        by the solution matrix X.
 ldb    is the leading dimension of the two dimensional array containing B.
        ldb must be at least max(1, m).

 Output
 ------
 B      contains the solution matrix X satisfying op(A) * X = alpha * B,
        or X * op(A) = alpha * B

 Reference: http://www.netlib.org/blas/ztrsm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDtrmm-char-char-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDtrmm</h4>
<pre>public static&nbsp;void&nbsp;cublasDtrmm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasDtrmm (char side, char uplo, char transa, char diag, int m, int n,
              double alpha, const double *A, int lda, const double *B, int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a double-precision scalar, B is an m x n matrix composed
 of double precision elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of double precision elements. op(A) is one of

   op(A) = A  or  op(A) = transpose(A)

 Matrices A and B are stored in column major format, and lda and ldb are
 the leading dimensions of the two-dimensonials arrays that contain A and
 B, respectively.

 Input
 -----
 side   specifies whether op(A) multiplies B from the left or right.
        If side = 'L' or 'l', then B = alpha * op(A) * B. If side =
        'R' or 'r', then B = alpha * B * op(A).
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', A is an upper triangular matrix.
        If uplo = 'L' or 'l', A is a lower triangular matrix.
 transa specifies the form of op(A) to be used in the matrix
        multiplication. If transa = 'N' or 'n', then op(A) = A. If
        transa = 'T', 't', 'C', or 'c', then op(A) = transpose(A).
 diag   specifies whether or not A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or
        'n', A is not assumed to be unit triangular.
 m      the number of rows of matrix B. m must be at least zero.
 n      the number of columns of matrix B. n must be at least zero.
 alpha  double precision scalar multiplier applied to op(A)*B, or
        B*op(A), respectively. If alpha is zero no accesses are made
        to matrix A, and no read accesses are made to matrix B.
 A      double precision array of dimensions (lda, k). k = m if side =
        'L' or 'l', k = n if side = 'R' or 'r'. If uplo = 'U' or 'u'
        the leading k x k upper triangular part of the array A must
        contain the upper triangular matrix, and the strictly lower
        triangular part of A is not referenced. If uplo = 'L' or 'l'
        the leading k x k lower triangular part of the array A must
        contain the lower triangular matrix, and the strictly upper
        triangular part of A is not referenced. When diag = 'U' or 'u'
        the diagonal elements of A are no referenced and are assumed
        to be unity.
 lda    leading dimension of A. When side = 'L' or 'l', it must be at
        least max(1,m) and at least max(1,n) otherwise
 B      double precision array of dimensions (ldb, n). On entry, the
        leading m x n part of the array contains the matrix B. It is
        overwritten with the transformed matrix on exit.
 ldb    leading dimension of B. It must be at least max (1, m).

 Output
 ------
 B      updated according to B = alpha * op(A) * B  or B = alpha * B * op(A)

 Reference: http://www.netlib.org/blas/dtrmm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsymm-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsymm</h4>
<pre>public static&nbsp;void&nbsp;cublasDsymm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasDsymm (char side, char uplo, int m, int n, double alpha,
              const double *A, int lda, const double *B, int ldb,
              double beta, double *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision scalars, A is a symmetric matrix
 consisting of double precision elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 elements.

 Input
 -----
 side   specifies whether the symmetric matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the symmetric matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of symmetric matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of symmetric
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  double precision scalar multiplier applied to A * B, or B * A
 A      double precision array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the symmetric matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the symmetric matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        symmetric matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the symmetric matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        symmetric matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the symmetric matrix and the
        strictly upper triangular part is not referenced.
 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      double precision array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      double precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/dsymm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZsymm-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZsymm</h4>
<pre>public static&nbsp;void&nbsp;cublasZsymm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZsymm (char side, char uplo, int m, int n, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
              cuDoubleComplex beta, cuDoubleComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision complex scalars, A is a symmetric matrix
 consisting of double precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 complex elements.

 Input
 -----
 side   specifies whether the symmetric matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the symmetric matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of symmetric matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of symmetric
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  double precision scalar multiplier applied to A * B, or B * A
 A      double precision array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the symmetric matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the symmetric matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        symmetric matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the symmetric matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        symmetric matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the symmetric matrix and the
        strictly upper triangular part is not referenced.
 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      double precision array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      double precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/zsymm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsyrk-char-char-int-int-double-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsyrk</h4>
<pre>public static&nbsp;void&nbsp;cublasDsyrk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasDsyrk (char uplo, char trans, int n, int k, double alpha,
              const double *A, int lda, double beta, double *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.

 Alpha and beta are double precision scalars. C is an n x n symmetric matrix
 consisting of double precision elements and stored in either lower or
 upper storage mode. A is a matrix consisting of double precision elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * transpose(A) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = transpose(A) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision scalar multiplier applied to A * transpose(A) or
        transpose(A) * A.
 A      double precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   double precision scalar multiplier applied to C. If beta izs zero, C
        does not have to be a valid input
 C      double precision array of dimensions (ldc, n). If uplo = 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo = 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * transpose(A) + beta * C, or C =
        alpha * transpose(A) * A + beta * C

 Reference: http://www.netlib.org/blas/dsyrk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZsyrk-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZsyrk</h4>
<pre>public static&nbsp;void&nbsp;cublasZsyrk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZsyrk (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, cuDoubleComplex beta, cuDoubleComplex *C, int ldc)

 performs one of the symmetric rank k operations

   C = alpha * A * transpose(A) + beta * C, or
   C = alpha * transpose(A) * A + beta * C.

 Alpha and beta are double precision complex scalars. C is an n x n symmetric matrix
 consisting of double precision complex elements and stored in either lower or
 upper storage mode. A is a matrix consisting of double precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * transpose(A) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = transpose(A) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision complex scalar multiplier applied to A * transpose(A) or
        transpose(A) * A.
 A      double precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   double precision complex scalar multiplier applied to C. If beta izs zero, C
        does not have to be a valid input
 C      double precision complex array of dimensions (ldc, n). If uplo = 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo = 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * transpose(A) + beta * C, or C =
        alpha * transpose(A) * A + beta * C

 Reference: http://www.netlib.org/blas/zsyrk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZsyr2k-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZsyr2k</h4>
<pre>public static&nbsp;void&nbsp;cublasZsyr2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZsyr2k (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
               const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
               cuDoubleComplex beta, cuDoubleComplex *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.

 Alpha and beta are double precision complex scalars. C is an n x n symmetric matrix
 consisting of double precision complex elements and stored in either lower or upper
 storage mode. A and B are matrices consisting of double precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C,
        If trans == 'T', 't', 'C', or 'c', C = alpha * transpose(A) * B +
        alpha * transpose(B) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision scalar multiplier.
 A      double precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      double precision array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      double precision array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*transpose(B) + alpha*B*transpose(A) +
        beta*C or alpha*transpose(A)*B + alpha*transpose(B)*A + beta*C

 Reference:   http://www.netlib.org/blas/zsyr2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZher2k-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZher2k</h4>
<pre>public static&nbsp;void&nbsp;cublasZher2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                double&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZher2k (char uplo, char trans, int n, int k, cuDoubleComplex alpha,
               const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
               double beta, cuDoubleComplex *C, int ldc)

 performs one of the hermitian rank 2k operations

    C =   alpha * A * conjugate(transpose(B))
        + conjugate(alpha) * B * conjugate(transpose(A))
        + beta * C ,
    or
    C =  alpha * conjugate(transpose(A)) * B
       + conjugate(alpha) * conjugate(transpose(B)) * A
       + beta * C.

 Alpha is double precision complex scalar whereas Beta is a double precision real scalar.
 C is an n x n hermitian matrix consisting of double precision complex elements and
 stored in either lower or upper storage mode. A and B are matrices consisting of
 double precision complex elements with dimension of n x k in the first case,
 and k x n in the second case.

 Input
 -----
 uplo   specifies whether the hermitian matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C =   alpha * A * conjugate(transpose(B))
            + conjugate(alpha) * B * conjugate(transpose(A))
            + beta * C .
        If trans == 'T', 't', 'C', or 'c',
        C =  alpha * conjugate(transpose(A)) * B
          + conjugate(alpha) * conjugate(transpose(B)) * A
          + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision scalar multiplier.
 A      double precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      double precision array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      double precision array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the hermitian matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the hermitian matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
        The imaginary parts of the diagonal elements need
        not be set,  they are assumed to be zero,  and on exit they
        are set to zero.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*conjugate(transpose(B)) +
        + conjugate(alpha)*B*conjugate(transpose(A)) + beta*C or
        alpha*conjugate(transpose(A))*B + conjugate(alpha)*conjugate(transpose(B))*A
        + beta*C.

 Reference:   http://www.netlib.org/blas/zher2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZher-char-int-double-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZher</h4>
<pre>public static&nbsp;void&nbsp;cublasZher(char&nbsp;uplo,
                              int&nbsp;n,
                              double&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                              int&nbsp;lda)</pre>
<div class="block"><pre>
 void
 cublasZher (char uplo, int n, double alpha, const cuDoubleComplex *x, int incx,
             cuDoubleComplex *A, int lda)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x) + A,

 where alpha is a double precision real scalar, x is an n element double
 precision complex vector and A is an n x n hermitian matrix consisting of
 double precision complex elements. Matrix A is stored in column major format,
 and lda is the leading dimension of the two-dimensional array
 containing A.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or
        the lower triangular part of array A. If uplo = 'U' or 'u',
        then only the upper triangular part of A may be referenced.
        If uplo = 'L' or 'l', then only the lower triangular part of
        A may be referenced.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 alpha  double precision real scalar multiplier applied to
        x * conjugate(transpose(x))
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must
        not be zero.
 A      double precision complex array of dimensions (lda, n). If uplo = 'U' or
        'u', then A must contain the upper triangular part of a hermitian
        matrix, and the strictly lower triangular part is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part
        of a hermitian matrix, and the strictly upper triangular part is
        not referenced. The imaginary parts of the diagonal elements need
        not be set, they are assumed to be zero, and on exit they
        are set to zero.
 lda    leading dimension of the two-dimensional array containing A. lda
        must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(x)) + A

 Reference: http://www.netlib.org/blas/zher.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhpr-char-int-double-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZhpr</h4>
<pre>public static&nbsp;void&nbsp;cublasZhpr(char&nbsp;uplo,
                              int&nbsp;n,
                              double&nbsp;alpha,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                              int&nbsp;incx,
                              <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasZhpr (char uplo, int n, double alpha, const cuDoubleComplex *x, int incx,
             cuDoubleComplex *AP)

 performs the hermitian rank 1 operation

    A = alpha * x * conjugate(transpose(x)) + A,

 where alpha is a double precision real scalar and x is an n element double
 precision complex vector. A is a hermitian n x n matrix consisting of double
 precision complex elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array AP. If uplo == 'U' or 'u', then the upper
        triangular part of A is supplied in AP. If uplo == 'L' or 'l', then
        the lower triangular part of A is supplied in AP.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision real scalar multiplier applied to x * conjugate(transpose(x)).
 x      double precision array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 AP     double precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
        The imaginary parts of the diagonal elements need not be set, they
        are assumed to be zero, and on exit they are set to zero.

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(x)) + A

 Reference: http://www.netlib.org/blas/zhpr.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, or incx == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhpr2-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZhpr2</h4>
<pre>public static&nbsp;void&nbsp;cublasZhpr2(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;AP)</pre>
<div class="block"><pre>
 void
 cublasZhpr2 (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
              const cuDoubleComplex *y, int incy, cuDoubleComplex *AP)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a double precision complex scalar, and x and y are n element double
 precision complex vectors. A is a hermitian n x n matrix consisting of double
 precision complex elements that is supplied in packed form.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision complex scalar multiplier applied to x * conjugate(transpose(y)) +
        y * conjugate(transpose(x)).
 x      double precision complex array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      double precision complex array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 AP     double precision complex array with at least ((n * (n + 1)) / 2) elements. If
        uplo == 'U' or 'u', the array AP contains the upper triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i <= j, then A[i,j] is stored is AP[i+(j*(j+1)/2)]. If
        uplo == 'L' or 'L', the array AP contains the lower triangular part
        of the hermitian matrix A, packed sequentially, column by column;
        that is, if i >= j, then A[i,j] is stored in AP[i+((2*n-j+1)*j)/2].
        The imaginary parts of the diagonal elements need not be set, they
        are assumed to be zero, and on exit they are set to zero.

 Output
 ------
 A      updated according to A = alpha*x*conjugate(transpose(y))
                               + conjugate(alpha)*y*conjugate(transpose(x))+A

 Reference: http://www.netlib.org/blas/zhpr2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZher2-char-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZher2</h4>
<pre>public static&nbsp;void&nbsp;cublasZher2(char&nbsp;uplo,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 void cublasZher2 (char uplo, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
                   const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the hermitian rank 2 operation

    A = alpha*x*conjugate(transpose(y)) + conjugate(alpha)*y*conjugate(transpose(x)) + A,

 where alpha is a double precision complex scalar, x and y are n element double
 precision complex vector and A is an n by n hermitian matrix consisting of double
 precision complex elements.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the lower
        triangular part of array A. If uplo == 'U' or 'u', then only the
        upper triangular part of A may be referenced and the lower triangular
        part of A is inferred. If uplo == 'L' or 'l', then only the lower
        triangular part of A may be referenced and the upper triangular part
        of A is inferred.
 n      specifies the number of rows and columns of the matrix A. It must be
        at least zero.
 alpha  double precision complex scalar multiplier applied to x * conjugate(transpose(y)) +
        y * conjugate(transpose(x)).
 x      double precision array of length at least (1 + (n - 1) * abs (incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 y      double precision array of length at least (1 + (n - 1) * abs (incy)).
 incy   storage spacing between elements of y. incy must not be zero.
 A      double precision complex array of dimensions (lda, n). If uplo == 'U' or 'u',
        then A must contains the upper triangular part of a hermitian matrix,
        and the strictly lower triangular parts is not referenced. If uplo ==
        'L' or 'l', then A contains the lower triangular part of a hermitian
        matrix, and the strictly upper triangular part is not referenced.
        The imaginary parts of the diagonal elements need not be set,
        they are assumed to be zero, and on exit they are set to zero.

 lda    leading dimension of A. It must be at least max(1, n).

 Output
 ------
 A      updated according to A = alpha*x*conjugate(transpose(y))
                               + conjugate(alpha)*y*conjugate(transpose(x))+A

 Reference: http://www.netlib.org/blas/zher2.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasDsyr2k-char-char-int-int-double-jcuda.Pointer-int-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasDsyr2k</h4>
<pre>public static&nbsp;void&nbsp;cublasDsyr2k(char&nbsp;uplo,
                                char&nbsp;trans,
                                int&nbsp;n,
                                int&nbsp;k,
                                double&nbsp;alpha,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                                int&nbsp;lda,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                                int&nbsp;ldb,
                                double&nbsp;beta,
                                <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                                int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasDsyr2k (char uplo, char trans, int n, int k, double alpha,
               const double *A, int lda, const double *B, int ldb,
               double beta, double *C, int ldc)

 performs one of the symmetric rank 2k operations

    C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C, or
    C = alpha * transpose(A) * B + alpha * transpose(B) * A + beta * C.

 Alpha and beta are double precision scalars. C is an n x n symmetric matrix
 consisting of double precision elements and stored in either lower or upper
 storage mode. A and B are matrices consisting of double precision elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the symmetric matrix C is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the symmetric matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the symmetric matrix is to be references,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n',
        C = alpha * A * transpose(B) + alpha * B * transpose(A) + beta * C,
        If trans == 'T', 't', 'C', or 'c', C = alpha * transpose(A) * B +
        alpha * transpose(B) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of rows of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision scalar multiplier.
 A      double precision array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contain the matrix
        A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1,k).
 B      double precision array of dimensions (lda, kb), where kb is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array B must contain the matrix B,
        otherwise the leading k x n part of the array must contain the matrix
        B.
 ldb    leading dimension of N. When trans == 'N' or 'n' then ldb must be at
        least max(1, n). Otherwise ldb must be at least max(1, k).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      double precision array of dimensions (ldc, n). If uplo == 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the symmetric matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo == 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the symmetric matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
 ldc    leading dimension of C. Must be at least max(1, n).

 Output
 ------
 C      updated according to alpha*A*transpose(B) + alpha*B*transpose(A) +
        beta*C or alpha*transpose(A)*B + alpha*transpose(B)*A + beta*C

 Reference:   http://www.netlib.org/blas/dsyr2k.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZgemm-char-char-int-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZgemm</h4>
<pre>public static&nbsp;void&nbsp;cublasZgemm(char&nbsp;transa,
                               char&nbsp;transb,
                               int&nbsp;m,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void cublasZgemm (char transa, char transb, int m, int n, int k,
                   cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
                   const cuDoubleComplex *B, int ldb, cuDoubleComplex beta,
                   cuDoubleComplex *C, int ldc)

 zgemm performs one of the matrix-matrix operations

    C = alpha * op(A) * op(B) + beta*C,

 where op(X) is one of

    op(X) = X   or   op(X) = transpose  or  op(X) = conjg(transpose(X))

 alpha and beta are double-complex scalars, and A, B and C are matrices
 consisting of double-complex elements, with op(A) an m x k matrix, op(B)
 a k x n matrix and C an m x n matrix.

 Input
 -----
 transa specifies op(A). If transa == 'N' or 'n', op(A) = A. If transa ==
        'T' or 't', op(A) = transpose(A). If transa == 'C' or 'c', op(A) =
        conjg(transpose(A)).
 transb specifies op(B). If transa == 'N' or 'n', op(B) = B. If transb ==
        'T' or 't', op(B) = transpose(B). If transb == 'C' or 'c', op(B) =
        conjg(transpose(B)).
 m      number of rows of matrix op(A) and rows of matrix C. It must be at
        least zero.
 n      number of columns of matrix op(B) and number of columns of C. It
        must be at least zero.
 k      number of columns of matrix op(A) and number of rows of op(B). It
        must be at least zero.
 alpha  double-complex scalar multiplier applied to op(A)op(B)
 A      double-complex array of dimensions (lda, k) if transa ==  'N' or
        'n'), and of dimensions (lda, m) otherwise.
 lda    leading dimension of A. When transa == 'N' or 'n', it must be at
        least max(1, m) and at least max(1, k) otherwise.
 B      double-complex array of dimensions (ldb, n) if transb == 'N' or 'n',
        and of dimensions (ldb, k) otherwise
 ldb    leading dimension of B. When transb == 'N' or 'n', it must be at
        least max(1, k) and at least max(1, n) otherwise.
 beta   double-complex scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input.
 C      double precision array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m).

 Output
 ------
 C      updated according to C = alpha*op(A)*op(B) + beta*C

 Reference: http://www.netlib.org/blas/zgemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if any of m, n, or k are < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtrmm-char-char-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtrmm</h4>
<pre>public static&nbsp;void&nbsp;cublasZtrmm(char&nbsp;side,
                               char&nbsp;uplo,
                               char&nbsp;transa,
                               char&nbsp;diag,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb)</pre>
<div class="block"><pre>
 void
 cublasZtrmm (char side, char uplo, char transa, char diag, int m, int n,
              cuDoubleComplex alpha, const cuDoubleComplex *A, int lda, const cuDoubleComplex *B,
              int ldb)

 performs one of the matrix-matrix operations

   B = alpha * op(A) * B,  or  B = alpha * B * op(A)

 where alpha is a double-precision complex scalar, B is an m x n matrix composed
 of double precision complex elements, and A is a unit or non-unit, upper or lower,
 triangular matrix composed of double precision complex elements. op(A) is one of

   op(A) = A  , op(A) = transpose(A) or op(A) = conjugate(transpose(A))

 Matrices A and B are stored in column major format, and lda and ldb are
 the leading dimensions of the two-dimensonials arrays that contain A and
 B, respectively.

 Input
 -----
 side   specifies whether op(A) multiplies B from the left or right.
        If side = 'L' or 'l', then B = alpha * op(A) * B. If side =
        'R' or 'r', then B = alpha * B * op(A).
 uplo   specifies whether the matrix A is an upper or lower triangular
        matrix. If uplo = 'U' or 'u', A is an upper triangular matrix.
        If uplo = 'L' or 'l', A is a lower triangular matrix.
 transa specifies the form of op(A) to be used in the matrix
        multiplication. If transa = 'N' or 'n', then op(A) = A. If
        transa = 'T' or 't', then op(A) = transpose(A).
        If transa = 'C' or 'c', then op(A) = conjugate(transpose(A)).
 diag   specifies whether or not A is unit triangular. If diag = 'U'
        or 'u', A is assumed to be unit triangular. If diag = 'N' or
        'n', A is not assumed to be unit triangular.
 m      the number of rows of matrix B. m must be at least zero.
 n      the number of columns of matrix B. n must be at least zero.
 alpha  double precision complex scalar multiplier applied to op(A)*B, or
        B*op(A), respectively. If alpha is zero no accesses are made
        to matrix A, and no read accesses are made to matrix B.
 A      double precision complex array of dimensions (lda, k). k = m if side =
        'L' or 'l', k = n if side = 'R' or 'r'. If uplo = 'U' or 'u'
        the leading k x k upper triangular part of the array A must
        contain the upper triangular matrix, and the strictly lower
        triangular part of A is not referenced. If uplo = 'L' or 'l'
        the leading k x k lower triangular part of the array A must
        contain the lower triangular matrix, and the strictly upper
        triangular part of A is not referenced. When diag = 'U' or 'u'
        the diagonal elements of A are no referenced and are assumed
        to be unity.
 lda    leading dimension of A. When side = 'L' or 'l', it must be at
        least max(1,m) and at least max(1,n) otherwise
 B      double precision complex array of dimensions (ldb, n). On entry, the
        leading m x n part of the array contains the matrix B. It is
        overwritten with the transformed matrix on exit.
 ldb    leading dimension of B. It must be at least max (1, m).

 Output
 ------
 B      updated according to B = alpha * op(A) * B  or B = alpha * B * op(A)

 Reference: http://www.netlib.org/blas/ztrmm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZgeru-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZgeru</h4>
<pre>public static&nbsp;void&nbsp;cublasZgeru(int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasZgeru (int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
             const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * transpose(y) + A,

 where alpha is a double precision complex scalar, x is an m element double
 precision complex vector, y is an n element double precision complex vector, and A
 is an m by n matrix consisting of double precision complex elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  double precision complex scalar multiplier applied to x * transpose(y)
 x      double precision complex array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      double precision complex array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      double precision complex array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * transpose(y) + A

 Reference: http://www.netlib.org/blas/zgeru.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m < 0, n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZgerc-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZgerc</h4>
<pre>public static&nbsp;void&nbsp;cublasZgerc(int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda)</pre>
<div class="block"><pre>
 cublasZgerc (int m, int n, cuDoubleComplex alpha, const cuDoubleComplex *x, int incx,
             const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda)

 performs the symmetric rank 1 operation

    A = alpha * x * conjugate(transpose(y)) + A,

 where alpha is a double precision complex scalar, x is an m element double
 precision complex vector, y is an n element double precision complex vector, and A
 is an m by n matrix consisting of double precision complex elements. Matrix A
 is stored in column major format, and lda is the leading dimension of
 the two-dimensional array used to store A.

 Input
 -----
 m      specifies the number of rows of the matrix A. It must be at least
        zero.
 n      specifies the number of columns of the matrix A. It must be at
        least zero.
 alpha  double precision complex scalar multiplier applied to x * conjugate(transpose(y))
 x      double precision array of length at least (1 + (m - 1) * abs(incx))
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.
 y      double precision complex array of length at least (1 + (n - 1) * abs(incy))
 incy   specifies the storage spacing between elements of y. incy must not
        be zero.
 A      double precision complex array of dimensions (lda, n).
 lda    leading dimension of two-dimensional array used to store matrix A

 Output
 ------
 A      updated according to A = alpha * x * conjugate(transpose(y)) + A

 Reference: http://www.netlib.org/blas/zgerc.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m < 0, n < 0, incx == 0, incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZherk-char-char-int-int-double-jcuda.Pointer-int-double-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZherk</h4>
<pre>public static&nbsp;void&nbsp;cublasZherk(char&nbsp;uplo,
                               char&nbsp;trans,
                               int&nbsp;n,
                               int&nbsp;k,
                               double&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               double&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZherk (char uplo, char trans, int n, int k, double alpha,
              const cuDoubleComplex *A, int lda, double beta, cuDoubleComplex *C, int ldc)

 performs one of the hermitian rank k operations

   C = alpha * A * conjugate(transpose(A)) + beta * C, or
   C = alpha * conjugate(transpose(A)) * A + beta * C.

 Alpha and beta are double precision scalars. C is an n x n hermitian matrix
 consisting of double precision complex elements and stored in either lower or
 upper storage mode. A is a matrix consisting of double precision complex elements
 with dimension of n x k in the first case, and k x n in the second case.

 Input
 -----
 uplo   specifies whether the hermitian matrix C is stored in upper or lower
        storage mode as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 trans  specifies the operation to be performed. If trans == 'N' or 'n', C =
        alpha * A * conjugate(transpose(A)) + beta * C. If trans == 'T', 't', 'C', or 'c',
        C = alpha * conjugate(transpose(A)) * A + beta * C.
 n      specifies the number of rows and the number columns of matrix C. If
        trans == 'N' or 'n', n specifies the number of rows of matrix A. If
        trans == 'T', 't', 'C', or 'c', n specifies the columns of matrix A.
        n must be at least zero.
 k      If trans == 'N' or 'n', k specifies the number of columns of matrix A.
        If trans == 'T', 't', 'C', or 'c', k specifies the number of rows of
        matrix A. k must be at least zero.
 alpha  double precision scalar multiplier applied to A * conjugate(transpose(A)) or
        conjugate(transpose(A)) * A.
 A      double precision complex array of dimensions (lda, ka), where ka is k when
        trans == 'N' or 'n', and is n otherwise. When trans == 'N' or 'n',
        the leading n x k part of array A must contain the matrix A,
        otherwise the leading k x n part of the array must contains the
        matrix A.
 lda    leading dimension of A. When trans == 'N' or 'n' then lda must be at
        least max(1, n). Otherwise lda must be at least max(1, k).
 beta   double precision scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      double precision complex array of dimensions (ldc, n). If uplo = 'U' or 'u',
        the leading n x n triangular part of the array C must contain the
        upper triangular part of the hermitian matrix C and the strictly
        lower triangular part of C is not referenced. On exit, the upper
        triangular part of C is overwritten by the upper triangular part of
        the updated matrix. If uplo = 'L' or 'l', the leading n x n
        triangular part of the array C must contain the lower triangular part
        of the hermitian matrix C and the strictly upper triangular part of C
        is not referenced. On exit, the lower triangular part of C is
        overwritten by the lower triangular part of the updated matrix.
        The imaginary parts of the diagonal elements need
        not be set,  they are assumed to be zero,  and on exit they
        are set to zero.
 ldc    leading dimension of C. It must be at least max(1, n).

 Output
 ------
 C      updated according to C = alpha * A * conjugate(transpose(A)) + beta * C, or C =
        alpha * conjugate(transpose(A)) * A + beta * C

 Reference: http://www.netlib.org/blas/zherk.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if n < 0 or k < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhemm-char-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZhemm</h4>
<pre>public static&nbsp;void&nbsp;cublasZhemm(char&nbsp;side,
                               char&nbsp;uplo,
                               int&nbsp;m,
                               int&nbsp;n,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;B,
                               int&nbsp;ldb,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;C,
                               int&nbsp;ldc)</pre>
<div class="block"><pre>
 void
 cublasZhemm (char side, char uplo, int m, int n, cuDoubleComplex alpha,
              const cuDoubleComplex *A, int lda, const cuDoubleComplex *B, int ldb,
              cuDoubleComplex beta, cuDoubleComplex *C, int ldc);

 performs one of the matrix-matrix operations

   C = alpha * A * B + beta * C, or
   C = alpha * B * A + beta * C,

 where alpha and beta are double precision complex scalars, A is a hermitian matrix
 consisting of double precision complex elements and stored in either lower or upper
 storage mode, and B and C are m x n matrices consisting of double precision
 complex elements.

 Input
 -----
 side   specifies whether the hermitian matrix A appears on the left side
        hand side or right hand side of matrix B, as follows. If side == 'L'
        or 'l', then C = alpha * A * B + beta * C. If side = 'R' or 'r',
        then C = alpha * B * A + beta * C.
 uplo   specifies whether the hermitian matrix A is stored in upper or lower
        storage mode, as follows. If uplo == 'U' or 'u', only the upper
        triangular part of the hermitian matrix is to be referenced, and the
        elements of the strictly lower triangular part are to be infered from
        those in the upper triangular part. If uplo == 'L' or 'l', only the
        lower triangular part of the hermitian matrix is to be referenced,
        and the elements of the strictly upper triangular part are to be
        infered from those in the lower triangular part.
 m      specifies the number of rows of the matrix C, and the number of rows
        of matrix B. It also specifies the dimensions of hermitian matrix A
        when side == 'L' or 'l'. m must be at least zero.
 n      specifies the number of columns of the matrix C, and the number of
        columns of matrix B. It also specifies the dimensions of hermitian
        matrix A when side == 'R' or 'r'. n must be at least zero.
 alpha  double precision scalar multiplier applied to A * B, or B * A
 A      double precision complex array of dimensions (lda, ka), where ka is m when
        side == 'L' or 'l' and is n otherwise. If side == 'L' or 'l' the
        leading m x m part of array A must contain the hermitian matrix,
        such that when uplo == 'U' or 'u', the leading m x m part stores the
        upper triangular part of the hermitian matrix, and the strictly lower
        triangular part of A is not referenced, and when uplo == 'U' or 'u',
        the leading m x m part stores the lower triangular part of the
        hermitian matrix and the strictly upper triangular part is not
        referenced. If side == 'R' or 'r' the leading n x n part of array A
        must contain the hermitian matrix, such that when uplo == 'U' or 'u',
        the leading n x n part stores the upper triangular part of the
        hermitian matrix and the strictly lower triangular part of A is not
        referenced, and when uplo == 'U' or 'u', the leading n x n part
        stores the lower triangular part of the hermitian matrix and the
        strictly upper triangular part is not referenced. The imaginary parts
        of the diagonal elements need not be set, they are assumed to be zero.

 lda    leading dimension of A. When side == 'L' or 'l', it must be at least
        max(1, m) and at least max(1, n) otherwise.
 B      double precision complex array of dimensions (ldb, n). On entry, the leading
        m x n part of the array contains the matrix B.
 ldb    leading dimension of B. It must be at least max (1, m).
 beta   double precision complex scalar multiplier applied to C. If beta is zero, C
        does not have to be a valid input
 C      double precision complex array of dimensions (ldc, n)
 ldc    leading dimension of C. Must be at least max(1, m)

 Output
 ------
 C      updated according to C = alpha * A * B + beta * C, or C = alpha *
        B * A + beta * C

 Reference: http://www.netlib.org/blas/zhemm.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if m or n are < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZtrsv-char-char-char-int-jcuda.Pointer-int-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cublasZtrsv</h4>
<pre>public static&nbsp;void&nbsp;cublasZtrsv(char&nbsp;uplo,
                               char&nbsp;trans,
                               char&nbsp;diag,
                               int&nbsp;n,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx)</pre>
<div class="block"><pre>
 void
 cublasZtrsv (char uplo, char trans, char diag, int n, const cuDoubleComplex *A,
              int lda, cuDoubleComplex *x, int incx)

 solves a system of equations op(A) * x = b, where op(A) is either A,
 transpose(A) or conjugate(transpose(A)). b and x are double precision
 complex vectors consisting of n elements, and A is an n x n matrix
 composed of a unit or non-unit, upper or lower triangular matrix.
 Matrix A is stored in column major format, and lda is the leading
 dimension of the two-dimensional array containing A.

 No test for singularity or near-singularity is included in this function.
 Such tests must be performed before calling this function.

 Input
 -----
 uplo   specifies whether the matrix data is stored in the upper or the
        lower triangular part of array A. If uplo = 'U' or 'u', then only
        the upper triangular part of A may be referenced. If uplo = 'L' or
        'l', then only the lower triangular part of A may be referenced.
 trans  specifies op(A). If transa = 'n' or 'N', op(A) = A. If transa = 't',
        'T', 'c', or 'C', op(A) = transpose(A)
 diag   specifies whether or not A is a unit triangular matrix like so:
        if diag = 'U' or 'u', A is assumed to be unit triangular. If
        diag = 'N' or 'n', then A is not assumed to be unit triangular.
 n      specifies the number of rows and columns of the matrix A. It
        must be at least 0.
 A      is a double precision complex array of dimensions (lda, n). If uplo = 'U'
        or 'u', then A must contains the upper triangular part of a symmetric
        matrix, and the strictly lower triangular parts is not referenced.
        If uplo = 'L' or 'l', then A contains the lower triangular part of
        a symmetric matrix, and the strictly upper triangular part is not
        referenced.
 lda    is the leading dimension of the two-dimensional array containing A.
        lda must be at least max(1, n).
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
        On entry, x contains the n element right-hand side vector b. On exit,
        it is overwritten with the solution vector x.
 incx   specifies the storage spacing between elements of x. incx must not
        be zero.

 Output
 ------
 x      updated to contain the solution vector x that solves op(A) * x = b.

 Reference: http://www.netlib.org/blas/ztrsv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if incx == 0 or if n < 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
<a name="cublasZhbmv-char-int-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-jcuda.Pointer-int-jcuda.cuDoubleComplex-jcuda.Pointer-int-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>cublasZhbmv</h4>
<pre>public static&nbsp;void&nbsp;cublasZhbmv(char&nbsp;uplo,
                               int&nbsp;n,
                               int&nbsp;k,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;alpha,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;A,
                               int&nbsp;lda,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;x,
                               int&nbsp;incx,
                               <a href="../../jcuda/cuDoubleComplex.html" title="class in jcuda">cuDoubleComplex</a>&nbsp;beta,
                               <a href="../../jcuda/Pointer.html" title="class in jcuda">Pointer</a>&nbsp;y,
                               int&nbsp;incy)</pre>
<div class="block"><pre>
 void
 cublasZhbmv (char uplo, int n, int k, cuDoubleComplex alpha, const cuDoubleComplex *A, int lda,
              const cuDoubleComplex *x, int incx, cuDoubleComplex beta, cuDoubleComplex *y, int incy)

 performs the matrix-vector operation

     y := alpha*A*x + beta*y

 alpha and beta are double precision complex scalars. x and y are double precision
 complex vectors with n elements. A is an n by n hermitian band matrix consisting
 of double precision complex elements, with k super-diagonals and the same number
 of subdiagonals.

 Input
 -----
 uplo   specifies whether the upper or lower triangular part of the hermitian
        band matrix A is being supplied. If uplo == 'U' or 'u', the upper
        triangular part is being supplied. If uplo == 'L' or 'l', the lower
        triangular part is being supplied.
 n      specifies the number of rows and the number of columns of the
        hermitian matrix A. n must be at least zero.
 k      specifies the number of super-diagonals of matrix A. Since the matrix
        is hermitian, this is also the number of sub-diagonals. k must be at
        least zero.
 alpha  double precision complex scalar multiplier applied to A*x.
 A      double precision complex array of dimensions (lda, n). When uplo == 'U' or
        'u', the leading (k + 1) x n part of array A must contain the upper
        triangular band of the hermitian matrix, supplied column by column,
        with the leading diagonal of the matrix in row (k+1) of the array,
        the first super-diagonal starting at position 2 in row k, and so on.
        The top left k x k triangle of the array A is not referenced. When
        uplo == 'L' or 'l', the leading (k + 1) x n part of the array A must
        contain the lower triangular band part of the hermitian matrix,
        supplied column by column, with the leading diagonal of the matrix in
        row 1 of the array, the first sub-diagonal starting at position 1 in
        row 2, and so on. The bottom right k x k triangle of the array A is
        not referenced. The imaginary parts of the diagonal elements need
        not be set, they are assumed to be zero.
 lda    leading dimension of A. lda must be at least (k + 1).
 x      double precision complex array of length at least (1 + (n - 1) * abs(incx)).
 incx   storage spacing between elements of x. incx must not be zero.
 beta   double precision complex scalar multiplier applied to vector y. If beta is
        zero, y is not read.
 y      double precision complex array of length at least (1 + (n - 1) * abs(incy)).
        If beta is zero, y is not read.
 incy   storage spacing between elements of y. incy must not be zero.

 Output
 ------
 y      updated according to alpha*A*x + beta*y

 Reference: http://www.netlib.org/blas/zhbmv.f

 Error status for this function can be retrieved via cublasGetError().

 Error Status
 ------------
 CUBLAS_STATUS_NOT_INITIALIZED  if CUBLAS library has not been initialized
 CUBLAS_STATUS_INVALID_VALUE    if k or n < 0, or if incx or incy == 0
 CUBLAS_STATUS_ARCH_MISMATCH    if invoked on device without DP support
 CUBLAS_STATUS_EXECUTION_FAILED if function failed to launch on GPU
 </pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/JCublas.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../jcuda/jcublas/cublasStatus.html" title="class in jcuda.jcublas"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../jcuda/jcublas/JCublas2.html" title="class in jcuda.jcublas"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?jcuda/jcublas/JCublas.html" target="_top">Frames</a></li>
<li><a href="JCublas.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<p class="legalCopy"><small>Copyright &#169; 2016. All rights reserved.</small></p>
</body>
</html>
