---
title: 딥 뉴럴 네트워크 소개
layout: kr-default
---

# 딥 뉴럴 네트워크 소개

차례

* <a href="#define">뉴럴 네트워크의 정의</a>
* <a href="#element">뉴럴 네트워크의 구성 요소</a>
* <a href="#concept">딥 뉴럴 네트워크의 기본 개념</a>
* <a href="#forward">예제: 뉴럴 네트워크와 backprop</a>
* <a href="#regression">다중 회귀 분석 (Multiple Linear Regression)</a>
* <a href="#logistic">로지스틱 회귀 및 분류</a>
* <a href="#ai">뉴럴 네트워크와 인공 지능</a>
* <a href="#intro">학습 자료</a>

## <a name="define">뉴럴 네트워크의 정의</a>

뉴럴 네트워크는 인간의 뇌가 패턴을 인식하는 방식을 모사한 알고리즘입니다. 뉴럴 네트워크는 시각, 청각 입력 데이터를 퍼셉트론이나 분류, 군집을 이용하여 해석하는데, 이렇게 해석한 결과 이용하면 이미지, 소리, 문자, 시계열 데이터에서 특정 패턴을 인식할 수 있습니다.

뉴럴 네트워크를 이용하면 각종 분류(classification) 및 군집화(clustering)가 가능합니다. 지금부터 자세히 살펴보겠지만, 단순하게 표현하면 분류나 군집화를 원하는 데이터 위에 여러 가지 레이어를 얹어서 원하는 작업을 하게 됩니다. 이 레이어에서는 라벨링이 되어있지 않은 데이터를 서로 비교하여 유사도를 구해주거나, 라벨링이 되어있는 데이터를 기반으로 분류기를 학습하여 자동으로 데이터를 분류하도록 할 수 있습니다. (구체적으로 이야기하면 뉴럴 네트워크로 특징을 추출하고 그 특징을 다시 다른 머신러닝 알고리즘의 입력으로 사용하여 분류나 군집화를 할 수 있습니다. 즉, 딥 뉴럴 네트워크를 어떤 머신러닝 시스템의 구성 요소로 생각하면 됩니다. 여기서 전체 시스템이란 [강화학습(Reinforced learning)](../reinforcementlearning.html), 분류 및 [군집화](../linear-regression.html)를 말합니다.)

딥러닝을 이용해보고 싶다면 우선 어떤 문제를 해결하고 싶은지 생각해 보십시오. 어떤 분류를 하고 싶은지, 그리고 내가 어떤 정보를 취할 수 있는지에 대해서 말입니다. 예를 들면 이메일 데이타를 `스팸`과 `스팸 아님`으로 분류한다든지, 고객을 `친절한 고객`과 `악덕 고객`, `불만이 많은 고객`과 `만족하는 고객`으로 분류할 수 있습니다. 이렇게 어떤 분류를 원하는지 정한 뒤엔 분류에 필요한 데이터를 가지고 있는지 생각 해 보아야 합니다. 예를 들어 이미 `스팸`과 `스팸 아님`으로 라벨링이 된 이메일 데이터가 있는지, 없다면 내가 직접 데이터셋을 만들 수 있는지를 고민해야 합니다. 또, 이 데이터로 원하는 라벨링이 과연 가능한 것인지도 생각해봐야 합니다.

예를 들어, 암 고위험군에 속하는 사람들을 분류하는 알고리즘을 만들기 위해서는 우선 암 환자와 아닌 사람의 데이터가 필요합니다. 데이터는 사람들의 나이, 흡연 습관같은 쉬운 특징이나 일일 운동량, 온라인 활동 로그같은 간접적인 특징 등 무엇이든 가능합니다. 그러나 사람들의 건강과 관련된 개인 정보가 전혀 없는 상태라면 아무리 좋은 알고리즘이 있어도 암을 예측하기는 어려울 것 입니다.

필요한 데이터가 있다면 이제 뉴럴 네트워크가 사람들의 암 발병률을 예측하도록 학습할 수 있습니다. 즉, 암에 걸린/걸리지 않은 사람들이 각각 어떤 행동 패턴을 갖는지, 어떤 것을 기준으로 어떻게 분류하면 되는지를 뉴럴 네트워크가 학습하도록 하는 것 입니다. 가지고 있는 데이터로 학습이 잘 되었다면 이젠 사람들의 행동 패턴을 이용해 그 사람들이 암에 걸릴 확률을 예상할 수 있습니다.

같은 원리로 다양한 분류 작업이 가능합니다. 예를 들어 소셜 데이팅 서비스를 기획한다면 서로 잘 어울릴 수 있는 상대를 골라주거나, 신인 중에서 장래가 유망한 운동 선수, 회사에 도움이 될 직원 등을 분류하는 것이 가능합니다. 물론 작업마다 다른 데이터가 필요합니다. 예를 들어 사람들의 취미, 나이, 사회 활동이나 운동 선수의 운동량, 체형, 직원의 근로 실적 등을 이용할 수 있습니다.

## <a name="element">뉴럴 네트워크의 구성 요소</a>

딥러닝은 뉴럴 네트워크 중에서 여러 개의 레이어를 사용해 구성한 네트워크를 말하며, 이 레이어는 여러 개의 노드로 이루어져 있습니다. 노드에서는 실제로 연산이 일어나는데, 이 연산 과정은 인간의 신경망을 구성하는 뉴런에서 일어나는 과정을 모사하도록 설계되어있습니다. 노드는 일정 크기 이상의 자극을 받으면 반응을 하는데, 그 반응의 크기는 입력 값과 노드의 계수를 곱한 값와 대략 비례합니다. 일반적으로 노드는 여러 개의 입력을 받으며 입력의 개수 만큼 계수를 가지고 있습니다. 따라서 이 계수를 조절함으로써 여러 입력에 다른 가중치를 부여할 수 있습니다. 최종적으로 곱한 값들은 전부 더해지고 그 합은 활성 함수(activation function)의 입력으로 들어가게 됩니다. 활성 함수의 결과가 노드의 출력에 해당하며 이 출력값이 궁극적으로 분류나 회귀 분석에 쓰이게 됩니다.

노드에서 일어나는 계산 과정이 아래 다이어그램에 정리되어 있습니다.

![Alt text](../img/perceptron_node.png)

레이어는 여러 개의 노드로 이루어져 있으며 입력값에 따라 각 노드의 활성화/비활성화 여부가 결정됩니다. 입력 데이터는 첫 번째 레이어의 입력이 되며 그 이후엔 각 레이어의 출력이 다시 다음 레이어의 입력이 됩니다.

![Alt text](../img/mlp.png)

모든 계수는 학습 과정에서 계속 조금씩 변하는데, 결과적으로 각 노드가 어떤 입력을 중요하게 여기는지를 반영합니다. 그리고 뉴럴 네트워크의 '학습(training)'은 이 계수를 업데이트하는 과정입니다.

## <a name="concept">딥 뉴럴 네트워크의 기본 개념</a>

딥러닝 네트워크와 일반적인 (단일 레이어) 네트워크의 핵심적인 차이점은 레이어의 개수 (깊이)입니다.

전통적인 머신러닝 알고리즘은 하나의 입력과 하나의 출력 레이어로 이루어져 있으며 기껏해야 중간에 하나의 히든 레이어를 가지고 있습니다. 이런 구조의 네트워크를 얕다(shallow)고 표현합니다. 입력과 출력 레이어를 고려해서 3개가 넘는 레이어를 (즉 2개 이상의 히든 레이어를) 갖는 경우에 우리는 이 네트워크가 깊다(deep)고 표현합니다.

딥러닝 네트워크에서 각 노드는 각자 다른 특징을 추출하며 잘 설계/학습된 뉴럴넷은 여러 가지 복잡한 특징을 추출할 수 있습니다. 

![Alt text](../img/feature_hierarchy.png)

이렇게 딥 뉴럴넷에서는 레이어마다 *다른 층위의 특징*이 학습이 됩니다. 낮은 층위의 특징은 단순하고 구체적이며 (예:이미지를 이루는 수평선, 수직선, 대각선) 높은 층위의 특징은 더욱 복잡하고 추상적입니다 (예:사람 모양, 자동차 모양, 고양이 모양, 얼굴 모양..). 이런 추상화 과정을 통해 딥 뉴럴넷이 아주 큰, 고차원의 데이터를 이해하며 이 과정은 수 억, 수 십억 개의 계수가 관여합니다. (이 과정에서 [비선형함수](../glossary.html#nonlineartransformfunction)를 사용합니다.)

또한 딥 뉴럴넷은 데이터를 이용해 데이터의 잠재적인 구조(latent structures)를 파악할 수 있습니다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감정이 무엇인지 등)를 파악할 수 있습니다. 이를 통해 데이터가 라벨링되어있지 않아도 데이터간의 유사성을 효과적으로 파악할 수 있으며, 결과적으로 딥 뉴럴넷은 데이터 군집화에 아주 좋은 성능을 발휘합니다. 

예를 들어, 딥러닝은 대량의 사진 데이터를 받아서 비슷한 사진끼리 모아줄 수 있습니다. 구글 포토나 각종 사진 관리 앱의 스마트 사진 앨범 기능은 이런 기능을 이용한 것 입니다.

이런 군집화 기술은 다른 데이터에도 적용할 수 있습니다. 예를 들어 이메일에 이 기술을 적용하면 이메일의 내용에 따라 불만/항의 메일, 감사 메일, 문의 메일, 전혀 관계없는 스팸 메일 등 메일의 내용에 따른 분류를 할 수 있습니다. 이 분류 결과를 이용하면 고객관리에 큰 도움이 될 것입니다. 같은 방법을 전화 통화 녹음 데이터에도 적용할 수 있습니다.
사용자 로그같은 시계열 데이터를 사용하면 비정상 행위 탐지가 가능합니다. 스마트폰의 위치 데이터로는 사용자의 건강 상태 진단이 가능합니다. 

딥러닝 네트워크가 일반적인 머신 러닝과 다른 점은 **특징 추출이 자동적**으로 이루어지는 점 입니다. 기존에는 효과적인 특징을 추출하기 위해 관련 분야 전문가가 오랜 시간동안 직접 특징을 추출하는 수식이나 방법을 고안해야 했습니다. 이 방법은 개발, 평가 및 보완에 많은 시간이 걸립니다. 딥러닝은 이런 과정을 컴퓨터가 대신 하도록 알고리즘을 짠 것으로, 사람에 비해 훨씬 빠르고 효과적으로 수행해도록 학습시켜줍니다. 

라벨링이 되어있지 않은 데이터를 학습하는 경우에 네트워크는 데이터의 특징을 자동적으로 추출합니다. 이 자동 추출은 여러 가지 방법이 있는데, 보통 이 과정은 네트워크를 통과시켰을 때의 출력이 입력과 같아지도록 학습합니다. 결과적으로 이 네트워크는 입력을 효율적으로 인코딩하고 다시 이를 디코딩하는 - 간단하게 말하면 재구성(reconstruct)하는 - 작업을 합니다. RBM(Restricted Boltzmann machines)의 학습 과정도 이런 구조로 이루어져있습니다.

라벨이 어떤 것이든지(입력을 그대로 사용/별도의 라벨을 사용) 네트워크는 입력과 출력의 상관관계를 찾습니다.

상황에 따라서 라벨링된 데이터로 네트워크를 어느 정도 학습시킨 뒤 라벨링이 되어있지 않은 데이터를 추가하여 네트워크를 계속 학습시킬 수도 있습니다. 이 방법을 이용하면 네트워크의 성능을 극대화할 수 있습니다. 흔히 충분한 데이터를 가진 일반적인 알고리즘이 구조는 훌륭하지만 데이터가 부족한 알고리즘보다 더 좋다고 합니다. 라벨링이 되어있지 않은 데이터에서도 학습이 가능하다는 점은 딥러닝의 특별한 장점입니다.

딥러닝 네트워크의 마지막 레이어는 출력 레이어입니다. 출력 레이너는 로지스틱(logistic) 혹은 소프트맥스(softmax)인 경우가 대부분인데 이 레이어를 사용하면 최종적으로 특정 라벨의 확률을 구할 수 있습니다. 예를 들어 사진을 입력으로 넣었을 때 사진의 물체가 사람일 확률을 구할 수 있습니다.

## <a name="forward">예제: 뉴럴 네트워크와 backprop</a>

뉴럴넷 학습의 목적은 최종적으로 출력에서 오류를 최소화하는 것 입니다. 운동장 주변의 트랙을 뛰는 달리기 경기를 생각해보십시오. 트랙을 여러 바퀴 달리다 보면 같은 지점을 여러 번 지나게 됩니다. 뉴럴넷의 학습 과정도 비슷합니다. 우선 학습이 시작되기 전에 뉴럴넷의 모든 계수는 초기화됩니다. 그리고 학습이 잘 되었다면 업데이트된 계수를 이용해 뉴럴넷으로 각종 분류와 예측이 가능합니다.

학습 과정 내부에선 같은 원리의 계수 업데이트가 반복적으로 일어납니다. 계수 업데이트의 원리는 우선 계수를 추정하고 그 계수를 사용했을 때 발생하는 에러를 측정한 뒤 그 에러에 기반해서 계수를 약간씩 업데이트 하는 것 입니다.

우리는 네트워크의 여러 계수를 합쳐서 모델이라고 부릅니다. 모델은 초기화 된 상태일 수도 있고, 학습이 완료된 상태일 수도 있습니다. 실제로 데이터가 생성되는 원리는 알 수 없기 때문에 이것을 모사한, 말 그대로 모델인 셈입니다. 초기화된 모델은 의미있는 작업을 하 못하지만 학습이 진행될수록 모델은 임의의 값이 아닌, 실제와 유사한 결과를 출력하게 됩니다.

이는 뉴럴 네트워크가 데이터를 보기 전 까지는 아무것도 모르는 상태이기 때문입니다. 계수를 임의의 값으로 초기화하는 이유도 마찬가지입니다. 그리고 데이터를 읽어가면서 계수를 조금씩 올바른 방향으로 업데이트 합니다.

이제 정말 단순하게 이 과정을 식으로 표현하겠습니다.

입력값이 네트워크에 들어오면, 현재 상태의 계수를 이용해 결과를 출력합니다.

    입력 * 계수 = 출력 (추정값)

그리고 이렇게 추정한 값을 실제 정답과 비교합니다.

    정답 - 추정값 = 오차

정답과 추정값의 차이가 바로 오차입니다. 네트워크는 오차를 측정하고 이 오차를 반영해서 계수를 보정합니다. 

    오차 * 계수 별 오차 기여도 = 보정값

이 아주 간략한 관계식에 뉴럴 네트워크의 가장 중요한 내용이 있습니다. 입력을 받아 출력을 내고, 오차를 계산한 뒤 이를 반영해 계수를 업데이트 하는 것 입니다. 이 과정을 계속 반복하는 것이 학습 과정입니다.

이제 단계별로 자세히 살펴봅시다. 우선 입력을 받아서 출력을 추정하는 과정을 보겠습니다.

### <a name="multiple">다중 회귀 분석</a>

인공 신경망(뉴럴 네트워크은 사람의 신경망을 모사한 측면이 있습니다. 하지만 결과적으로 뉴럴 네트워크는 숫자와 수식으로 이루어진 머신러닝 알고리즘입니다. 사실 원리 자체는 매우 간단해서 *선형 회귀*를 아는 사람이라면 누구나 뉴럴 네트워크를 이해할 수 있습니다. 선형 회귀를 간단히 수식으로 표현하면 아래와 같습니다.

        Y_hat = bX + a

여기에서 X는 입력, b는 기울기, a는 y절편, Y_hat은 추정한 출력입니다. 예를 들면 X는 일일 운동량이고 Y는 발병률, 또는 X는 비료 사용량이고 Y는 수확량이 될 수 있습니다. Y가 X에 영향을 받는 모든 경우를 이 식으로 모델링할 수 있습니다. 

이제 이 회귀 분석 식을 *다중 회귀 분석*으로 바꿔봅시다. 다중 회귀 분석은 회귀 분석과 유사하지만 입력 변수가 여러 개입니다. 즉, 아래와 같은 식으로 표현할 수 있습니다.

        Y_hat = b_1*X_1 + b_2*X_2 + b_3*X_3 + a

수확량을 예측경우라면 `X_1`이 비료 사용량, `X_2`는 강우량, `X_3`은 일조량을 가정할 수 있습니다. 이 세 가지 변수는 모두 `Y_hat`, 수확량에 영향을 끼칩니다.

사실 뉴럴 네트워크의 모든 노드마다 별도의 다중 회귀 분석이 이루어집니다. 레이어의 출력은 다음 단계 레이어의 입력이 된다고 이야기 했었는데, 이 입력 값이 바로 위의 `X_1`, `X_2`, `X_3`에 해당합니다. 그리고 노드가 갖고 있는 계수는 `b_1`, `b_2`, `b_3`입니다. 다시 말해 이 계수는 입력 값을 얼마나 반영할 것인지를 정하는 가중치입니다. 그리고 신경망의 학습은 각 레이어가 입력 데이터 중 어떤 값을 얼마나 반영할 것인지를 정하는 과정입니다.

이렇게 계산된 `Y_hat`은 출력으로 나가기 전에 비선형 함수를 한 번 통과합니다. 여기에서 비선형 함수를 사용하는 이유는 여러 가지가 있습니다. 일반적으로, 출력의 범위를 제한하는 비선형 함수를 써서 노드의 출력값이 너무 크게 발산하지 않게 해줍니다. (이것보다 더 중요한 목적은 함수의 비선형성이 필요하기 때문입니다.)

이렇게 회귀 분석과 비선형 함수를 조합하면 노드는 켜고 끌 수 있는 스위치 같은 역할을 합니다. (인간의 뉴런도 마찬가지입니다.) 이 스위치는 입력 신호를 얼마나 출력에 전달할지를 정하고, 수많은 스위치의 조합이 최종 출력단에서 분류 작업을 합니다.

뉴럴 네트워크의 최종 출력단의 출력을 1/0으로 제한하면 (binary decision) 특정 라벨에 대한 분류가 됩니다. 반면 [로지스틱 회귀 분석](#logistic)을 출력단에 붙이면 출력값이 0과 1 사이의 연속적인 값(예: 0, 0.4, 0.5, 0.9..)으로 나올 수 있게 됩니다.

각 노드에서 적용되는 비선형 함수는 S자 모양의 비선형성을 갖는 경우가 대부분입니다. Sigmode함수나 하이퍼탄젠셜 함수가 여기에 해당합니다. 그리고 이 비선형 함수의 출력이 다시 다음 레이어의 입력 값이 됩니다. 

### Gradient Descent

모델의 학습 과정에서는 각 계수의 값이 반복적으로 업데이트됩니다. 이 업데이트 방법 중 가장 널리 쓰이는 방법은 "gradient descent (경사 하강법)"입니다.

Gradient는 경사 혹은 기울기를 의미합니다. x-y 평면에서 기울기는 두 변수의 관계를 설명해줍니다. x의 변화량에 따른 y의 변화량 - 예를 들어 시간에 따른 통잔 잔고의 변화량을 함수의 기울기로 설명할 수 있습니다. 뉴럴 네트워크에서는 우리는 네트워크의 오차와 각 계수의 관계에 관심이 있습니다. 즉, 각 계수의 값을 증가 혹은 감소시켰을 때 네트워크의 오차가 어떻게 변하는지 그 관계에 주목합니다.

조금 더 자세히 들여다봅시다. 계수를 어떤 값으로 결정하면 전체 에러가 가장 작아질까요? 어떻게 노드의 계수를 설정해야 입력 데이터에서 의미있는 정보를 추출할 수 있을까요? 어떻게 해야 사진의 물체가 사람인지, 자동차인지, 고양이인지 알아낼 수 있을까요?

뉴럴 네트워크 학습과정은 수 많은 계수를 보정해가는 과정입니다. 이 계수는 오차를 줄이는 방향으로 보정되어야 데이터에서 의미있는 정보를 추출할 수 있습니다. 그리고 이 *오차*와 *계수*의 관계는 편미분으로 정의할 수 있습니다. *dE/dw*가 계수의 변화량에 따른 오차의 변화량, 즉 우리에게 중요한 그 *기울기*에 해당합니다.

딥 뉴럴 네트워크는 여러 레이어로 이루어져있기 때문에 각 노드의 계수는 신호에 곱해지는 여러 계수 중 하나입니다. 따라서 이 관계를 미적분학의 [연쇄 법칙(chain rule)](https://ko.wikipedia.org/wiki/연쇄_법칙)을 사용해 설명할 수 있습니다. 이를 이용하면 네트워크의 출력이 여러 층의 레이어와 갖는 관계를 구할 수 있습니다. 그리고 결과적으로 각 레이어의 계수와 최종 출력(또는 오차)과의 관계가 나옵니다.

연쇄 법칙은 아래와 같이 설명할 수 있습니다.

![Alt text](../img/chain_rule.png)

뉴럴 네트워크의 오차와 각 계수와의 관계는 아래와 같습니다.

![Alt text](../img/backprop_chain_rule.png)

즉 *오차*와 *계수*가 *활성 함수*를 통해 정해지는 경우 최종적으로 계수 값의 변화가 오차를 증가할지, 혹은 감소할지를 구할 수 있습니다. 반대로 활성 함수를 바꾸는 것이 어떤 영향을 끼칠지도 구할 수 있습니다. 

이것이 딥러닝 학습의 핵심입니다. 모델의 학습은 모델의 계수를 업데이트해서 오차를 줄이는 과정입니다.

## <a name="logistic">로지스틱 회귀 함수</a>

딥 러닝 네트워크의 여러 레이어 중 마지막 레이어, 즉 출력 레이어는 다른 레이어와는 조금 다릅니다. 가장 흔한 작업인 분류(classification) 작업의 경우 출력 레이어는 데이터의 각 샘플이 여러 범주에 속할 확률을 구한 뒤 확률을 비교하여 그 중 하나의 범주를 선택합니다. 출력 레이어의 노드는 각각 하나의 범주에 해당하고 이 노드가 활성화 되는 정도를 비교하여 하나의 노드를, 즉 하나의 범주를 고릅니다.

분류 작업의 경우 최종적으로 출력 노드는 0 또는 1의 값을 가지게 됩니다. 즉, 무조건 해당 범주에 속하거나(1) 혹은 속하지 않는다(0)는 결론을 내리게 설계됩니다.

한편 입력 데이터는 출력과 달리 연속적인 값을 가지는 경우가 대부분입니다. 즉 입력 신호는 특정 범위에서 연속적인 값을 갖는 값으로 이루어져 있습니다.

예를 들어 추천 엔진을 구현하는 경우 최종 결과는 해당 아이템을 추천할 것 인지 아닌지로 딱 떨어지게 나와야 합니다. 하지만 입력 데이터는 고객이 해당 페이지에서 머무른 시간, 고객의 구매력 등 연속된 값을 갖습니다.

즉 입력으로 들어온 온갖 범위의 값(예: 3만원짜리 티셔츠, 고객이 과거에 구매한 내역, 고객이 웹사이트에 머무른 시간 등)을 압축해서 최종적으로 이 아이템을 어떤 범주에 넣을 것인지, 혹은 사용자가 어떤 타입의 고객인지 등 어떤 범주에 넣을지를 결정합니다.

이렇게 넓은 범위의 값을 0 또는 1의 값으로 결정해주는 과정을 로지스틱 회귀라고 합니다. 이 이름이 굉장히 헷갈리기 쉬운데, 회귀(연속된 값을 예측하는 작업)라는 이름이 붙여져 있지만 실제로는 분류 작업을 한다는 것을 유의하시기 바랍니다. 

![Alt text](../img/logistic_regression.png)

로지스틱 회귀의 공식을 조금 들여다 보겠습니다.

연속된 값(예: -100, -0.5, 1.0, e^4, 300,...)을 확률로 표현해주려면 입력 값을 양수로 바꿔야 합니다. (확률은 0에서 1사이의 값을 가집니다.) 이렇게 양수로 바꿔주기 위해 분모에 *e^(-x)*가 들어갑니다. 왜냐하면 *e^(-x)*의 경우 x에 어떤 값이 들어오더라도 그 결과는 양수가 되기 때문입니다. 

또 한 가지 고려할 내용은 바로 입력값 x가 클 경우 확률이 점점 증가하도록 설계해야 한다는 것 입니다. 그래서 *e^(-x)*가 분모에 포함되어 있습니다. 만일 x가 점점 커지면 *e^(-x)*는 (여전히 양수지만) 점점 작아집니다. 그러면 *F(x)*는 (확률의 최대 값인) 1에 가까워집니다. 반대로 x가 점점 작아지면 (-1, -10, -100...) *e^(-x)*의 값이 매우 커지고, *F(x)*는 0에 가까워집니다. 

만일 이렇게 지수 함수로 처리를 하지 않는다면 결과를 0과 1 사이에 압축시키기가 매우 까다롭습니다. 따라서 지수 함수를 사용한 로지스틱 회귀를 뉴럴 네트워크의 출력 레이어에 사용하는 것 입니다.

최종적인 판단을 위해서 확률의 기준값을 세워주면 됩니다. 예를 들어 어떤 노드의 확률이 0.5보다 크다면 그 노드에 해당하는 범주에 속한다고 판별한다고 규칙을 만드는 것 입니다. 만일 이 기준값이 너무 작다면(예:0.0001을 넘기면 이 범주에 해당한다) false positive(긍정 오류, 거짓 양성: 실제로는 이 범주에 해당하지 않는데 이 범주라고 예측을 하는 것)가 많아지고, 기준값이 너무 크다면 반대로 false negative(부정 오류, 거짓 음성)이 많아집니다.

## <a name="ai">뉴럴 네트워크와 인공 지능</a>

이렇게 임의의 값에서 출발해서 시행착오를 거듭하는 학습 과정 때문에 뉴럴 네트워크는 단순 무식한 방법(brute force)라고 비판받기도 합니다. 학습한 모델의 결과가 좋더라도 과정이 비효율적이라는 단점을 지적하는 사람들이 있기 때문입니다.

그러나 경사 하강법은 존재하는 모든 경우의 수를 다 따지는 것이 아닙니다. 계속해서 가능한 경우의 수를 줄여나가며 최적의 답을 찾는 과정이기 때문에 사실은 굉장히 효율적인 방법입니다.

## <a name="intro">학습 자료</a>

딥러닝 초보자들을 위한 강좌를 모아놓았으니 참고하시기 바랍니다.

* [제한된 볼츠만 머신(Restricted Boltzmann Machines)를 위한 초보자용 튜토리얼](../kr-restrictedboltzmannmachine.html)
* [고유 벡터(Eigenvectors), PCA, 공분산(Covariance) 및 엔트로피(Entropy)](../kr-eigenvector.html)
* [딥러닝과 뉴럴 네트워크 용어 사전](../glossary.html)
* [컨볼루션 네트워](../kr-convolutionalnets.html)
* [RNNs과](../kr-usingrnns.html)
* [Word2vec과 자연어 처리](../kr-word2vec.html)
* [Deeplearing4j 퀵 스타트 가이드 (Quick Start Guide)](../kr-quickstart.html)
* [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) (A seven-video series)
* [A Neural Network in 11 Lines of Python](https://iamtrask.github.io/2015/07/12/basic-python-network/)
* [A Step-by-Step Backpropagation Example](http://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
